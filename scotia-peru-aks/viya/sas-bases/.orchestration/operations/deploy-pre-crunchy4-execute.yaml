apiVersion: orchestration.sas.com/v3beta6
kind: LifecycleOperation
metadata:
  annotations:
    sas.com/component-name: sas-crunchy5-postgres-operator
    sas.com/component-version: 1.6.3-20250609.1749489660207
  creationTimestamp: null
  name: deploy-pre-crunchy4-execute
spec:
  args:
  - name: manifest
  - name: namespace
  - name: timeout
  - name: serviceAccountName
  source: |-
    package main
    import (
      "encoding/json"
      "fmt"
      "sas/orchestration/lifecycle"
      c "sas/orchestration/lifecycle/cluster"
      m "sas/orchestration/lifecycle/manifest"
    )
    func main() {
      manifest := lifecycle.Arg("manifest")
      namespace := lifecycle.Arg("namespace")
      timeout := lifecycle.Arg("timeout")
      serviceAccountName := lifecycle.Arg("serviceAccountName")
      // see ORCHESTRATE-2654 for details on why this is conditionally run
      if len(serviceAccountName) != 0 {
        setupRbac(serviceAccountName, namespace, timeout)
        defer cleanupRbac(serviceAccountName, namespace)
      }
      resources, err := c.Resources(c.Namespace(namespace), c.Group("crunchydata.com"), c.Version("v1"), c.Resource("pgclusters"))
      if err != nil {
        panic(fmt.Sprintf("Failed to get Pgclusters: %v", err))
      }
      scaleDownDataServerOperatorIfExists(namespace, timeout)
      for _, resource := range resources {
        pgclusterNameI := resource.F("metadata").F("name").Value()
        pgclusterName, ok := pgclusterNameI.(string)
        if !ok {
          panic(fmt.Sprintf("Pgcluster didn't have a name"))
        }
        // safely shut down pgcluster
        shutdownPostgres(pgclusterName, namespace, timeout)
        onOpenShift := lifecycle.VariableExists("dataserver.sas.com/is-openshift")
        if !onOpenShift {
          // fix permissions for pgcluster, see DEPENBDAT-2205
          patchBackrestSecurityContext(pgclusterName, namespace, timeout)
          fixBackrestFilePerms(pgclusterName, namespace)
        }
        // delete pgcluster & additional artifacts
        runRmdataPgtask(pgclusterName, namespace, timeout)
        waitForRmdataPgtaskDeletion(pgclusterName, namespace, timeout)
        deleteTLSArtifacts(pgclusterName, namespace, timeout)
        if onOpenShift {
          // fix permissions for pgcluster specific to OpenShift
          fixOpenShiftFilePerms(manifest, pgclusterName, namespace, timeout)
        }
      }
      waitForRemainingPostgresPodDeletion(namespace, timeout)
      scaleDownCrunchyOperator(namespace, timeout)
    }
    func setupRbac(serviceAccountName, namespace, timeout string) {
      serviceAccount := fmt.Sprintf("%s:%s", namespace, serviceAccountName)
      // Clear out and re-create the role for pgclusters
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgclusters")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pgclusters", "--verb", "get,create,update,patch,list", "--resource", "pgclusters.crunchydata.com")
      // Clear out and re-create the role for pgtasks
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgtasks")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pgtasks", "--verb", "get,create,update,patch,list,watch", "--resource", "pgtasks.crunchydata.com")
      // Clear out and re-create the role for pods
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pods", "--verb", "get,list,watch", "--resource", "pods")
      // Clear out and re-create the role for pods/exec
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods-exec")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pods-exec", "--verb", "get,create", "--resource", "pods/exec")
      // Clear out and re-create the role for deployments
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-deployments")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-deployments", "--verb", "get,patch,list,watch", "--resource", "deployments.apps,deployments.apps/scale")
      // Clear out and re-create the role for jobs
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-jobs")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-jobs", "--verb", "get,delete", "--resource", "jobs.batch")
      // Clear out and re-create the role for secrets
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-secrets")
      lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-secrets", "--verb", "get,delete", "--resource", "secrets")
      // Clear out and re-create the rolebinding for pgclusters
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgclusters")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pgclusters", "--role", "sas-prepare-for-update-crunchy-pgclusters", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for pgtasks
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgtasks")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pgtasks", "--role", "sas-prepare-for-update-crunchy-pgtasks", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for pods
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pods", "--role", "sas-prepare-for-update-crunchy-pods", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for pods/exec
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods-exec")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pods-exec", "--role", "sas-prepare-for-update-crunchy-pods-exec", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for deployments
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-deployments")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-deployments", "--role", "sas-prepare-for-update-crunchy-deployments", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for jobs
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-jobs")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-jobs", "--role", "sas-prepare-for-update-crunchy-jobs", "--serviceaccount", serviceAccount)
      // Clear out and re-create the rolebinding for secrets
      lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-secrets")
      lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-secrets", "--role", "sas-prepare-for-update-crunchy-secrets", "--serviceaccount", serviceAccount)
    }
    func cleanupRbac(serviceAccountName, namespace string) {
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgclusters")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgtasks")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-configmaps")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods-exec")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-deployments")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-jobs")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-secrets")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgclusters")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgtasks")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-configmaps")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods-exec")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-deployments")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-jobs")
      lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-secrets")
    }
    func scaleDownDataServerOperatorIfExists(namespace, timeout string) {
      // Check if the Data Server Operator deployment exists
      resources, err := c.Resources(c.Namespace(namespace), c.Group("apps"), c.Resource("deployments"), c.Name("sas-data-server-operator"))
      if err != nil {
        panic(fmt.Sprintf("Failed to check if Data Server Operator already deployed: %v", err))
      }
      if len(resources) == 0 { // if not found, then there is nothing for us to scale
        return
      }
      // Scale down Data Server Operator so that it doesn't interfere with shutting down Pgclusters
      _, err = lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "sas-data-server-operator", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to scale down Data Server Operator deployment: %v", err))
      }
      // Wait for the Data Server Operator pod to be deleted
      _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "app.kubernetes.io/name=sas-data-server-operator", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of Data Server Operator pod: %v", err))
      }
    }
    // Only intended for non-OpenShift providers
    func patchBackrestSecurityContext(pgclusterName, namespace, timeout string) {
      backrestDeplName := fmt.Sprintf("%s-backrest-shared-repo", pgclusterName)
      _, err := lifecycle.Kubectl("patch", "--namespace", namespace, "deployment", backrestDeplName, "--type", "json", "-p", `[{"op": "replace", "path": "/spec/template/spec/securityContext", "value": { "runAsNonRoot": true, "runAsUser": 2000, "runAsGroup": 26, "fsGroup": 26, "supplementalGroups": [26, 2000]}}]`)
      if err != nil {
        panic(fmt.Sprintf("Failed to patch backrest-shared-repo deployment: %v", err))
      }
      _, err = lifecycle.Kubectl("rollout", "status", "--namespace", namespace, "--timeout", timeout, "deployment", backrestDeplName)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for backrest-shared-repo deployment patch to rollout: %v", err))
      }
    }
    // Only intended for non-OpenShift providers
    func fixBackrestFilePerms(pgclusterName, namespace string) {
      // kubectl exec requires "deployment/<depl_name>", not "deployment <depl_name>"
      backrestDeplExecName := fmt.Sprintf("deployment/%s-backrest-shared-repo", pgclusterName)
      backrestDir := fmt.Sprintf("/backrestrepo/%s-backrest-shared-repo/", pgclusterName)
      retries := 3
      retryInterval := 30
      _, err := lifecycle.KubectlWithRetry(retries, retryInterval, "exec", "--namespace", namespace, backrestDeplExecName, "--", "chmod", "-R", "770", backrestDir)
      if err != nil {
        panic(fmt.Sprintf("Failed to chmod backrest-shared-repo directory: %v", err))
      }
      _, err = lifecycle.KubectlWithRetry(retries, retryInterval, "exec", "--namespace", namespace, backrestDeplExecName, "--", "chgrp", "-R", "postgres", backrestDir)
      if err != nil {
        panic(fmt.Sprintf("Failed to chgrp backrest-shared-repo directory: %v", err))
      }
    }
    func fixOpenShiftFilePerms(manifest, pgclusterName, namespace, timeout string) {
      for step := 1; step <= 3; step++ {
        selector := fmt.Sprintf("webinfdsvr.sas.com/upgrade-crunchy-step-%d=%s", step, pgclusterName)
        resources, err := m.Resources(manifest, m.Kind("Job"), m.LabelSelector(selector))
        if err != nil {
          panic(fmt.Sprintf("Did not find manifest resources with expected label '%s': %v", selector, err))
        }
        if len(resources) != 1 {
          panic(fmt.Sprintf("Expected 1 manifest job resource with label '%s', got %d", selector, len(resources)))
        }
        resourceBytes, err := json.Marshal(resources[0].Value())
        if err != nil {
          panic(err)
        }
        _, err = lifecycle.KubectlWithStdin(string(resourceBytes), "apply", "-f", "-", "--namespace", namespace)
        if err != nil {
          panic(fmt.Sprintf("Failed to apply Crunchy OpenShift upgrade step %d: %v", step, err))
        }
        _, err = lifecycle.Kubectl("wait", "--for", "condition=complete", "job", "--namespace", namespace, "--selector", selector, "--timeout", timeout)
        if err != nil {
          panic(fmt.Sprintf("Failed to wait for Crunchy OpenShift upgrade job to finish: %v", err))
        }
      }
    }
    func shutdownPostgres(pgclusterName, namespace, timeout string) {
      // Scale down postgres replica deployments to re-elect original primary
      replicaSelector := fmt.Sprintf("crunchy-pgha-scope=%s,name!=%s", pgclusterName, pgclusterName)
      _, err := lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "--selector", replicaSelector, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to scale down Postgres replica deployments: %v", err))
      }
      // Wait for replica pods to be deleted
      _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", replicaSelector, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of Postgres replica pods: %v", err))
      }
      // Get the replica deploy names which are the same as the pvc names
      resources, err := c.Resources(c.Namespace(namespace), c.Resource("deployments"), c.LabelSelector(replicaSelector))
      if err != nil {
        panic(fmt.Sprintf("Failed to get replica deployment resources: %v", err))
      }
      for _, resource := range resources {
        deployNameI := resource.F("metadata").F("name").Value()
        deployName, ok := deployNameI.(string)
        if !ok {
          panic("Crunchy Postgres replica deployment didn't have a name")
        }
        // Delete replica PVC
        _, err = lifecycle.Kubectl("delete", "pvc", "--namespace", namespace, deployName, "--ignore-not-found", "true", "--timeout", timeout)
        if err != nil {
          panic(fmt.Sprintf("Failed to delete unused Crunchy Postgres replica PVC: %v", err))
        }
      }
      // Scale down postgres primary deployment
      primarySelector := fmt.Sprintf("crunchy-pgha-scope=%s,name=%s", pgclusterName, pgclusterName)
      _, err = lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "--selector", primarySelector, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to scale down Postgres primary deployment: %v", err))
      }
      // Wait for primary pod to be deleted
      _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", primarySelector, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of Postgres primary pod: %v", err))
      }
      // Delete the pgo-client job if exists. This job is for all pg clusters.
      _, err = lifecycle.Kubectl("delete", "job", "--namespace", namespace, "sas-crunchy-data-pgo-client", "--ignore-not-found", "true", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to delete sas-crunchy-data-pgo-client job: %v", err))
      }
    }
    func runRmdataPgtask(pgclusterName, namespace, timeout string) {
      // Run rmdata pgtask to delete the Crunchy pgcluster. Have to use this approach
      // instead of deleting the pgcluster directly since Crunchy 4.5, used in LTS 2020.1,
      // does not support deletion of the pgcluster CR directly
      pgtask := map[string]interface{}{
        "apiVersion": "crunchydata.com/v1",
        "kind":       "Pgtask",
        "metadata": map[string]interface{}{
          "labels": map[string]interface{}{
            "pg-cluster": pgclusterName,
            "pgrmdata":   "true",
          },
          "name": fmt.Sprintf("%s-rmdata", pgclusterName),
        },
        "spec": map[string]interface{}{
          "name": fmt.Sprintf("%s-rmdata", pgclusterName),
          "parameters": map[string]interface{}{
            "crunchy-pgha-scope": pgclusterName,
            "delete-backups":     "false",
            "delete-data":        "false",
            "is-backup":          "false",
            "is-replica":         "false",
            "pg-cluster":         pgclusterName,
            "replica-name":       "",
          },
          "status": "",
          "storagespec": map[string]interface{}{
            "accessmode":         "",
            "matchLabels":        "",
            "name":               "",
            "size":               "",
            "storageclass":       "",
            "storagetype":        "",
            "supplementalgroups": "",
          },
          "tasktype": "delete-data",
        },
      }
      pgtaskJson, err := json.Marshal(pgtask)
      if err != nil {
        panic(fmt.Sprintf("Failed to marshal Pgtask: %v", err))
      }
      _, err = lifecycle.KubectlWithStdin(string(pgtaskJson), "apply", "-f", "-", "--namespace", namespace, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to run Pgtask to delete Pgcluster: %v", err))
      }
    }
    func deleteTLSArtifacts(pgclusterName, namespace, timeout string) {
      // Delete the TLS artifacts. This will cause new TLS certs to be created,
      // which is necessary for upgrades supporting cert-manager 1.7.
      // See DEPENBDAT-1963
      jobName := fmt.Sprintf("%s-tls-generator", pgclusterName)
      _, err := lifecycle.Kubectl("delete", "--namespace", namespace, "job", jobName, "--ignore-not-found", "true", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to delete TLS generator job: %v", err))
      }
      secretName := fmt.Sprintf("%s-tls-secret", pgclusterName)
      _, err = lifecycle.Kubectl("delete", "--namespace", namespace, "secret", secretName, "--ignore-not-found", "true", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to delete TLS secret: %v", err))
      }
    }
    func waitForRmdataPgtaskDeletion(pgclusterName, namespace, timeout string) {
      // Wait for the postgres operator to remove the pgtask resources
      selector := fmt.Sprintf("pgrmdata,pg-cluster=%s", pgclusterName)
      _, err := lifecycle.Kubectl("wait", "--for", "delete", "pgtasks", "--namespace", namespace, "--selector", selector, "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of Pgtask: %v", err))
      }
    }
    func waitForRemainingPostgresPodDeletion(namespace, timeout string) {
      // Wait for the rest of the crunchy pods to be deleted
      _, err := lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "crunchy-pgha-scope", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of remaining Postgres pods: %v", err))
      }
    }
    func scaleDownCrunchyOperator(namespace, timeout string) {
      // Scale down Crunchy Operator so that, after update is applied, the new
      // Data Server Operator isn't inadvertently communicating with the old
      // Crunchy Operator pod
      _, err := lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "sas-crunchy-data-postgres-operator", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to scale down Crunchy Operator deployment: %v", err))
      }
      // Wait for the Crunchy Operator pod to be deleted
      _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "app.kubernetes.io/name=sas-crunchy-data-postgres-operator", "--timeout", timeout)
      if err != nil {
        panic(fmt.Sprintf("Failed to wait for deletion of Crunchy Operator pod: %v", err))
      }
    }
