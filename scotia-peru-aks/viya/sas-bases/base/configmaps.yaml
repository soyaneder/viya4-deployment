apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: input
literals:
- IMAGE_REGISTRY=cr.sas.com
---
apiVersion: builtin
kind: ConfigMapGenerator
labels:
  orchestration.sas.com/lifecycle: image
options:
  labels:
    orchestration.sas.com/lifecycle: image
metadata:
  name: sas-lifecycle-image
literals:
  - image=cr.sas.com/viya-4-x64_oci_linux_2-docker/sas-orchestration:1.147.1-20251124.1764004273016
  - registry=cr.sas.com
---
apiVersion: builtin
kind: ConfigMapGenerator
labels:
  orchestration.sas.com/lifecycle: operations
options:
  labels:
    orchestration.sas.com/lifecycle: operations
metadata:
  name: sas-lifecycle-operations
literals:
  - |
    assess=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        lifecycle.orchestration.sas.com/publish: "true"
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: assess
    spec:
      args:
      - name: namespace
      - name: manifest
      - default: 7200s
        name: timeout
      steps:
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/assess=true
  - |
    assess-cas=apiVersion: orchestration.sas.com/v2beta12
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/assess: "true"
      name: assess-cas
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - cas.sas.com/operator_manifest_version
        - (.Annotation "sas.com/component-version" $resource)
        cmd: set_variable
        withManifestResources:
          group: apps
          kind: Deployment
          manifest: $manifest
          name: sas-cas-operator
          version: v1
      - args:
        - cas.sas.com/operator_cluster_version
        - (.Annotation "sas.com/component-version" $resource)
        cmd: set_variable
        withClusterResources:
          group: apps
          name: sas-cas-operator
          namespace: $namespace
          resource: deployment
          version: v1
      - args:
        - cas.sas.com/update
        - "true"
        cmd: set_variable
        when: |-
          (and
            (.VariableExists "cas.sas.com/operator_manifest_version" )
            (.VariableExists "cas.sas.com/operator_cluster_version" )
            (ne
              (.GetVariable "cas.sas.com/operator_manifest_version")
              (.GetVariable "cas.sas.com/operator_cluster_version")
            )
          )
      - args:
        - cas.sas.com/server_manifest_version
        - (.Coalesce (index ($resource | .ToObject).data "SAS_COMPONENT_VERSION_sas-cas-server") "")
        cmd: set_variable
        withManifestResources:
          kind: ConfigMap
          labelSelector: orchestration.sas.com/lifecycle=components
          manifest: $manifest
      - args:
        - cas.sas.com/server_cluster_version
        - (.Coalesce (index ($resource | .ToObject).data "SAS_COMPONENT_VERSION_sas-cas-server") "")
        cmd: set_variable
        withClusterResources:
          labelSelector: orchestration.sas.com/lifecycle=components
          namespace: $namespace
          resource: configmap
      - args:
        - cas.sas.com/update
        - "true"
        cmd: set_variable
        when: |-
          (and
            (and
              (.VariableExists "cas.sas.com/server_manifest_version")
              (ne (.GetVariable "cas.sas.com/server_manifest_version") "")
            )
            (and
              (.VariableExists "cas.sas.com/server_cluster_version" )
              (ne (.GetVariable "cas.sas.com/server_cluster_version") "")
            )
            (ne
              (.GetVariable "cas.sas.com/server_manifest_version")
              (.GetVariable "cas.sas.com/server_cluster_version")
            )
          )
      - args:
        - cas.sas.com/commonfiles_manifest_version
        - (.Coalesce (index ($resource | .ToObject).data "SAS_COMPONENT_VERSION_sas-commonfiles") "")
        cmd: set_variable
        withManifestResources:
          kind: ConfigMap
          labelSelector: orchestration.sas.com/lifecycle=components
          manifest: $manifest
      - args:
        - cas.sas.com/commonfiles_cluster_version
        - (.Coalesce (index ($resource | .ToObject).data "SAS_COMPONENT_VERSION_sas-commonfiles") "")
        cmd: set_variable
        withClusterResources:
          labelSelector: orchestration.sas.com/lifecycle=components
          namespace: $namespace
          resource: configmap
      - args:
        - cas.sas.com/update
        - "true"
        cmd: set_variable
        when: |-
          (and
            (and
              (.VariableExists "cas.sas.com/commonfiles_manifest_version")
              (ne (.GetVariable "cas.sas.com/commonfiles_manifest_version") "")
            )
            (and
              (.VariableExists "cas.sas.com/commonfiles_cluster_version" )
              (ne (.GetVariable "cas.sas.com/commonfiles_cluster_version") "")
            )
            (ne
              (.GetVariable "cas.sas.com/commonfiles_manifest_version")
              (.GetVariable "cas.sas.com/commonfiles_cluster_version")
            )
          )
  - |
    cluster-api=apiVersion: orchestration.sas.com/v3beta1
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: cluster-api
    spec:
      args:
      - name: clusterApiManifest
      - name: clusterApiNamespace
      - name: timeout
      source: |-
        package main
        import (
          "fmt"
          "sas/orchestration/lifecycle"
        )
        func main() {
          manifest := lifecycle.Arg("clusterApiManifest")
          namespace := lifecycle.Arg("clusterApiNamespace")
          timeout := lifecycle.Arg("timeout")
          if namespace != "" {
            err := lifecycle.StartLeading(namespace)
            if err != nil {
              fmt.Printf("%v\n", err)
              return
            }
            defer lifecycle.StopLeading(namespace)
          }
          err := lifecycle.Run("cluster-api-assess", "--clusterApiManifest", manifest, "--clusterApiNamespace", namespace, "--timeout", timeout)
          if err != nil {
            fmt.Printf("%v\n", err)
            return
          }
          err = lifecycle.Run("cluster-api-deploy", "--clusterApiManifest", manifest, "--clusterApiNamespace", namespace, "--timeout", timeout)
          if err != nil {
            fmt.Printf("%v\n", err)
            return
          }
        }
  - |
    cluster-api-assess=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: cluster-api-assess
    spec:
      args:
      - name: clusterApiManifest
        required: true
      - name: clusterApiNamespace
      libraries:
      - cluster-api-lib
      source: |-
        package main
        import (
          "fmt"
          "sas/orchestration/lifecycle"
          m "sas/orchestration/lifecycle/manifest"
          c "sas/orchestration/lifecycle/cluster"
          ca "sas/orchestration/lifecycle/cadence"
        )
        func main() {
          manifest := lifecycle.Arg("clusterApiManifest")
          resources, err := m.Resources(manifest, m.Group("apiextensions.k8s.io"), m.Kind("CustomResourceDefinition"), m.LabelSelector("sas.com/admin=cluster-api"))
          if err != nil {
            fmt.Printf("%v\n", err)
            return
          }
          for _, manifestCrd := range resources {
            name := clusterapilib.nameOf(manifestCrd)
            clusterCrd := clusterapilib.getClusterCrd(name)
            validate(manifestCrd, clusterCrd)
          }
        }
        func validate(manifestCrd, clusterCrd *lifecycle.Resource) {
          // If nothing is in the cluster then the update is valid
          if clusterCrd == nil {
            return
          }
          clusterApiNamespace := lifecycle.Arg("clusterApiNamespace")
          manifestCrdConversionStrategy := clusterapilib.conversionStrategyOf(manifestCrd)
          clusterCrdConversionStrategy := clusterapilib.conversionStrategyOf(clusterCrd)
          clusterCrdWebhookNamespace := clusterapilib.webhookNamespaceOf(clusterCrd)
  
          // Calculate if update is "allowed"
          namespace := lifecycle.Arg("clusterApiNamespace")
          kind := clusterapilib.kindOf(clusterCrd)
          name := clusterapilib.nameOf(clusterCrd)
          clusterInfo := clusterapilib.MustGetClusterVersionInfo(namespace, kind, name)
          manifestInfo := clusterapilib.GetManifestVersionInfo(manifestCrd)
          updateError := ca.VerifyUpdateIsAllowed(clusterInfo, manifestInfo)
  
          // If
          // * no clusterApiNamespace is specified
          // * the conversion strategy is webhook
          // * the CRD in the manifest is an update
          // then the update is not valid.
          if clusterApiNamespace == "" &&
            manifestCrdConversionStrategy == "Webhook" && updateError == nil {
            name := clusterapilib.nameOf(manifestCrd)
            lifecycle.Fail(fmt.Sprintf("CRD %s is being updated and requires clusterApiNamespace to be specified", name))
          }
          // If
          // * clusterApiNamespace is specified
          // * the CRD in the cluster has a webhook namespace
          // * the CRD in the manifest has a webhook conversion strategy
          // * the clusterApiNamespace is different than what is already in the CRD in the cluster
          // then the update is not valid.
          if clusterApiNamespace != "" &&
            clusterCrdWebhookNamespace != "" &&
            manifestCrdConversionStrategy == "Webhook" &&
            clusterApiNamespace != clusterCrdWebhookNamespace {
            lifecycle.Fail(fmt.Sprintf("Cluster CRD conversion.webhook.namespace is immutable and currently set to %s", clusterCrdWebhookNamespace))
          }
        }
  - |
    cluster-api-deploy=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: cluster-api-deploy
    spec:
      args:
      - name: clusterApiManifest
        required: true
      - name: clusterApiNamespace
      - default: 2700s
        name: timeout
      libraries:
      - cluster-api-lib
      source: |-
        package main
        import (
          "fmt"
          "encoding/json"
          "sas/orchestration/lifecycle"
          m "sas/orchestration/lifecycle/manifest"
          c "sas/orchestration/lifecycle/cluster"
          ca "sas/orchestration/lifecycle/cadence"
        )
        func main() {
          manifest := lifecycle.Arg("clusterApiManifest")
          resources := m.Resources(manifest, m.LabelSelector("sas.com/admin=cluster-api"))
          for _, resource := range resources {
            kind := clusterapilib.kindOf(resource)
            if kind == "CustomResourceDefinition" {
              deployCrd(resource)
            } else {
              deployWebhook(resource)
            }
          }
        }
        func deployCrd(resource *lifecycle.Resource) {
          namespace := lifecycle.Arg("clusterApiNamespace")
          kind := clusterapilib.kindOf(resource)
          name := clusterapilib.nameOf(resource)
  
          clusterInfo := clusterapilib.MustGetClusterVersionInfo(namespace, kind, name)
          manifestInfo := clusterapilib.GetManifestVersionInfo(resource)
          updateError := ca.VerifyUpdateIsAllowed(clusterInfo, manifestInfo)
  
          if updateError == nil {
            // Incoming crd is newer.  Go ahead and apply
            timeout := lifecycle.Arg("timeout")
            resourceBytes, err := json.Marshal(resource.Value())
            if err != nil {
              panic(err)
            }
            _, err = lifecycle.KubectlWithStdin(string(resourceBytes), "apply", "--timeout", timeout, "--namespace", namespace, "--server-side", "--force-conflicts", "-f", "-")
            if err != nil {
              panic(err)
            }
            _, err = lifecycle.Kubectl("wait", "--for", "condition=established", "--timeout", timeout, "crd", name)
            lifecycle.Log(fmt.Sprintf("The CRD %s will be applied.", name))
          } else {
            lifecycle.Log(fmt.Sprintf("The CRD %s will not be applied. A newer CRD by that name exists in the cluster.", name))
          }
        }
        func deployWebhook(resource *lifecycle.Resource) {
          namespace := lifecycle.Arg("clusterApiNamespace")
          kind := clusterapilib.kindOf(resource)
          name := clusterapilib.nameOf(resource)
          clusterInfo := clusterapilib.MustGetClusterVersionInfo(namespace, kind, name)
          manifestInfo := clusterapilib.GetManifestVersionInfo(resource)
          updateError := ca.VerifyUpdateIsAllowed(clusterInfo, manifestInfo)
  
          if updateError == nil {
            // Incoming webhook is newer.  Go ahead and apply
            timeout := lifecycle.Arg("timeout")
            resourceBytes, err := json.Marshal(resource.Value())
            if err != nil {
              panic(err)
            }
            _, err = lifecycle.KubectlWithStdin(string(resourceBytes), "apply", "--timeout", timeout, "--namespace", namespace, "-f", "-")
            if err != nil {
              panic(err)
            }
            lifecycle.Log(fmt.Sprintf("The webhook %s will be applied.", name))
          } else {
            lifecycle.Log(fmt.Sprintf("The webhook %s will not be applied. A newer webhook by that name exists in the cluster.", name))
          }
        }
  - |
    cluster-api-lib=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: cluster-api-lib
    spec:
      source: |-
        package clusterapilib
        import (
          "fmt"
          "sas/orchestration/lifecycle"
          c "sas/orchestration/lifecycle/cluster"
          ca "sas/orchestration/lifecycle/cadence"
        )
        func getClusterCrd(name string) *lifecycle.Resource {
          clusterCrds := c.Resources(c.Group("apiextensions.k8s.io"), c.Resource("CustomResourceDefinition"), c.Name(name))
          if len(clusterCrds) > 1 {
            panic(fmt.Sprintf("Expected one Resource but got more than one: %v", clusterCrds))
          }
          if len(clusterCrds) == 0 {
            return nil
          }
          return clusterCrds[0]
        }
        func kindOf(o *lifecycle.Resource) string {
          kindI := o.F("kind").Value()
          kind, ok := kindI.(string)
          if !ok {
            panic(fmt.Sprintf("no kind found for resource: %v", o.Value()))
          }
          return kind
        }
        func annotationOf(o *lifecycle.Resource, name string) string {
          annotationI := o.F("metadata").F("annotations").F(name).Value()
          annotation, ok := annotationI.(string)
          if !ok {
            return ""
          }
          return annotation
        }
        func nameOf(o *lifecycle.Resource) string {
          nameI := o.F("metadata").F("name").Value()
          name, ok := nameI.(string)
          if !ok {
            panic(fmt.Sprintf("no name found for resource: %v", o.Value()))
          }
          return name
        }
        func versionsOf(o *lifecycle.Resource) int {
          versionsI := o.F("spec").F("versions").Value()
          versions, ok := versionsI.([]interface{})
          if !ok {
            return 1
          }
          return len(versions)
        }
        func conversionStrategyOf(o *lifecycle.Resource) string {
          conversionStrategyI := o.F("spec").F("conversion").F("strategy").Value()
          conversionStrategy, ok := conversionStrategyI.(string)
          if !ok {
            return "None"
          }
          return conversionStrategy
        }
        func webhookNamespaceOf(o *lifecycle.Resource) string {
          webhookNamespaceI := o.F("spec").F("conversion").F("webhook").F("clientConfig").F("service").F("namespace").Value()
          webhookNamespace, ok := webhookNamespaceI.(string)
          if !ok {
            return ""
          }
          return webhookNamespace
        }
        // *********************************
        // Version check functions
        // *********************************
        func GetManifestVersionInfo(resource *lifecycle.Resource) ca.CadenceInfo {
          return ca.NewCadenceInfoFromAnnotations(resource)
        }
        func MustGetClusterVersionInfo(namespace, kind, name string) ca.CadenceInfo {
          resources, err := c.Resources(c.Namespace(namespace), c.Resource(kind), c.Name(name))
          if err != nil {
            panic(err)
          }
          if len(resources) > 1 {
            panic(fmt.Sprintf("Namespace %s contains multiple webhook resources with name %s", namespace, name))
          }
          if len(resources) == 0 {
             return nil
          }
          return ca.NewCadenceInfoFromAnnotations(resources[0])
        }
  - |
    deploy=apiVersion: orchestration.sas.com/v2beta13
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy
    spec:
      args:
      - name: namespace
        required: true
      - name: manifest
      - name: clusterApiManifest
      - default: 7200s
        name: timeout
      - name: deploymentDir
      - name: serviceAccountName
      - name: clusterApiNamespace
      steps:
      - args:
        - $namespace
        cmd: start_leading
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - configmap
        - sas-deploy-lifecycle-operation-variables
        cmd: kubectl
      - args:
        - create
        - --namespace
        - $namespace
        - configmap
        - sas-deploy-lifecycle-operation-variables
        cmd: kubectl
      - args:
        - deploy-assess
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        - --manifest
        - $manifest
        cmd: run
      - args:
        - cluster-api
        - --timeout
        - $timeout
        - --clusterApiManifest
        - $clusterApiManifest
        - --clusterApiNamespace
        - $clusterApiNamespace
        cmd: run
        when: $clusterApiManifest
      - args:
        - deploy-stage
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        - --manifest
        - $manifest
        cmd: run
      - args:
        - deploy-pre
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        - --manifest
        - $manifest
        cmd: run
      - args:
        - deploy-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        - --manifest
        - $manifest
        cmd: run
      - args:
        - deploy-post
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        - --manifest
        - $manifest
        cmd: run
      - always: true
        args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - configmap
        - sas-deploy-lifecycle-operation-variables
        cmd: kubectl
      - always: true
        args:
        - $namespace
        cmd: stop_leading
  - |
    deploy-assess=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-assess
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      - name: serviceAccountName
      steps:
      - always: true
        args:
        - assess
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/deploy-assess=true
      - always: true
        args:
        - deploy-assess-commonfiles
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - always: true
        args:
        - deploy-assess-consul
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - always: true
        args:
        - deploy-assess-elasticsearch
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - always: true
        args:
        - deploy-assess-rabbitmq
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
  - |
    deploy-assess-commonfiles=apiVersion: orchestration.sas.com/v2beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-commonfiles
        sas.com/component-version: 2.17.23-20250909.1757415529480
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-commonfiles
      name: deploy-assess-commonfiles
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - deploy-assess-commonfiles-execute
        - --namespace
        - $namespace
        cmd: run
        when: |-
          (or
            (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "batch").WithVersion "v1").WithKind "Job").WithName "sas-commonfiles"))
            (.ClusterResource ((((((.NewClusterResourcesIterationSpec).WithNamespace $namespace).WithGroup "batch").WithVersion "v1").WithResource "job").WithName "sas-commonfiles"))
          )
  - |
    deploy-assess-commonfiles-execute=apiVersion: orchestration.sas.com/v2beta5
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-commonfiles
        sas.com/component-version: 2.17.23-20250909.1757415529480
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-commonfiles
      name: deploy-assess-commonfiles-execute
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - annotate
        - --namespace
        - $namespace
        - configmap
        - sas-deploy-lifecycle-operation-variables
        - sas.com/sas-commonfiles-update=true
        cmd: kubectl
  - |
    deploy-assess-crunchy4=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-assess: "true"
      name: deploy-assess-crunchy4
    spec:
      args:
      - name: namespace
        required: true
      source: |-
        package main
        import (
          "fmt"
          "strings"
          "sas/orchestration/lifecycle"
          c "sas/orchestration/lifecycle/cluster"
        )
        func main() {
          namespace := lifecycle.Arg("namespace")
          checkCrunchy4(namespace)
          checkOpenShift()
        }
        func checkCrunchy4(namespace string) {
          opDeployments, err := c.Resources(c.Namespace(namespace), c.Version("v1"), c.Resource("Deployment"), c.Name("sas-crunchy-data-postgres-operator"))
          if err != nil {
            panic(fmt.Sprintf("Failed to get deployments: %v", err))
          }
          if len(opDeployments) > 0 {
            lifecycle.Log("Detected existing deployment as running Crunchy 4")
            lifecycle.SetVariable("dataserver.sas.com/crunchy-v4", "true")
          }
        }
        func checkOpenShift() {
          out, err := lifecycle.Kubectl("api-versions")
          if err != nil {
            panic(fmt.Sprintf("Failed to get api-versions: %v", err))
          }
          if strings.Contains(out, "config.openshift.io") {
            lifecycle.Log("Detected deployment as running on OpenShift")
            lifecycle.SetVariable("dataserver.sas.com/is-openshift", "true")
          }
        }
  - |
    deploy-assess-elasticsearch=apiVersion: orchestration.sas.com/v2beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-opendistro-operator
        sas.com/component-version: 7.52.2-20250911.1757593776425
      creationTimestamp: null
      name: deploy-assess-elasticsearch
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - deploy-assess-elasticsearch-execute
        - --namespace
        - $namespace
        cmd: run
        when: |-
          (and
            (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "apps").WithVersion "v1").WithKind "Deployment").WithName "sas-opendistro-operator"))
            (.ClusterResource ((((((.NewClusterResourcesIterationSpec).WithNamespace $namespace).WithGroup "apps").WithVersion "v1").WithResource "deployment").WithName "sas-opendistro-operator"))
            (ne
              (.Annotation "sas.com/component-version" (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "apps").WithVersion "v1").WithKind "Deployment").WithName "sas-opendistro-operator")))
              (.Annotation "sas.com/component-version" (.ClusterResource ((((((.NewClusterResourcesIterationSpec).WithNamespace $namespace).WithGroup "apps").WithVersion "v1").WithResource "deployment").WithName "sas-opendistro-operator")))
            )
          )
  - |
    deploy-assess-elasticsearch-execute=apiVersion: orchestration.sas.com/v2beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-opendistro-operator
        sas.com/component-version: 7.52.2-20250911.1757593776425
      creationTimestamp: null
      name: deploy-assess-elasticsearch-execute
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - annotate
        - --namespace
        - $namespace
        - configmap
        - sas-deploy-lifecycle-operation-variables
        - sas.com/sas-opendistro-operator-update=true
        cmd: kubectl
  - |
    deploy-assess-pyconfig-cronjob=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
        participate.lifecycle.sas.com/deploy-assess: "true"
      name: deploy-assess-pyconfig-cronjob
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - deploy-assess-pyconfig-execute
        - --namespace
        - $namespace
        cmd: run
        when: (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "batch").WithVersion "v1").WithKind "CronJob").WithName "sas-pyconfig"))
  - |
    deploy-assess-pyconfig-execute=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
      name: deploy-assess-pyconfig-execute
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - annotate
        - --namespace
        - $namespace
        - configmap
        - sas-deploy-lifecycle-operation-variables
        - sas.com/sas-pyconfig-update=true
        - --overwrite
        cmd: kubectl
  - |
    deploy-assess-pyconfig-job=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
        participate.lifecycle.sas.com/deploy-assess: "true"
      name: deploy-assess-pyconfig-job
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - deploy-assess-pyconfig-execute
        - --namespace
        - $namespace
        cmd: run
        when: (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "batch").WithVersion "v1").WithKind "job").WithName "sas-pyconfig"))
  - |
    deploy-execute=apiVersion: orchestration.sas.com/v3beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-execute
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      source: |-
        package main
  
        import (
            "regexp"
            "strconv"
            "encoding/json"
            "fmt"
  
            lifecycle "sas/orchestration/lifecycle"
        )
  
        func main() {
            manifest := lifecycle.Arg("manifest")
            namespace := lifecycle.Arg("namespace")
            timeout := lifecycle.Arg("timeout")
  
            minorVersion := getApiMinorVersion()
            retries := 3
            retryWait := 6
  
            applyClusterWideResources(manifest, timeout, namespace)
            applyClusterLocalResources(manifest, minorVersion, timeout, namespace, retries, retryWait)
            applyNamespaceResources(manifest, minorVersion, timeout, namespace, retries, retryWait)
            pruneIstioResources(manifest, timeout, namespace, retries, retryWait)
        }
  
        // The default prune list in kubernetes 1.18.8 can be found at
        // https://github.com/kubernetes/kubernetes/blob/9f2892aab98fe339f3bd70e3c470144299398ace/staging/src/k8s.io/kubectl/pkg/cmd/apply/prune.go#L172
        // In order to facilitate adding new entries to the prune list without
        // adding new `kubectl apply` executions, those default entries are
        // explicitly listed here.
        // In addition, as versions introduce new GVKs and retire older GVKs, we
        // have to adjust the list to ensure it is doing only those we expect it to.
        func getCommonAllowList(minorVersion uint) []string {
            allowList := []string{
                "core/v1/ConfigMap",
                "core/v1/Endpoints",
                "core/v1/Namespace",
                "core/v1/PersistentVolumeClaim",
                "core/v1/PersistentVolume",
                "core/v1/Pod",
                "core/v1/ReplicationController",
                "core/v1/Secret",
                "core/v1/Service",
                "batch/v1/Job",
                "apps/v1/DaemonSet",
                "apps/v1/Deployment",
                "apps/v1/ReplicaSet",
                "apps/v1/StatefulSet",
            }
  
            // Introductions
            if minorVersion >= 21 {
                allowList = append(allowList, "batch/v1/CronJob")
            }
            if minorVersion >= 22 {
                // This came out in 1.19, but this file's previous logic introduced
                // it in 1.22. Retaining that behavior for backward compatibility.
                allowList = append(allowList, "networking.k8s.io/v1/Ingress")
            }
  
            // Retirements
            if minorVersion < 22 {
                allowList = append(allowList, "extensions/v1beta1/Ingress")
            }
            if minorVersion < 25 {
                allowList = append(allowList, "batch/v1beta1/CronJob")
            }
  
            return allowList
        }
  
        func getApiMinorVersion() uint {
            _, serverVersion, err := lifecycle.KubernetesClientAndServerVersion()
            if err != nil {
                panic(err)
            }
            return serverVersion.Minor()
        }
  
        func hasGroupVersion(gv string) bool {
            versionList, err := lifecycle.Kubectl("api-versions")
            if err != nil {
                panic(err)
            }
            re := regexp.MustCompile(`\b` + gv + `\b`)
            return re.MatchString(versionList)
        }
  
        func applyClusterWideResources(manifest string, timeout string, namespace string) {
            cmdArgs := []string{
                "apply",
                "--timeout", timeout,
                "--namespace", namespace,
                "--selector", "sas.com/admin=cluster-wide",
            }
            cmdArgs = append(cmdArgs, "-f", manifest)
  
            _, err := lifecycle.Kubectl(cmdArgs...)
            if err != nil {
                panic(err)
            }
        }
  
        func applyClusterLocalResources(manifest string, minorVersion uint, timeout string, namespace string, retries int, retryWait int) {
            allowList := getCommonAllowList(minorVersion)
            cmdArgs := []string{
                "apply",
                "--timeout", timeout,
                "--namespace", namespace,
                "--selector", "sas.com/admin=cluster-local",
            }
            cmdArgs = append(cmdArgs, "--prune")
            for _, item := range allowList {
                cmdArgs = append(cmdArgs, "--prune-allowlist", item)
            }
            cmdArgs = append(cmdArgs, "-f", manifest)
  
            _, err := lifecycle.KubectlWithRetry(retries, retryWait, cmdArgs...)
            if err != nil {
                panic(err)
            }
        }
  
        func applyNamespaceResources(manifest string, minorVersion uint, timeout string, namespace string, retries int, retryWait int) {
            allowList := getCommonAllowList(minorVersion)
            allowList = append(allowList, "autoscaling/v2/HorizontalPodAutoscaler")
            if hasGroupVersion("route.openshift.io/v1") {
                allowList = append(allowList, "route.openshift.io/v1/Route")
            }
            cmdArgs := []string{
                "apply",
                "--timeout", timeout,
                "--namespace", namespace,
                "--selector", "sas.com/admin=namespace",
            }
            cmdArgs = append(cmdArgs, "--prune")
            for _, item := range allowList {
                cmdArgs = append(cmdArgs, "--prune-allowlist", item)
            }
            cmdArgs = append(cmdArgs, "-f", manifest)
  
            _, err := lifecycle.KubectlWithRetry(retries, retryWait, cmdArgs...)
            if err != nil {
                panic(err)
            }
        }
  
        func pruneIstioResources(manifest string, timeout string, namespace string, retries int, retryWait int) {
            if !hasGroupVersion("networking.istio.io/v1alpha3") {
                return
            }
            allowList := []string{
                "networking.istio.io/v1alpha3/DestinationRule",
                "networking.istio.io/v1alpha3/VirtualService",
            }
            cmdArgs := []string{
                "apply",
                "--timeout", timeout,
                "--namespace", namespace,
                "--selector", "sas.com/admin=namespace",
            }
            cmdArgs = append(cmdArgs, "--prune")
            for _, item := range allowList {
                cmdArgs = append(cmdArgs, "--prune-allowlist", item)
            }
            cmdArgs = append(cmdArgs, "-f", manifest)
  
            _, err := lifecycle.KubectlWithRetry(retries, retryWait, cmdArgs...)
            if err != nil {
                panic(err)
            }
        }
  - |
    deploy-post=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-post
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      - name: serviceAccountName
      steps:
      - args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/deploy-post=true
  - |
    deploy-post-cas=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-post: "true"
      name: deploy-post-cas
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      steps:
      - args:
        - deploy-post-cas-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        when: (eq (.GetVariable "cas.sas.com/update") "true")
  - |
    deploy-post-cas-execute=apiVersion: orchestration.sas.com/v2beta11
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-post-cas-execute
    spec:
      args:
      - name: namespace
        required: true
      - name: timeout
        required: true
      steps:
      - args:
        - rollout
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - status
        - deployment
        - sas-cas-operator
        cmd: kubectl
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - pods
        - --selector
        - app.kubernetes.io/managed-by=sas-cas-operator,sas.com/cas-auto-restart=true
        cmd: kubectl
      - args:
        - deploy-post-cas-transfer
        - --namespace
        - $namespace
        - --casname
        - $resource.Name
        cmd: run
        withClusterResources:
          currentConfiguration:
            jsonPath: '{.spec.supportStateTransfer}'
            value: '"true"'
          namespace: $namespace
          resource: CASDeployment
  - |
    deploy-post-cas-transfer=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-post-cas-transfer
    spec:
      args:
      - name: namespace
        required: true
      - name: casname
        required: true
      steps:
      - args:
        - Activity on CAS server
        - $casname
        - in namespace
        - $namespace
        - will be transferred to an updated server.
        cmd: log
      - args:
        - patch
        - CASDeployments
        - $casname
        - --namespace
        - $namespace
        - --type=json
        - --patch
        - '[{"op": "add", "path": "/spec/startStateTransfer", "value":true}]'
        cmd: kubectl
  - |
    deploy-post-migrate-analytics-resources-services=apiVersion: orchestration.sas.com/v3beta1
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-analytics-resources
        sas.com/component-version: 22.70.3-20250910.1757545928326
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-post: "true"
      name: deploy-post-migrate-analytics-resources-services
    spec:
      args:
      - name: namespace
      - name: serviceAccountName
      - default: 7200s
        name: timeout
      source: |-
        package main
  
        import (
          "fmt"
          "strings"
          "strconv"
          "time"
          "sas/orchestration/lifecycle"
        )
  
        const (
          AnalyticsResourcesName = "sas-analytics-resources"
          AnalyticsServicesName = "sas-analytics-services"
          AnalyticsGatewayName = "sas-analytics-gateway"
        )
  
        func main() {
  
          namespace := lifecycle.Arg("namespace")
          serviceAccountName := lifecycle.Arg("serviceAccountName")
          timeout := lifecycle.Arg("timeout")
          namespaceBinding := namespace + ":" + serviceAccountName
          serviceAccountNameBlank := len(strings.TrimSpace(serviceAccountName)) == 0
  
          lifecycle.Log("Timeout for kubectl: " + timeout)
  
          if !serviceAccountNameBlank {
            lifecycle.Log("Add role-based access controls (RBAC) for deploy-post-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "role", "deploy-post-migrate-analytics-resources-services")
            lifecycle.Kubectl("create", "--namespace", namespace,  "role", "deploy-post-migrate-analytics-resources-services", "--verb=get,list,watch,patch", "--resource=deployments/scale,horizontalpodautoscalers,pods", "--resource-name", AnalyticsResourcesName, "--resource-name", AnalyticsGatewayName)
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "rolebinding", "deploy-post-migrate-analytics-resources-services")
            lifecycle.Kubectl("create", "--namespace", namespace,  "rolebinding", "deploy-post-migrate-analytics-resources-services",  "--role", "deploy-post-migrate-analytics-resources-services", "--serviceaccount", namespaceBinding)
          } else {
            lifecycle.Log("ServiceAccountName is not defined.. executing with the default user")
          }
  
          restoreHPA(namespace, AnalyticsResourcesName)
          restoreHPA(namespace, AnalyticsGatewayName)
          restoreDeploymentScale(namespace, AnalyticsResourcesName)
          restoreDeploymentScale(namespace, AnalyticsGatewayName)
  
          if !serviceAccountNameBlank {
            lifecycle.Log("Clean up role-based access controls (RBAC) for deploy-post-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "rolebinding", "deploy-post-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "role", "sas-migrate-analytics-resources-services")
          }
        }
  
        func restoreDeploymentScale(namespace string, svcName string) {
          if lifecycle.VariableExists(svcName + "/replicas") {
            replicas := lifecycle.GetVariable(svcName + "/replicas")
            lifecycle.Log(fmt.Sprintf("deployment/%s was scaled to 0 from %d. Restoring replicas..", svcName, replicas))
            lifecycle.Kubectl(
               "scale",
              "--namespace",
               namespace,
               fmt.Sprintf("--replicas=%d", replicas),
               "deployment/" + svcName)
          }
        }
  
        func restoreHPA(namespace string, svcName string) {
            min, max := 0, 0
  
            if svcName == AnalyticsResourcesName {
              min, max = getOriginalHPA(namespace, svcName)
            } else if svcName == AnalyticsGatewayName {
              asMin, asMax := getOriginalHPA(namespace, AnalyticsServicesName)
              agMin, agMax := getOriginalHPA(namespace, AnalyticsGatewayName)
              min = asMin + agMin
              max = asMax + agMax
            }
  
            if max > 0 {
              lifecycle.Log(fmt.Sprintf("Restoring %s HPA to min %d, max %d", svcName, min, max))
              lifecycle.Kubectl("patch", "--namespace", namespace, "hpa", svcName, "--patch", fmt.Sprintf("{\"spec\":{\"minReplicas\":%d, \"maxReplicas\":%d}}", min, max))
            }
        }
  
        func getOriginalHPA(namespace string, svcName string) (int, int) {
          if lifecycle.VariableExists(svcName + "/hpamin") {
            min, minError := strconv.Atoi(lifecycle.GetVariable(svcName + "/hpamin").(string))
            if minError!=nil{
              lifecycle.Log("Error while getting hpamin for service %s in namespace %s with Error %s",svcName,namespace,minError.Error())
              min=0
            }
            max, maxError := strconv.Atoi(lifecycle.GetVariable(svcName + "/hpamax").(string))
            if maxError!=nil{
              lifecycle.Log("Error while getting hpamax for service %s in namespace %s with Error %s",svcName,namespace,maxError.Error())
              max=0
            }
  
            return min, max
          }
          return 0, 0
        }
  - |
    deploy-post-openshift=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-post: "true"
      name: deploy-post-openshift
    spec:
      args:
      - name: namespace
        required: true
      steps:
      - always: true
        args:
        - delete
        - --namespace
        - $namespace
        - --ignore-not-found
        - rolebinding
        - sas-predeploy-openshift-route
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
      - always: true
        args:
        - delete
        - --namespace
        - $namespace
        - --ignore-not-found
        - role
        - sas-predeploy-openshift-route
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
  - |
    deploy-post-pyconfig=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
        participate.lifecycle.sas.com/deploy-post: "true"
      name: deploy-post-pyconfig
    spec:
      args:
      - name: namespace
      - name: manifest
      steps:
      - args:
        - pyconfig-runonce-execute
        - --namespace
        - $namespace
        cmd: run
        when: (.ManifestResource $manifest (((((.NewManifestResourcesIterationSpec).WithGroup "batch").WithVersion "v1").WithKind "CronJob").WithName "sas-pyconfig"))
  - |
    deploy-pre=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-pre
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      - name: serviceAccountName
      steps:
      - args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/deploy-pre=true
      - args:
        - deploy-pre-commonfiles
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - args:
        - deploy-pre-consul
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - args:
        - deploy-pre-elasticsearch
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
      - args:
        - deploy-pre-rabbitmq
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run_when_exists
  - |
    deploy-pre-commonfiles=apiVersion: orchestration.sas.com/v2beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-commonfiles
        sas.com/component-version: 2.17.23-20250909.1757415529480
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-commonfiles
      name: deploy-pre-commonfiles
    spec:
      args:
      - name: namespace
      - name: timeout
      steps:
      - args:
        - deploy-pre-commonfiles-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        when: |-
          (eq
            "true"
            (.Annotation "sas.com/sas-commonfiles-update" (.ClusterResource ((((((.NewClusterResourcesIterationSpec).WithNamespace $namespace).WithGroup "").WithVersion "v1").WithResource "configmap").WithName "sas-deploy-lifecycle-operation-variables")))
          )
  - |
    deploy-pre-commonfiles-execute=apiVersion: orchestration.sas.com/v2beta4
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-commonfiles
        sas.com/component-version: 2.17.23-20250909.1757415529480
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-commonfiles
      name: deploy-pre-commonfiles-execute
    spec:
      args:
      - name: namespace
      - name: timeout
      steps:
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - job
        - sas-commonfiles
        cmd: kubectl
  - |
    deploy-pre-crunchy4=apiVersion: orchestration.sas.com/v2beta11
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-pre: "true"
      name: deploy-pre-crunchy4
    spec:
      args:
      - name: manifest
        required: true
      - name: namespace
        required: true
      - name: timeout
        required: true
      - name: serviceAccountName
      steps:
      - args:
        - deploy-pre-crunchy4-execute
        - --manifest
        - $manifest
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
        when: (.GetVariable "dataserver.sas.com/crunchy-v4")
  - |
    deploy-pre-crunchy4-execute=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      name: deploy-pre-crunchy4-execute
    spec:
      args:
      - name: manifest
      - name: namespace
      - name: timeout
      - name: serviceAccountName
      source: |-
        package main
        import (
          "encoding/json"
          "fmt"
          "sas/orchestration/lifecycle"
          c "sas/orchestration/lifecycle/cluster"
          m "sas/orchestration/lifecycle/manifest"
        )
        func main() {
          manifest := lifecycle.Arg("manifest")
          namespace := lifecycle.Arg("namespace")
          timeout := lifecycle.Arg("timeout")
          serviceAccountName := lifecycle.Arg("serviceAccountName")
          // see ORCHESTRATE-2654 for details on why this is conditionally run
          if len(serviceAccountName) != 0 {
            setupRbac(serviceAccountName, namespace, timeout)
            defer cleanupRbac(serviceAccountName, namespace)
          }
          resources, err := c.Resources(c.Namespace(namespace), c.Group("crunchydata.com"), c.Version("v1"), c.Resource("pgclusters"))
          if err != nil {
            panic(fmt.Sprintf("Failed to get Pgclusters: %v", err))
          }
          scaleDownDataServerOperatorIfExists(namespace, timeout)
          for _, resource := range resources {
            pgclusterNameI := resource.F("metadata").F("name").Value()
            pgclusterName, ok := pgclusterNameI.(string)
            if !ok {
              panic(fmt.Sprintf("Pgcluster didn't have a name"))
            }
            // safely shut down pgcluster
            shutdownPostgres(pgclusterName, namespace, timeout)
            onOpenShift := lifecycle.VariableExists("dataserver.sas.com/is-openshift")
            if !onOpenShift {
              // fix permissions for pgcluster, see DEPENBDAT-2205
              patchBackrestSecurityContext(pgclusterName, namespace, timeout)
              fixBackrestFilePerms(pgclusterName, namespace)
            }
            // delete pgcluster & additional artifacts
            runRmdataPgtask(pgclusterName, namespace, timeout)
            waitForRmdataPgtaskDeletion(pgclusterName, namespace, timeout)
            deleteTLSArtifacts(pgclusterName, namespace, timeout)
            if onOpenShift {
              // fix permissions for pgcluster specific to OpenShift
              fixOpenShiftFilePerms(manifest, pgclusterName, namespace, timeout)
            }
          }
          waitForRemainingPostgresPodDeletion(namespace, timeout)
          scaleDownCrunchyOperator(namespace, timeout)
        }
        func setupRbac(serviceAccountName, namespace, timeout string) {
          serviceAccount := fmt.Sprintf("%s:%s", namespace, serviceAccountName)
          // Clear out and re-create the role for pgclusters
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgclusters")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pgclusters", "--verb", "get,create,update,patch,list", "--resource", "pgclusters.crunchydata.com")
          // Clear out and re-create the role for pgtasks
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgtasks")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pgtasks", "--verb", "get,create,update,patch,list,watch", "--resource", "pgtasks.crunchydata.com")
          // Clear out and re-create the role for pods
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pods", "--verb", "get,list,watch", "--resource", "pods")
          // Clear out and re-create the role for pods/exec
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods-exec")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-pods-exec", "--verb", "get,create", "--resource", "pods/exec")
          // Clear out and re-create the role for deployments
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-deployments")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-deployments", "--verb", "get,patch,list,watch", "--resource", "deployments.apps,deployments.apps/scale")
          // Clear out and re-create the role for jobs
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-jobs")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-jobs", "--verb", "get,delete", "--resource", "jobs.batch")
          // Clear out and re-create the role for secrets
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-secrets")
          lifecycle.Kubectl("create", "--namespace", namespace, "role", "sas-prepare-for-update-crunchy-secrets", "--verb", "get,delete", "--resource", "secrets")
          // Clear out and re-create the rolebinding for pgclusters
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgclusters")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pgclusters", "--role", "sas-prepare-for-update-crunchy-pgclusters", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for pgtasks
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgtasks")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pgtasks", "--role", "sas-prepare-for-update-crunchy-pgtasks", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for pods
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pods", "--role", "sas-prepare-for-update-crunchy-pods", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for pods/exec
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods-exec")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-pods-exec", "--role", "sas-prepare-for-update-crunchy-pods-exec", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for deployments
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-deployments")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-deployments", "--role", "sas-prepare-for-update-crunchy-deployments", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for jobs
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-jobs")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-jobs", "--role", "sas-prepare-for-update-crunchy-jobs", "--serviceaccount", serviceAccount)
          // Clear out and re-create the rolebinding for secrets
          lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-secrets")
          lifecycle.Kubectl("create", "--namespace", namespace, "rolebinding", "sas-prepare-for-update-crunchy-secrets", "--role", "sas-prepare-for-update-crunchy-secrets", "--serviceaccount", serviceAccount)
        }
        func cleanupRbac(serviceAccountName, namespace string) {
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgclusters")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pgtasks")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-configmaps")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-pods-exec")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-deployments")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-jobs")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "rolebinding", "sas-prepare-for-update-crunchy-secrets")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgclusters")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pgtasks")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-configmaps")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-pods-exec")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-deployments")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-jobs")
          lifecycle.Kubectl("delete", "--namespace", namespace, "--ignore-not-found", "role", "sas-prepare-for-update-crunchy-secrets")
        }
        func scaleDownDataServerOperatorIfExists(namespace, timeout string) {
          // Check if the Data Server Operator deployment exists
          resources, err := c.Resources(c.Namespace(namespace), c.Group("apps"), c.Resource("deployments"), c.Name("sas-data-server-operator"))
          if err != nil {
            panic(fmt.Sprintf("Failed to check if Data Server Operator already deployed: %v", err))
          }
          if len(resources) == 0 { // if not found, then there is nothing for us to scale
            return
          }
          // Scale down Data Server Operator so that it doesn't interfere with shutting down Pgclusters
          _, err = lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "sas-data-server-operator", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to scale down Data Server Operator deployment: %v", err))
          }
          // Wait for the Data Server Operator pod to be deleted
          _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "app.kubernetes.io/name=sas-data-server-operator", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of Data Server Operator pod: %v", err))
          }
        }
        // Only intended for non-OpenShift providers
        func patchBackrestSecurityContext(pgclusterName, namespace, timeout string) {
          backrestDeplName := fmt.Sprintf("%s-backrest-shared-repo", pgclusterName)
          _, err := lifecycle.Kubectl("patch", "--namespace", namespace, "deployment", backrestDeplName, "--type", "json", "-p", `[{"op": "replace", "path": "/spec/template/spec/securityContext", "value": { "runAsNonRoot": true, "runAsUser": 2000, "runAsGroup": 26, "fsGroup": 26, "supplementalGroups": [26, 2000]}}]`)
          if err != nil {
            panic(fmt.Sprintf("Failed to patch backrest-shared-repo deployment: %v", err))
          }
          _, err = lifecycle.Kubectl("rollout", "status", "--namespace", namespace, "--timeout", timeout, "deployment", backrestDeplName)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for backrest-shared-repo deployment patch to rollout: %v", err))
          }
        }
        // Only intended for non-OpenShift providers
        func fixBackrestFilePerms(pgclusterName, namespace string) {
          // kubectl exec requires "deployment/<depl_name>", not "deployment <depl_name>"
          backrestDeplExecName := fmt.Sprintf("deployment/%s-backrest-shared-repo", pgclusterName)
          backrestDir := fmt.Sprintf("/backrestrepo/%s-backrest-shared-repo/", pgclusterName)
          retries := 3
          retryInterval := 30
          _, err := lifecycle.KubectlWithRetry(retries, retryInterval, "exec", "--namespace", namespace, backrestDeplExecName, "--", "chmod", "-R", "770", backrestDir)
          if err != nil {
            panic(fmt.Sprintf("Failed to chmod backrest-shared-repo directory: %v", err))
          }
          _, err = lifecycle.KubectlWithRetry(retries, retryInterval, "exec", "--namespace", namespace, backrestDeplExecName, "--", "chgrp", "-R", "postgres", backrestDir)
          if err != nil {
            panic(fmt.Sprintf("Failed to chgrp backrest-shared-repo directory: %v", err))
          }
        }
        func fixOpenShiftFilePerms(manifest, pgclusterName, namespace, timeout string) {
          for step := 1; step <= 3; step++ {
            selector := fmt.Sprintf("webinfdsvr.sas.com/upgrade-crunchy-step-%d=%s", step, pgclusterName)
            resources, err := m.Resources(manifest, m.Kind("Job"), m.LabelSelector(selector))
            if err != nil {
              panic(fmt.Sprintf("Did not find manifest resources with expected label '%s': %v", selector, err))
            }
            if len(resources) != 1 {
              panic(fmt.Sprintf("Expected 1 manifest job resource with label '%s', got %d", selector, len(resources)))
            }
            resourceBytes, err := json.Marshal(resources[0].Value())
            if err != nil {
              panic(err)
            }
            _, err = lifecycle.KubectlWithStdin(string(resourceBytes), "apply", "-f", "-", "--namespace", namespace)
            if err != nil {
              panic(fmt.Sprintf("Failed to apply Crunchy OpenShift upgrade step %d: %v", step, err))
            }
            _, err = lifecycle.Kubectl("wait", "--for", "condition=complete", "job", "--namespace", namespace, "--selector", selector, "--timeout", timeout)
            if err != nil {
              panic(fmt.Sprintf("Failed to wait for Crunchy OpenShift upgrade job to finish: %v", err))
            }
          }
        }
        func shutdownPostgres(pgclusterName, namespace, timeout string) {
          // Scale down postgres replica deployments to re-elect original primary
          replicaSelector := fmt.Sprintf("crunchy-pgha-scope=%s,name!=%s", pgclusterName, pgclusterName)
          _, err := lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "--selector", replicaSelector, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to scale down Postgres replica deployments: %v", err))
          }
          // Wait for replica pods to be deleted
          _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", replicaSelector, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of Postgres replica pods: %v", err))
          }
          // Get the replica deploy names which are the same as the pvc names
          resources, err := c.Resources(c.Namespace(namespace), c.Resource("deployments"), c.LabelSelector(replicaSelector))
          if err != nil {
            panic(fmt.Sprintf("Failed to get replica deployment resources: %v", err))
          }
          for _, resource := range resources {
            deployNameI := resource.F("metadata").F("name").Value()
            deployName, ok := deployNameI.(string)
            if !ok {
              panic("Crunchy Postgres replica deployment didn't have a name")
            }
            // Delete replica PVC
            _, err = lifecycle.Kubectl("delete", "pvc", "--namespace", namespace, deployName, "--ignore-not-found", "true", "--timeout", timeout)
            if err != nil {
              panic(fmt.Sprintf("Failed to delete unused Crunchy Postgres replica PVC: %v", err))
            }
          }
          // Scale down postgres primary deployment
          primarySelector := fmt.Sprintf("crunchy-pgha-scope=%s,name=%s", pgclusterName, pgclusterName)
          _, err = lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "--selector", primarySelector, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to scale down Postgres primary deployment: %v", err))
          }
          // Wait for primary pod to be deleted
          _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", primarySelector, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of Postgres primary pod: %v", err))
          }
          // Delete the pgo-client job if exists. This job is for all pg clusters.
          _, err = lifecycle.Kubectl("delete", "job", "--namespace", namespace, "sas-crunchy-data-pgo-client", "--ignore-not-found", "true", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to delete sas-crunchy-data-pgo-client job: %v", err))
          }
        }
        func runRmdataPgtask(pgclusterName, namespace, timeout string) {
          // Run rmdata pgtask to delete the Crunchy pgcluster. Have to use this approach
          // instead of deleting the pgcluster directly since Crunchy 4.5, used in LTS 2020.1,
          // does not support deletion of the pgcluster CR directly
          pgtask := map[string]interface{}{
            "apiVersion": "crunchydata.com/v1",
            "kind":       "Pgtask",
            "metadata": map[string]interface{}{
              "labels": map[string]interface{}{
                "pg-cluster": pgclusterName,
                "pgrmdata":   "true",
              },
              "name": fmt.Sprintf("%s-rmdata", pgclusterName),
            },
            "spec": map[string]interface{}{
              "name": fmt.Sprintf("%s-rmdata", pgclusterName),
              "parameters": map[string]interface{}{
                "crunchy-pgha-scope": pgclusterName,
                "delete-backups":     "false",
                "delete-data":        "false",
                "is-backup":          "false",
                "is-replica":         "false",
                "pg-cluster":         pgclusterName,
                "replica-name":       "",
              },
              "status": "",
              "storagespec": map[string]interface{}{
                "accessmode":         "",
                "matchLabels":        "",
                "name":               "",
                "size":               "",
                "storageclass":       "",
                "storagetype":        "",
                "supplementalgroups": "",
              },
              "tasktype": "delete-data",
            },
          }
          pgtaskJson, err := json.Marshal(pgtask)
          if err != nil {
            panic(fmt.Sprintf("Failed to marshal Pgtask: %v", err))
          }
          _, err = lifecycle.KubectlWithStdin(string(pgtaskJson), "apply", "-f", "-", "--namespace", namespace, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to run Pgtask to delete Pgcluster: %v", err))
          }
        }
        func deleteTLSArtifacts(pgclusterName, namespace, timeout string) {
          // Delete the TLS artifacts. This will cause new TLS certs to be created,
          // which is necessary for upgrades supporting cert-manager 1.7.
          // See DEPENBDAT-1963
          jobName := fmt.Sprintf("%s-tls-generator", pgclusterName)
          _, err := lifecycle.Kubectl("delete", "--namespace", namespace, "job", jobName, "--ignore-not-found", "true", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to delete TLS generator job: %v", err))
          }
          secretName := fmt.Sprintf("%s-tls-secret", pgclusterName)
          _, err = lifecycle.Kubectl("delete", "--namespace", namespace, "secret", secretName, "--ignore-not-found", "true", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to delete TLS secret: %v", err))
          }
        }
        func waitForRmdataPgtaskDeletion(pgclusterName, namespace, timeout string) {
          // Wait for the postgres operator to remove the pgtask resources
          selector := fmt.Sprintf("pgrmdata,pg-cluster=%s", pgclusterName)
          _, err := lifecycle.Kubectl("wait", "--for", "delete", "pgtasks", "--namespace", namespace, "--selector", selector, "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of Pgtask: %v", err))
          }
        }
        func waitForRemainingPostgresPodDeletion(namespace, timeout string) {
          // Wait for the rest of the crunchy pods to be deleted
          _, err := lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "crunchy-pgha-scope", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of remaining Postgres pods: %v", err))
          }
        }
        func scaleDownCrunchyOperator(namespace, timeout string) {
          // Scale down Crunchy Operator so that, after update is applied, the new
          // Data Server Operator isn't inadvertently communicating with the old
          // Crunchy Operator pod
          _, err := lifecycle.Kubectl("scale", "deployments", "--namespace", namespace, "--replicas", "0", "sas-crunchy-data-postgres-operator", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to scale down Crunchy Operator deployment: %v", err))
          }
          // Wait for the Crunchy Operator pod to be deleted
          _, err = lifecycle.Kubectl("wait", "--for", "delete", "pods", "--namespace", namespace, "--selector", "app.kubernetes.io/name=sas-crunchy-data-postgres-operator", "--timeout", timeout)
          if err != nil {
            panic(fmt.Sprintf("Failed to wait for deletion of Crunchy Operator pod: %v", err))
          }
        }
  - |
    deploy-pre-crunchy5=apiVersion: orchestration.sas.com/v3beta1
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-pre: "true"
      name: deploy-pre-crunchy5
    spec:
      args:
      - name: namespace
        required: true
      - name: timeout
        required: true
      - name: manifest
        required: true
      - name: serviceAccountName
      source: "package main\n\nimport (\n  \"fmt\"\n  \"sas/orchestration/lifecycle\"\n  c \"sas/orchestration/lifecycle/cluster\"\n  m \"sas/orchestration/lifecycle/manifest\"\n  \"strconv\"\n  \"strings\"\n  \"time\"\n)\n\nfunc main() {\n  namespace := lifecycle.Arg(\"namespace\")\n  timeout := lifecycle.Arg(\"timeout\")\n  manifest := lifecycle.Arg(\"manifest\")\n  serviceAccountName := lifecycle.Arg(\"serviceAccountName\")\n  pgo_fqdn := \"postgres-operator.crunchydata.com\"\n  pgo_label := fmt.Sprintf(\"%s/control-plane=postgres-operator\", pgo_fqdn)\n  fromPostgresVersion := \"12\" //Upgrade 'from' & 'to' versions should match with PGUpgrade CR 'fromPostgresVersion:' & 'toPostgresVersion:'.\n  toPostgresVersion := \"16\"   //The automated manual script 'postgres-upgrade.sh' also has these hard-coded versions which must match with each other.\n  var permissionsNeeded bool\n  if serviceAccountName == \"\" {\n    lifecycle.Log(\"ServiceAccount does not exist. Permissions to add pod/exec to sas-deployment-operator-reconcile-permissions role is not needed.\")\n    permissionsNeeded = false\n  } else {\n    lifecycle.Log(\"ServiceAccount exists. Permissions to add pod/exec to sas-deployment-operator-reconcile-permissions role are needed.\")\n    permissionsNeeded = true\n  }\n\n  //Operations to execute a postgres 12 to 16 upgrade, the \"f_*\" comments corresponds to the corresponding bash script to upgrade postgres as well\n  //Do Postgres Version Checks and get postgrescluster list\n  postgresClusters, upgrade, err := isUpgradeNeeded(namespace, fromPostgresVersion, toPostgresVersion, pgo_fqdn, manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: getting isUpgradeNeeded %v\", err))\n  }\n  lifecycle.Log(fmt.Sprintf(\"Upgrade is of value: %t\", upgrade))\n  if upgrade == false {\n    lifecycle.Log(\"Postgres Version Upgrade is not needed!\")\n    return\n  }\n  lifecycle.Log(fmt.Sprintf(\"Postgres Version checks, proceeding with upgrade from postgres version %s -> %s\", fromPostgresVersion, toPostgresVersion))\n\n  // f_shutdown_dso\n  lifecycle.Log(\"Scaling Down Data Server Operator if exists\")\n  scaleDownDataServerOperatorIfExists(namespace, timeout)\n\n  //f_drop_replicas\n  lifecycle.Log(\"Scale Down Postgres Replicas\")\n  scaleDownPostgresReplicas(namespace, postgresClusters, pgo_fqdn, timeout)\n\n  //f_check_checksums\n  lifecycle.Log(\"Checking Checksums on Postgres\")\n  applyCheckSum(namespace, postgresClusters, pgo_fqdn, permissionsNeeded, timeout)\n\n  //f_apply_crd\n  lifecycle.Log(fmt.Sprintf(\"Applying Postgres %s CRDs\", toPostgresVersion))\n  applyCrunchyCRDs(namespace, pgo_label, manifest, timeout)\n\n  //f_apply_pgo\n  lifecycle.Log(\"Applying PostgresOperator\")\n  applyPostgresOperator(namespace, postgresClusters, pgo_fqdn, pgo_label, manifest, timeout)\n\n  //f_delete_pgupgrade_cr_annotation\n  lifecycle.Log(\"Deleteing PGUpgradeCR and Annotation if exists\")\n  deletePGupgradeCRAnnotation(namespace, postgresClusters)\n\n  //f_create_pgupgrade_cr\n  lifecycle.Log(\"Creating PostgresUpgrade CR\")\n  createPosgresUpgradeCR(namespace, manifest)\n\n  //f_shutdown_pgcluster\n  lifecycle.Log(\"Shutting down PostgresCluster\")\n  shutdownPostgresCluster(namespace, postgresClusters, pgo_fqdn)\n\n  //f_annotate_pgupgrade\n  lifecycle.Log(\"Annotate pgupgrade\")\n  annotatePostgresUpgrade(namespace, postgresClusters, pgo_fqdn)\n\n  //f_wait_pgupgrade\n  lifecycle.Log(\"Wait for postgres upgrade job\")\n  waitPostgresUpgrade(namespace, postgresClusters, pgo_fqdn, \"7200s\")\n\n  //f_check_pgupgrade_status\n  lifecycle.Log(\"Check PostgresUpgrade Status\")\n  checkPostgresUpgradeStatus(namespace, postgresClusters)\n\n  //f_start_pgcluster\n  lifecycle.Log(\"Start PostgresCluster\")\n  startPostgresCluster(namespace, postgresClusters, pgo_fqdn, manifest)\n\n  //f_check_pgversion\n  assertPostgresVersion(namespace, postgresClusters, toPostgresVersion, pgo_fqdn)\n\n  lifecycle.Log(\"Start DataServer Operator\")\n  startDataServerOperator(namespace, timeout)\n\n  err, removePermissions := executePostUpgradeTasks(namespace, permissionsNeeded, serviceAccountName, postgresClusters, pgo_fqdn)\n  if err != nil && removePermissions {\n    toggleDeploymentPermissions(namespace, false)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err)\n      return\n    }\n  }\n}\n\nfunc isUpgradeNeeded(namespace string, fromPostgresVersion string, toPostgresVersion string, pgo_fqdn string, manifest string) ([]string, bool, error) {\n  var postgresClusters []string\n  postgresApiResources, err := lifecycle.Kubectl(\"api-resources\", \"--api-group\", \"postgres-operator.crunchydata.com\", \"--no-headers\")\n  lifecycle.Log(\"postgresApiResources error: %s\", postgresApiResources)\n  if err != nil {\n    return postgresClusters, false, fmt.Errorf(\"ERROR: finding postgres-operator.crunchydata.com %v\", err)\n  }\n  if !strings.Contains(postgresApiResources, \"postgresclusters\") {\n    lifecycle.Log(\"Cannot find postgresclusters crd\")\n    return postgresClusters, false, nil\n  }\n  isInternal := isInternal(namespace, manifest)\n  if !isInternal {\n    return postgresClusters, false, nil\n  }\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"))\n  if err != nil {\n    //error getting postgresclusters\n    panic(fmt.Sprintf(\"Failed to get postgrescluster: %v\", err))\n  }\n  for _, resource := range resources {\n    postgresclusterNameI := resource.F(\"metadata\").F(\"name\").Value()\n    postgrescluster, ok := postgresclusterNameI.(string)\n    if !ok {\n      panic(fmt.Sprintf(\"PostgresCluster didn't have a name\"))\n    }\n    postgresClusters = append(postgresClusters, postgrescluster)\n  }\n\n  if fromPostgresVersion == \"\" || toPostgresVersion == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Postgres versions missing\"))\n  }\n\n  if len(postgresClusters) == 0 {\n    return postgresClusters, false, nil\n  }\n\n  clusterCount := len(postgresClusters)\n  atFromVersionCount := 0\n  atToVersionCount := 0\n\n  for _, postgrescluster := range postgresClusters {\n    postgresVersion, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"postgrescluster\", postgrescluster, \"-o\", \"jsonpath={.spec.postgresVersion}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: trying to retrive postgresVersion for %s cluster: %v\", postgrescluster, err))\n    }\n    if postgresVersion == fromPostgresVersion {\n      atFromVersionCount += 1\n      lifecycle.Log(fmt.Sprintf(\"PostgresCluster %s is at version %s and needs to be upgraded\", postgrescluster, fromPostgresVersion))\n    } else if postgresVersion == toPostgresVersion {\n      atToVersionCount += 1\n      lifecycle.Log(fmt.Sprintf(\"PostgresCluster %s is already at version %s and does not upgrade\", postgrescluster, toPostgresVersion))\n    } else {\n      panic(fmt.Sprintf(\"ERROR: postgresVersion of %s cluster is an unexpected one %s\", postgrescluster, postgresVersion))\n    }\n  } // end of postgresCluster for loop\n\n  if atFromVersionCount == clusterCount {\n    return postgresClusters, true, nil\n  }\n\n  if atToVersionCount == clusterCount {\n    return postgresClusters, false, nil\n  }\n  panic(fmt.Sprintf(\"ERROR: postgrescluster versions do not align\"))\n}\n\n// Checks to see if the deployment operator\nfunc isInternal(namespace string, manifest string) bool {\n  selector := fmt.Sprintf(\"postgres-operator.crunchydata.com/control-plane=postgres-operator\")\n  resources, err := m.Resources(manifest, m.Kind(\"Deployment\"), m.LabelSelector(selector))\n  if err != nil {\n    fmt.Printf(\"Did not find manifest resources with expected label '%s': %v\", \"Indicating this is external postgres deployment, do not upgrade\", selector, err)\n    return false\n  }\n  if len(resources) != 0 {\n    fmt.Printf(\"Found postgres operator deployment in manifest, indicating that this is a internal postgres deployment, proceed with upgrade.\")\n    return true\n  } else {\n    fmt.Printf(\"Did not find manifest resources with expected label '%s'.\", \"Indicating this is external postgres deployment, do not upgrade\", selector)\n    return false\n  }\n}\n\nfunc deletePGupgradeCRAnnotation(namespace string, postgresClusters []string) {\n  lifecycle.Log(\"Deleting PGUpgrade CustomResources if exists...\")\n  //Delete all pgupgrade CRs.\n  //The command always returns the return code 0. If CR doesn't exists, it displays 'No resources found'.\n  lifecycle.Kubectl(\"--namespace\", namespace, \"delete\", \"pgupgrade\", \"--all\")\n  //Delete annotations by suffixing (-) to the annotations.\n  //The command always displays '...annotated', and alwyas returns the return code 0 regardless that the annotation exists or not.\n  lifecycle.Log(\"Deleting annotations if exist\")\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Kubectl(\"--namespace\", namespace, \"annotate\", \"postgrescluster\", postgrescluster, \"postgres-operator.crunchydata.com/allow-upgrade-\")\n  }\n}\n\nfunc assertPostgresVersion(namespace string, postgresClusters []string, expectedPostgresVersion string, pgo_fqdn string) {\n  if expectedPostgresVersion == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Desired Postgres Version is not defined\"))\n  }\n  for _, postgrescluster := range postgresClusters {\n    postgresVersion, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"postgrescluster\", postgrescluster, \"-o\", \"jsonpath={.spec.postgresVersion}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: checking final postgresVersion on %s cluster\", postgrescluster))\n    }\n    if postgresVersion != expectedPostgresVersion {\n      panic(fmt.Sprintf(\"ERROR: Error postgresVersion of %s cluster does not match the expected PostgresVersion %s\", postgrescluster, expectedPostgresVersion))\n    }\n  }\n}\n\nfunc getPostgreClusterList(namespace string) ([]string, error) {\n  var postgresClusters []string\n  postgresApiResources, err := lifecycle.Kubectl(\"api-resources\", \"--api-group\", \"postgres-operator.crunchydata.com\", \"--no-headers\")\n  lifecycle.Log(\"postgresApiResources error: %s\", postgresApiResources)\n  if err != nil {\n    return postgresClusters, fmt.Errorf(\"ERROR: finding postgres-operator.crunchydata.com %v\", err)\n  }\n  if !strings.Contains(postgresApiResources, \"postgresclusters\") {\n    lifecycle.Log(\"Cannot find postgresclusters crd\")\n    return postgresClusters, nil\n  }\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"))\n  if err != nil {\n    //error getting postgresclusters\n    panic(fmt.Sprintf(\"Failed to get postgrescluster: %v\", err))\n  }\n  for _, resource := range resources {\n    postgresclusterNameI := resource.F(\"metadata\").F(\"name\").Value()\n    postgrescluster, ok := postgresclusterNameI.(string)\n    if !ok {\n      panic(fmt.Sprintf(\"PostgresCluster didn't have a name\"))\n    }\n    postgresClusters = append(postgresClusters, postgrescluster)\n  }\n  return postgresClusters, nil\n}\n\nfunc scaleDownDataServerOperatorIfExists(namespace, timeout string) {\n  // Check if the Data Server Operator deployment exists\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"deployments\"), c.Name(\"sas-data-server-operator\"))\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to check if Data Server Operator already deployed: %v\", err))\n  }\n\n  if len(resources) != 0 {\n    selector := \"app.kubernetes.io/name=sas-data-server-operator\"\n    // Scale down Data Server Operator so that it doesn't interfere with shutting down postgrescluster\n    _, err := lifecycle.Kubectl(\"scale\", \"deploy\", \"--namespace\", namespace, \"--replicas=0\", \"sas-data-server-operator\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to scale down Data Server Operator deployment: %v\", err))\n    }\n    // Wait for the Data Server Operator pod to be deleted\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"delete\", \"pods\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for deletion of Data Server Operator pod: %v\", err))\n    }\n  }\n}\n\nfunc scaleDownPostgresReplicas(namespace string, postgresClusters []string, pgo_fqdn string, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n    fmt.Printf(\"scaleDownPostgresReplicas: postgrescluster %s\", postgrescluster)\n    selector := fmt.Sprintf(\"%s/role=replica,%s/cluster=%s\", pgo_fqdn, pgo_fqdn, postgrescluster)\n    resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"), c.Name(postgrescluster))\n    if err != nil && resources != nil {\n      panic(fmt.Sprintf(\"Could not find postgrescluster cr: %v\", err))\n    }\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"json\", \"-p\", `[{\"op\": \"replace\", \"path\": \"/spec/instances/0/replicas\", \"value\": 1}]`)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to scale down PostgresCluster: %v\", err))\n    }\n\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"delete\", \"pods\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for deletion of postgres pods: %v\", err))\n    }\n  }\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\nfunc getChecksum(namespace string, primary_pod string) (error, string) {\n  output, err := lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"psql\", \"-t\", \"-A\", \"-c\", \"show data_checksums\")\n  if err != nil {\n    return fmt.Errorf(\"ERROR: Failed to show data_checksums: %v\", err), \"\"\n  }\n  //remove whitespace/new line\n  output = strings.TrimSpace(output)\n  lifecycle.Log(fmt.Sprintf(\"Data_checksums is currently: %s \", output))\n  return nil, output\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\n// false == stopped, true == running\nfunc getPostgresStatus(namespace string, primary_pod string, postgrescluster string, desiredState string) (error, string) {\n  // Check the Postgres processes\n  command := fmt.Sprintf(\"ps xf | grep %s | grep -v grep | wc -l\", postgrescluster)\n  output, err := lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n  if err != nil {\n    return fmt.Errorf(\"ERROR: Failed to check the Postgres processes: %v\", err), \"Error\"\n  }\n  //Output comes as type string, convert to number\n  result := strings.TrimSpace(string(output))\n  count, err := strconv.Atoi(result)\n  if err != nil {\n    return fmt.Errorf(\"Error converting output to a number: %v\", err), \"Error\"\n  }\n\n  lifecycle.Log(fmt.Sprintf(\"The number of processes is: %d\\n\", count))\n  // If start case\n  //if number of processes >= 5 then return\n  //if number of processes < 5 then wait for certain amount of time and then check again\n  if desiredState == \"started\" {\n    if count >= 5 {\n      lifecycle.Log(\"Postgres process is running\")\n      return nil, \"started\"\n    } else {\n      lifecycle.Log(\"Postgres Process has not started yet\")\n      return nil, \"starting\"\n    }\n    //If stop case\n    // if number of processes == 0 then return\n    // if number of processes != 0 then wait for certain amount of time and then check again\n  } else if desiredState == \"stopped\" {\n    if count == 0 {\n      lifecycle.Log(\"Postgres process is stopped\")\n      return nil, \"stopped\"\n    } else {\n      lifecycle.Log(\"Postgres Process is still running\")\n      return nil, \"stopping\"\n    }\n  } else {\n    return fmt.Errorf(\"ERROR: Incorrect desired state, state must be started or Stopped\"), \"Error\"\n  }\n\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\nfunc waitForPostgres(namespace string, primary_pod string, postgresCluster string, desiredState string) error {\n  maxWait := 180 * time.Second //Maximum wait time in seconds\n  interval := 5 * time.Second  //Interval between checks in seconds\n  totalWait := 0 * time.Second\n  fmt.Printf(\"Checking postgres process for %s with the primary pod %s\", postgresCluster, primary_pod)\n  for {\n    if totalWait > maxWait {\n      return fmt.Errorf(\"Timed out waiting for postgres process for %s with the primary pod %s. Max wait time %v\", postgresCluster, primary_pod, maxWait)\n    }\n    //Check if the PG processes exist\n    err, status := getPostgresStatus(namespace, primary_pod, postgresCluster, desiredState)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: error getting the postgress process count %v\", err)\n    }\n    if status == desiredState {\n      fmt.Printf(\"Postgres process is in desired state %v after %v seconds\", desiredState, totalWait)\n      return nil\n    }\n    fmt.Printf(\"Total Wait: %s, sleeping for %s\", totalWait, interval)\n    time.Sleep(interval)\n    totalWait = totalWait + interval\n\n  }\n\n}\n\n// This is complicated function. The overall flow is to add pod/exec permissions for the Orchestration Deployment Operator Scenario.\n// We check the checksum status, which results in 3 different scenarios (\"on\"|\"off\"|unkown). The \"off\" scenario is the only scenario in which we take action.\n// After each scenario, we remove the pod/exec permissions from the service account\nfunc applyCheckSum(namespace string, postgresClusters []string, pgo_fqdn string, permissionsNeeded bool, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n\n    //Get the primary pod\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Failed to find primary postgres pod: %v\", err))\n    }\n\n    //Apply permissions to add permissions to exec into pods\n    //From this point on, we will not panic even if there is an error (with the exception of failing to add/remove the pod/exec permissions).\n    //This is necessary to not leave Postgres in a broken state and to remove the pod/exec permissions\n    if permissionsNeeded {\n      err := toggleDeploymentPermissions(namespace, true)\n      if err != nil {\n        panic(fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err))\n      }\n    }\n\n    err, status := getChecksum(namespace, primary_pod)\n    if err != nil {\n      lifecycle.Log(fmt.Sprintf(\"ERROR: getting checksum status: %v\", err))\n    }\n    lifecycle.Log(fmt.Sprintf(\"Current Checksum Status: %s\", status))\n\n    //Status is on, no need to do anything\n    if status == \"on\" {\n      lifecycle.Log(fmt.Sprintf(\"Data_checksums is %s, no further action required\", status))\n      //Remove pod/exec permissions and return\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err))\n        }\n      }\n\n      //Status is off, need to do a lot of stuff to enable checksum\n      //If there is an error that occurs during these operations we will flip enableChecksumSuccessful to false and at the end of this function, return error out and terminate the upgrade\n      //It is important that if an error occurs, all the steps to resume postgres functionality still runs in order to not leave postgres in a broken state.\n      //Do not return in order to remove the pod/exec priveledges in the Orchestration deploy scenario\n    } else if status == \"off\" {\n      lifecycle.Log(fmt.Sprintf(\"Updating cluster %s to enable checksum on the primary pod %s\", postgrescluster, primary_pod))\n      //Temporarily pause the cluster management of Crunchy Operator (PGO)\n      _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"merge\", \"--patch\", `{\"spec\":{\"paused\": true}}`)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to pause PGO: %v\", err))\n      }\n\n      //Temporarily pause patroni operations\n      enableChecksumSuccessful := false\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"pause\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to pause Patroni: %v\", err))\n      } else {\n        // Stop the Postgres processes\n        command := fmt.Sprintf(\"pg_ctl stop -D /pgdata/pg12 -m fast\")\n        _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n        if err != nil {\n          lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to stop the Postgres processes: %v\", err))\n        } else {\n          lifecycle.Log(\"Waiting for Postgres to be stopped\")\n          err = waitForPostgres(namespace, primary_pod, postgrescluster, \"stopped\")\n          if err != nil {\n            lifecycle.Log(fmt.Sprintf(\"ERROR: error waiting for postgres to stop\"))\n          } else {\n            //Helpful to just give it a bit more time to shutdown\n            time.Sleep(5 * time.Second)\n            // Run pg_checksums binary\n            command = fmt.Sprintf(`logFile=\"/pgdata/pg_up_09_chksum_enable.log\"; pg_checksums --enable --pgdata /pgdata/pg12 --progress --verbose >> $logFile 2>&1;`)\n            _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n            if err != nil {\n              lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to enable checksum: %v\", err))\n            } else {\n              //The following commands above all ran successfully, thus indicating that the data_checksums was turned on.\n              lifecycle.Log(\"Enabling data_checksums was successful\")\n              enableChecksumSuccessful = true\n            }\n          }\n        }\n      }\n\n      // Try reversing the temp 'pause' whether there was an error or not. Do not return on error of the commands to continue reversing.\n      // Resume patroni operations. This starts the Postgres process.\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"resume\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to Resume patroni operations: %v\", err))\n      }\n      lifecycle.Log(\"Waiting for Postgres to be started\")\n      err = waitForPostgres(namespace, primary_pod, postgrescluster, \"started\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: error occurred waiting for postgres to start\"))\n      }\n      //Helpful to just give it a bit more time to start up\n      time.Sleep(5 * time.Second)\n\n      // Check the Postgres cluster status\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"list\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to check the Postgres cluster status: %v\", err))\n      }\n\n      //Check if the PG checksum setting is \"on\"\n      err, status := getChecksum(namespace, primary_pod)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: getting checksum status: %v\", err))\n      }\n      lifecycle.Log(fmt.Sprintf(\"Resulting checksum setting is: %s\", status))\n\n      // Resume the cluster management of Crunchy Operator\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"merge\", \"--patch\", `{\"spec\":{\"paused\": false}}`)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to resume PGO: %v\", err))\n      }\n\n      //Remove permissions to exec into pods\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Sprintf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err))\n        }\n      }\n      if enableChecksumSuccessful && status == \"on\" {\n        lifecycle.Log(fmt.Sprintf(\"Data_checksums is %s. Successfully turned on checksum\", status))\n      } else {\n        panic(fmt.Sprintf(\"ERROR: Data_checksums is %s. Failed to turn on checksum panicing and exiting the upgrade\", status))\n      }\n\n      //Uknown case, neither \"on\"or \"off\" scenario\n    } else {\n      //Remove permissions to exec into pods\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Sprintf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err))\n        }\n      }\n        panic(fmt.Sprintf(\"ERROR: Checksum status is not 'on' nor 'off': %s. Postgres may be down. Postgres Upgrade cannot be proceeded\", status))\n    }\n  }\n}\nfunc applyCrunchyCRDs(namespace string, pgo_label string, manifest string, timeout string) {\n  lifecycle.Log(\"Applying Crunchy CRDs...\")\n  selector := fmt.Sprintf(\"sas.com/admin=cluster-api,%s\", pgo_label)\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", selector, \"-f\", manifest, \"--server-side\", \"--force-conflicts\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Could not apply CrunchyCRD %v\", err))\n  }\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(10 * time.Second)\n  _, err = lifecycle.Kubectl(\"wait\", \"crd\", \"--for\", \"condition=established\", \"--selector\", selector, \"--timeout\", timeout)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Crunchy CRDs failed to be applied %v\", err))\n  }\n\n  //Check if crds are found\n  crd, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"crd\", \"--selector\", selector, \"-o\", \"jsonpath='{.items[*].metadata.name}'\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Could not find Crunchy CRDs %v\", err))\n  }\n  lifecycle.Log(\"Found Crunchy CRDs %s\", crd)\n}\n\nfunc applyPostgresOperator(namespace string, postgresClusters []string, pgo_fqdn string, pgo_label string, manifest string, timeout string) {\n  lifecycle.Log(\"Applying Crunchy Postgres Operator...\")\n  clusterWideSelector := fmt.Sprintf(\"sas.com/admin=cluster-wide,%s\", pgo_label)\n  namespaceSelector := fmt.Sprintf(\"sas.com/admin=namespace,%s\", pgo_label)\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", clusterWideSelector, \"-f\", manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"serviceaccount\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get serviceaccount %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"role\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get role %v\", err))\n  }\n\n  //Creates rolebinding.rbac.authorization.k8s.io/postgres-operator\n  _, err = lifecycle.Kubectl(\"apply\", \"--selector\", fmt.Sprintf(\"sas.com/admin=cluster-local,%s\", pgo_label), \"-f\", manifest, \"--prune\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"rolebinding\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get rolebinding %v\", err))\n  }\n\n  // Creates deployment.apps/sas-crunchy5-postgres-operator\n  _, err = lifecycle.Kubectl(\"apply\", \"--selector\", namespaceSelector, \"-f\", manifest, \"--prune\", \"--prune-allowlist=autoscaling/v2/HorizontalPodAutoscaler\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  pgo_deploy, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"deploy\", \"--selector\", namespaceSelector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pgo_deploy == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed get pgo deployment %v\", err))\n  }\n\n  lifecycle.Log(\"Found PGO Deployment %s\", pgo_deploy)\n\n  // Sleep before starting to wait for pgo rollout. It is to work around the potential kubectl wait issue\n  time.Sleep(10 * time.Second)\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"rollout\", \"status\", fmt.Sprintf(\"deployment/%s\", pgo_deploy), \"--timeout\", \"600s\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to get deployment rollout status %v\", err))\n  }\n\n  lifecycle.Log(\"Waiting for pgclusters to be restarted after PGO is rolled out...\")\n  maxTry := len(postgresClusters)*2 + 1\n  for i := 0; i <= maxTry; i++ {\n    fmt.Printf(\"Wait loop: %v/%v\", i, maxTry)\n    time.Sleep(10 * time.Second)\n\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for\", \"condition=ready\", \"--selector\", fmt.Sprintf(\"%s/cluster,%s/data\", pgo_fqdn, pgo_fqdn), \"--timeout\", \"600s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Error occurred checking the condition of postgrescluster restarts %v\", err))\n    }\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"condition=ready\", \"pods\", \"--selector\", fmt.Sprintf(\"%s/cluster,%s/data\", pgo_fqdn, pgo_fqdn), \"--timeout\", \"600s\")\n  if err != nil {\n    fmt.Errorf(\"Kubectl wait for pgo pods to be ready failed\")\n  }\n\n  pgo_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pod\", \"--selector\", pgo_label, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pgo_pod == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed to get pgo pod %v\", err))\n  }\n  lifecycle.Log(\"PGO Pod is found! %s\", pgo_pod)\n}\n\nfunc createPosgresUpgradeCR(namespace string, manifest string) {\n  fmt.Printf(\"Create PGUpgrade CRs...\")\n  _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"apply\", \"-f\", manifest, \"--selector\", \"sas.com/pgupgrade-cr\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply PostgresUgrade CR %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed pgupgrade CR %v\", err))\n  }\n\n  //Check if pgupgrade CRs are found\n  pg_upgrade, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pg_upgrade == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed to get pgo pod %v\", err))\n  }\n  lifecycle.Log(\"pgupgrade found %s\", pg_upgrade)\n}\n\nfunc shutdownPostgresCluster(namespace string, postgresClusters []string, pgo_fqdn string) {\n  for _, postgrescluster := range postgresClusters {\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/data\", pgo_fqdn, postgrescluster, pgo_fqdn)\n    lifecycle.Log(\"Shutting down the cluster, %s\", postgrescluster)\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"json\", \"-p\", `[{\"op\": \"replace\", \"path\": \"/spec/shutdown\", \"value\": true}]`)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to shutdown postgrescluster: %v\", err))\n    }\n\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for=delete\", \"--selector\", selector, \"--timeout\", \"600s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres cluster to be shutdown %v\", err))\n    }\n\n    //Check if all PG pods are deleted. Note: If selector is used, it always returns 0.\n    pg_pods, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pod\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || pg_pods == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Postgres pods are left undeleted %v\", err))\n    }\n  }\n}\n\nfunc annotatePostgresUpgrade(namespace string, postgresClusters []string, pgo_fqdn string) {\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Annotate for the upgrade of %s\", postgrescluster)\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"annotate\", \"postgrescluster\", postgrescluster, fmt.Sprintf(\"%s/allow-upgrade=%s-upgrade\", pgo_fqdn, postgrescluster))\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to annotate postgres upgrade %v\", err))\n    }\n  }\n}\n\nfunc waitPostgresUpgrade(namespace string, postgresClusters []string, pgo_fqdn string, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Waiting for the %s pgupgrade job to finish...\", postgrescluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/pgupgrade=%s-upgrade\", pgo_fqdn, postgrescluster, pgo_fqdn, postgrescluster)\n\n    waitObjectCreated(namespace, \"job\", selector)\n    //Check if the object exists, and if not, then wait for it to be created\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", \"--selector\", selector)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get postgres upgrade job %v\", err))\n    }\n\n    //Dump upgrade job logs\n    lifecycle.Log(\"============================get yaml output========================\")\n    lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", fmt.Sprintf(\"%s-upgrade\", postgrescluster), \"-o\", \"yaml\")\n    lifecycle.Log(\"============================describe output========================\")\n    lifecycle.Kubectl(\"--namespace\", namespace, \"describe\", \"pgupgrade\", fmt.Sprintf(\"%s-upgrade\", postgrescluster))\n\n    //Commented out code to dump the logs of the pgupgrade pods\n    //However due to permission limitations on Lifecycle Operations\n    //Lifecycle operations cannot run kubectl logs commands. Keeping this code incase we need it in the future\n    // lifecycle.Log(\"Looking for pods %s pods\", selector)\n    // resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"pods\"), c.LabelSelector(selector))\n    // if err != nil {\n    // \tpanic(fmt.Sprintf(\"ERROR: Failed to get %s pods to grab upgrade logs: %v\", selector, err))\n    // }\n\n    // for _, resource := range resources {\n    // \tpodNameI := resource.F(\"metadata\").F(\"name\").Value()\n    // \tpodName, ok := podNameI.(string)\n    // \tif !ok {\n    // \t\tpanic(fmt.Sprintf(\"ERROR: %s, pod did not have a name\", selector))\n    // \t}\n    // \tlifecycle.Log(\"Printing logs for %s\", podName)\n    // \t//Print out logs of Pgupgrade log\n    // \t_, err = lifecycle.Kubectl(\"--namespace\", namespace, \"logs\", podName)\n    // \tif err != nil {\n    // \t\tpanic(fmt.Sprintf(\"ERROR: Failed to get logs of %s pod: %v\", podName, err))\n    // \t}\n    // }\n\n    //Wait for the job to be completed. Note: condition is NOT 'completed' BUT 'complete' (case insensitive)\n    //Using '--timeout' makes a job failure case to wait until timeout instead returning at the failure.\n    //But without '--timeout', the 'wait' returns 'timeout' prematurely. So, use it always.\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"job\", \"--for\", \"condition=complete\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres upgrade job to complete %v\", err))\n    }\n\n    job_name, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    job_status, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", job_name, \"-o\", \"jsonpath={.status.conditions[?(@.type=='Complete')].status}\")\n    failed_pods, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", job_name, \"-o\", \"jsonpath={.status.failed}\")\n    if job_status == \"True\" {\n      lifecycle.Log(\"job %s completed successfully\", job_status)\n    } else if failed_pods != \"\" {\n      panic(fmt.Sprintf(\"Jobe %s has failed\", job_name))\n    } else {\n      panic(fmt.Sprintf(\"Job %s is in an unknown state\", job_name))\n    }\n\n  }\n}\n\nfunc checkPostgresUpgradeStatus(namespace string, postgresClusters []string) {\n\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Checking the PGUpgrade CustomResource status for %s-upgrade...\", postgrescluster)\n    selector := fmt.Sprintf(\"%s-upgrade\", postgrescluster)\n    status_reason, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].reason}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade reason %v\", err))\n    }\n    lifecycle.Log(\"Status_reason: %s\", status_reason)\n    status_status, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].status}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade status %v\", err))\n    }\n    lifecycle.Log(\"status_status: %s\", status_status)\n\n    status_type, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].type}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade type %v\", err))\n    }\n    lifecycle.Log(\"status_type: %s\", status_type)\n    if status_reason == \"PGUpgradeSucceeded\" && status_status == \"True\" && status_type == \"Succeeded\" {\n      lifecycle.Log(\"PGUpgrade was successful\")\n    } else {\n      panic(fmt.Sprintf(\"ERROR: PGUpgrade failed. Check the log of the pgupgrade pod\"))\n    }\n  }\n}\n\nfunc startPostgresCluster(namespace string, postgresClusters []string, pgo_fqdn string, manifest string) {\n\n  lifecycle.Log(\"Applying PostgreSQL new image to the upgraded cluster...\")\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(30 * time.Second)\n  //applies postgrescluster customer resources for updated postgres\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", \"sas.com/postgrescluster-cr\", \"-f\", manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply new postgres images on the upgraded cluster %v\", err))\n  }\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(10 * time.Second)\n  //Wait for the primary pod running\n  for _, postgrescluster := range postgresClusters {\n    //PostgresCluster CR sets 'shutdown:' to false, so the cluster is started.\n    //Check if the object exists, and if not, then wait for it to be created.\n    lifecycle.Log(\"Waiting for the primary node (leader) to be running...\")\n    waitObjectCreated(namespace, \"pods\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn))\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for\", \"condition=ready\", \"--selector\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn), \"--timeout\", \"300s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres pods to come up %v\", err))\n    }\n\n    waitObjectCreated(namespace, \"pods\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn))\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn), \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pods are not found %v\", err))\n    }\n    lifecycle.Log(\"Displaying the cluster status for %s using the pod %s...\", postgrescluster, primary_pod)\n    lifecycle.Log(\"NOTE: Creating replicas may take time if the database size is big, so the process continues without waiting for replicas to come up.\")\n    lifecycle.Log(\"The Postgres cluster works without replicas. In order to check the status of replicas later, run: kubectl exec %s -n %s -c database -- patronictl list\", primary_pod, namespace)\n  }\n}\n\nfunc startDataServerOperator(namespace string, timeout string) {\n  lifecycle.Log(\"Start up Data Server Operator...\")\n  selector := \"app.kubernetes.io/name=sas-data-server-operator\"\n  _, err := lifecycle.Kubectl(\"scale\", \"deploy\", \"--namespace\", namespace, \"--replicas=1\", \"sas-data-server-operator\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed start data server operator %v\", err))\n  }\n\n  //Wait the object to be created first before starting to wait for the condition.\n  lifecycle.Log(\"Calling wait for object\")\n  waitObjectCreated(namespace, \"pods\", selector)\n\n  _, err = lifecycle.Kubectl(\"wait\", \"--for=condition=Ready\", \"pods\", \"--namespace\", namespace, \"--selector\", selector, \"--timeout\", timeout)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to wait for data-server-operator to restart %v\", err))\n  }\n\n  dso_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || dso_pod == \"0\" {\n    panic(fmt.Sprintf(\"ERROR: Data Server Operator pod are not found %v\", err))\n  }\n}\n\nfunc waitObjectCreated(namespace string, object string, selector string) {\n\n  maxWait := 180 * time.Second //Maximum wait time in seconds\n  interval := 5 * time.Second  //Interval between checks in seconds\n  totalWait := 0 * time.Second\n\n  fmt.Printf(\"Checking the object type %s of %s\", object, selector)\n  for {\n    if totalWait > maxWait {\n      panic(fmt.Sprintf(\"Timed out waiting for the object %s of %s. s %v\", object, selector, maxWait))\n    }\n    //Check if the object exists\n    objectCreated, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", object, \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Data Server Operator pod are not found %v\", err))\n    }\n    if objectCreated != \"\" {\n      fmt.Printf(\"Object %s was found after %v seconds\", objectCreated, totalWait)\n      break\n    }\n    fmt.Printf(\"Total Wait: %s, sleeping for %s\", totalWait, interval)\n    time.Sleep(interval)\n    totalWait = totalWait + interval\n\n  }\n\n}\n\n// Purpose of this wrapper function is to ensure that rbac permissions to execute the post upgrade commands are not left unchecked.\n// If a post upgrade command fails, we ensure we delete the pod/exec grant privledges from the role.\n// The check for serviceAccountName is an implicit check to see if this is a SAS Deployment Operator deployment or a SAS Orchestration Deploy deployment\n// If the serviceAccount does not exist, then it is a SAS Orchestration Deploy deployment and it is assumed that the kubeconfig that the deployment is using has the permissions to exec into pods\n// If the serviceAccountName does exist then it is asssume that this is a SAS Deployment Operator deployment and we need to add pod/exec privledges to the sas-deployment-operator-reconcile-permissions role that is used by the operator\nfunc executePostUpgradeTasks(namespace string, permissionsNeeded bool, serviceAccountName string, postgresClusters []string, pgo_fqdn string) (error, bool) {\n  if permissionsNeeded {\n    err := toggleDeploymentPermissions(namespace, true)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err)\n      return err, false\n    }\n  }\n  err := postUpgradeExtensionUpgrade(namespace, postgresClusters, pgo_fqdn)\n  if err != nil {\n    return err, true\n  }\n  err = postUpgradeVacuumdbAnalyze(namespace, postgresClusters, pgo_fqdn)\n  if err != nil {\n    return err, true\n  }\n  if permissionsNeeded {\n    err = toggleDeploymentPermissions(namespace, false)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err)\n      return err, false\n    }\n  }\n  return nil, false\n}\n\n// Post-upgrade task: Upgrade extensions\n// f_post_upgrade_extension_upgrade\nfunc postUpgradeExtensionUpgrade(namespace string, postgresClusters []string, pgo_fqdn string) error {\n  lifecycle.Log(\"Post-upgrade task: Upgrading extensions...\")\n  for _, postgresCluster := range postgresClusters {\n    lifecycle.Log(\"Get the primary pod of %s\", postgresCluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgresCluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pod are not found %v\", err))\n    }\n    script := fmt.Sprintf(`logFile=\"/pgdata/upgrade_extensions.log\"; echo > $logFile; echo \"Before extensions are upgraded...\" >> $logFile; psql -c '\\dx' >> $logFile; echo >> $logFile; echo \"Original script:\" >> $logFile; cat /pgdata/update_extensions.sql >> $logFile; cp /pgdata/update_extensions.sql /pgdata/drop_create_extensions.sql; sed -i '/pgaudit/c\\DROP EXTENSION \"pgaudit\";  CREATE EXTENSION \"pgaudit\";' /pgdata/drop_create_extensions.sql; echo >> $logFile; echo \"Updated script:\" >> $logFile; cat /pgdata/drop_create_extensions.sql >> $logFile; psql -f /pgdata/drop_create_extensions.sql | tee -a $logFile; echo >> $logFile; echo \"After extensions are upgraded...\" >> $logFile; echo >> $logFile; psql -c '\\dx' >> $logFile; echo \"The log file $logFile was created to show the details of the extension upgrades\";`)\n    // Run the script within the primary pod.\n    // Do not use '-it' for exec. It is not interactive.\n    // bash -c: commands;  -e: exit on error;  -u: undeclared variables are considered as an error\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-ceu\", script)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Unable to excute extensions upgrade call exiting %v\")\n      return err\n    }\n  }\n  return nil\n}\n\n// Post-upgrade task: Vacuumdb for analyze only\n// f_post_upgrade_vacuumdb_analyze\nfunc postUpgradeVacuumdbAnalyze(namespace string, postgresClusters []string, pgo_fqdn string) error {\n  lifecycle.Log(\"Post-upgrade task: running vacuumdb with analyze-only...\")\n  for _, postgresCluster := range postgresClusters {\n    lifecycle.Log(\"Get the primary pod of %s\", postgresCluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgresCluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pod are not found %v\", err))\n    }\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", \"nohup vacuumdb --all --analyze-only >/pgdata/vacuumdb-analyze-only.log 2>&1 &\")\n    if err != nil {\n      fmt.Errorf(\"ERROR: Unable to execute vacuumdb call exiting %v\")\n      return err\n    }\n  }\n  return nil\n}\n\nfunc toggleDeploymentPermissions(namespace string, add bool) error {\n  if add {\n    lifecycle.Log(\"Adding pod exec permissions to sas-deployment-operator-reconcile-permissions role\")\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"role\", \"sas-deployment-operator-reconcile-permissions\", \"--type\", \"json\", \"-p\", `[{\"op\": \"add\", \"path\": \"/rules/0/resources/-\", \"value\": \"pods/exec\"}]`)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: Cannot patch sas-deployment-operator-reconcile-permissions role to allow pods/exec permissions %v\", err)\n    }\n    return nil\n  } else {\n    lifecycle.Log(\"Removing pod exec permissions to sas-deployment-operator-reconcile-permissions role\")\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"role\", \"sas-deployment-operator-reconcile-permissions\", \"--type\", \"json\", \"-p\", `[{\"op\": \"remove\", \"path\": \"/rules/0/resources/-1\"}]`)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: Cannot patch sas-deployment-operator-reconcile-permissions role to remove pods/exec permissions %v\", err)\n    }\n    return nil\n  }\n\n}"
  - |
    deploy-pre-migrate-analytics-resources-services=apiVersion: orchestration.sas.com/v3beta1
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-analytics-resources
        sas.com/component-version: 22.70.3-20250910.1757545928326
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-pre: "true"
      name: deploy-pre-migrate-analytics-resources-services
    spec:
      args:
      - name: namespace
      - name: serviceAccountName
      - default: 7200s
        name: timeout
      source: |-
        package main
  
        import (
          "fmt"
          "sas/orchestration/lifecycle"
          "strconv"
          "strings"
        )
  
        const (
          AnalyticsResourcesName = "sas-analytics-resources"
          AnalyticsServicesName = "sas-analytics-services"
          AnalyticsGatewayName = "sas-analytics-gateway"
        )
  
        func main() {
  
          namespace := lifecycle.Arg("namespace")
          lifecycle.Log(fmt.Sprintf("namespace: %s", namespace))
  
          serviceAccountName := lifecycle.Arg("serviceAccountName")
          lifecycle.Log(fmt.Sprintf("service account: %s", serviceAccountName))
  
          namespaceBinding := namespace + ":" + serviceAccountName
          lifecycle.Log(fmt.Sprintf("namespace binding: %s", namespaceBinding))
  
          timeout := lifecycle.Arg("timeout")
          serviceAccountNameBlank := len(strings.TrimSpace(serviceAccountName)) == 0
  
          lifecycle.Log("Timeout for kubectl: " + timeout)
  
          // The beginning major version of analytics resources when unifying analytics-resources and -services DB schema occurs
          analyticsResourcesVer := 22
  
          // if ANALYTICS_RESOURCES_DB_MIGRATION_MAJOR_VERSION is defined
          // in configmaps, then override analyticsResourcesVer
          analyticsResourcesVer = getUpgradeVersions(namespace, analyticsResourcesVer)
  
          if !serviceAccountNameBlank {
            lifecycle.Log("Add role-based access controls (RBAC) for deploy-pre-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "role", "deploy-pre-migrate-analytics-resources-services")
            lifecycle.Kubectl("create", "--namespace", namespace,  "role", "deploy-pre-migrate-analytics-resources-services", "--verb=get,list,watch,patch", "--resource=deployments/scale,horizontalpodautoscalers,pods", "--resource-name", AnalyticsResourcesName, "--resource-name", AnalyticsServicesName, "--resource-name", AnalyticsGatewayName)
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "rolebinding", "deploy-pre-migrate-analytics-resources-services")
            lifecycle.Kubectl("create", "--namespace", namespace,  "rolebinding", "deploy-pre-migrate-analytics-resources-services",  "--role", "deploy-pre-migrate-analytics-resources-services", "--serviceaccount", namespaceBinding)
          } else {
            lifecycle.Log("ServiceAccountName is not defined.. executing with the default user")
          }
  
          lifecycle.Kubectl("version", "--output=json")
  
          res, err := lifecycle.Kubectl(
             "get",
             "pods",
             "--namespace",
             namespace,
             "--no-headers",
             "--output=jsonpath={range.items[*]}{.metadata.labels.app}{\":\"}{.metadata.annotations.sas\\.com/version}{\"\\n\"}{end}",
             "--selector",
             fmt.Sprintf("app in (%s,%s,%s)", AnalyticsResourcesName, AnalyticsServicesName, AnalyticsGatewayName))
  
          lifecycle.Log(res)
  
          if err != nil {
              lifecycle.Log("Unable to determine if any of the deprecated analytics pods are running.")
              // This is a fatal error since we are not able to determine if any of the deprecated analytics pods are running.
              panic(fmt.Sprintf("Failed to determine if any deprecated analytics pods are running: %v", err))
          }
  
          lines := strings.Split(res, "\n")
  
          // The total count of sas-analytics-resources (AR) pods.
          // If deprecated pods are found, then this count will be used by the post migration script to scale up the AR pods to their original count.
          arPod := 0
  
          // The total count of sas-analytics-gateway (AG) pods.
          agPod := 0
  
          // The total count of deprecated sas-analytics-services (AS) pods.
          // If deprecated pods are found, then the count of (agPod + asPod) will be used by the post migration script to scale up the AG pods.
          asPod := 0
  
          // Flag if deprecated AR pods are found.
          arPodDeprecatedFound := false
  
          for _, line := range lines {
            if strings.Contains(line, ":") {
              data := strings.Split(line, ":")
  
              version := strings.Split(data[1], ".")
  
              major, _ := strconv.Atoi(version[0])
  
              deploymentName := data[0]
              if strings.Contains(deploymentName, AnalyticsResourcesName) {
                // increment the count of AR pods
                arPod += 1
                if major < analyticsResourcesVer {
                  // set flag when deprecated AR pods was found
                  arPodDeprecatedFound = true
                }
              } else if strings.Contains(deploymentName, AnalyticsServicesName) {
                // increment the count of AS pods
                asPod += 1
              } else if strings.Contains(deploymentName, AnalyticsGatewayName) {
                // increment the count of AG pods
                agPod += 1
              } else {
                lifecycle.Log(fmt.Sprintf("Found unsupported deployment of '%s' with a major version of %d", deploymentName, major))
              }
            }
          }
  
          if asPod > 0 || arPodDeprecatedFound {
  
            if arPod > 0 {
              // scale the AR pods to 0
              setHPAToOne(namespace, AnalyticsResourcesName)
              lifecycle.Log(fmt.Sprintf("%s major < %s, scale pod to 0", AnalyticsResourcesName, analyticsResourcesVer))
              lifecycle.Kubectl(
                 "scale",
                 "--namespace",
                 namespace,
                 "--replicas=0",
                 "deployment/" + AnalyticsResourcesName)
            }
  
            if asPod > 0 {
              // scale the AS pods to 0
              setHPAToOne(namespace, AnalyticsServicesName)
              lifecycle.Log(fmt.Sprintf("%s, scale pod to 0", AnalyticsServicesName))
              lifecycle.Kubectl(
                 "scale",
                 "--namespace",
                 namespace,
                 "--replicas=0",
                 "deployment/" + AnalyticsServicesName)
            }
  
            if agPod > 0 {
              // scale the AG pods to 0
              setHPAToOne(namespace, AnalyticsGatewayName)
              lifecycle.Log(fmt.Sprintf("%s, scale pod to 0", AnalyticsGatewayName))
              lifecycle.Kubectl(
                 "scale",
                 "--namespace",
                 namespace,
                 "--replicas=0",
                 "deployment/" + AnalyticsGatewayName)
            }
  
            // set flag to indicate to indicate the # of original AR pods
            lifecycle.SetVariable(AnalyticsResourcesName + "/replicas", arPod)
  
            // set flag to indicate to indicate the # of original AS pods
            lifecycle.SetVariable(AnalyticsGatewayName + "/replicas", (asPod + agPod))
          }
  
          if !serviceAccountNameBlank {
            lifecycle.Log("Clean up role-based access controls (RBAC) for deploy-pre-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "rolebinding", "deploy-pre-migrate-analytics-resources-services")
            lifecycle.Kubectl("delete", "--namespace", namespace, "--wait", "--timeout", timeout,  "--ignore-not-found", "role", "sas-migrate-analytics-resources-services")
          }
  
        }
  
        func setHPAToOne(nameSpace string, svcName string)  {
  
          // Execute a kubectl "get hpa" command to determine the minReplicas and maxReplicas for the specified service.
          // If there is no HPA entry for the service, the output will be ":".
          // If there is an HPA entry for the service, the output will be two integer values demarcated by the colon character.
          // For example, "1:2" means that the minReplicas is 1 and the maxReplicas is 2.
          resHPA, errGetHPA := lifecycle.Kubectl(
            "get",
            "hpa",
            "--namespace",
            nameSpace,
            "-o",
            "jsonpath={.items[*].spec.minReplicas}:{.items[*].spec.maxReplicas}",
            "--field-selector",
            fmt.Sprintf("metadata.name=%s", svcName))
          if errGetHPA != nil {
             lifecycle.Log(resHPA)
             panic(fmt.Sprintf("Failed to get HPA for service %s in namespace %s: %v", svcName, nameSpace, errGetHPA))
          }
  
          resHPA = strings.TrimSpace(resHPA)
          if len(resHPA) > 2 && strings.Contains(resHPA, ":") {
            lifecycle.Log(fmt.Sprintf("processing HPA settings for service %s: %q", svcName, resHPA))
            tokens := strings.Split(resHPA, ":")
            if len(tokens) != 2 {
               panic(fmt.Sprintf("Unable to process HPA settings for %s: %s", svcName, resHPA))
            }
  
            hpaMin := tokens[0]
            hpaMax := tokens[1]
  
            if _, errMin := strconv.Atoi(hpaMin); errMin != nil {
               panic(fmt.Sprintf("an integer was expected for hpaMin instead of %s", hpaMin))
            }
  
            if _, errMax := strconv.Atoi(hpaMax); errMax != nil {
               panic(fmt.Sprintf("an integer was expected for hpaMax instead of %s", hpaMax))
            }
  
            lifecycle.SetVariable(fmt.Sprintf("%s/hpamin", svcName), hpaMin)
            lifecycle.SetVariable(fmt.Sprintf("%s/hpamax", svcName), hpaMax)
            lifecycle.Log(fmt.Sprintf("%s HPA Min=%s Max=%s", svcName, hpaMin, hpaMax))
            if stdOutAndErrPatch, errPatchHPA := lifecycle.Kubectl(
              "patch",
              "hpa",
              svcName,
              "--namespace",
              nameSpace,
              "--patch", "{\"spec\": {\"minReplicas\": 1, \"maxReplicas\": 1}}"); errPatchHPA != nil {
               lifecycle.Log(stdOutAndErrPatch)
               panic(fmt.Sprintf("Failed to HPA patch %s in namespace %s: %v", svcName, nameSpace, errPatchHPA))
            }
            lifecycle.Log(fmt.Sprintf("%s was patched to set HPA minReplicas=1 and maxReplicas=1", svcName))
          } else {
            lifecycle.Log(fmt.Sprintf("Can't parse HPA Min and Max for %s", svcName))
          }
        }
  
        func getUpgradeVersions(namespace string, analyticsResourcesVer int) (int) {
          cfgMapRes, _ := lifecycle.Kubectl(
             "get",
             "configmaps",
             "--namespace",
             namespace,
             "--no-headers",
             "--output=jsonpath={range .items[*].metadata }{.name}{'\\n'}{end}")
          cfgMapRows := strings.Split(cfgMapRes, "\n")
          for _, cfgMap := range cfgMapRows {
            if strings.HasPrefix(cfgMap, AnalyticsResourcesName) {
              analyticsResourcesVer = getVersion(namespace, cfgMap, analyticsResourcesVer, "ANALYTICS_RESOURCES_DB_MIGRATION_MAJOR_VERSION")
              break
            }
          }
          return analyticsResourcesVer
        }
  
        func getVersion(namespace string, v string, svcVersion int, envVar string) (int) {
          ver, _ := lifecycle.Kubectl(
             "get",
             "configmaps",
             v,
             "--namespace",
             namespace,
             fmt.Sprintf("--output=jsonpath={.data.%s}", envVar))
          ver = strings.ReplaceAll(ver, "\n", "")
          ver = strings.ReplaceAll(ver, "\"", "")
          if ver != "" {
            if intVer, err := strconv.Atoi(ver); err == nil {
              svcVersion = intVer
            }
          } else {
            lifecycle.Log(fmt.Sprintf("%s is not defined falling back to %d", envVar, svcVersion))
          }
          return svcVersion
        }
  - |
    deploy-pre-openshift=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/deploy-pre: "true"
      name: deploy-pre-openshift
    spec:
      args:
      - name: namespace
        required: true
      - name: manifest
        required: true
      - name: timeout
        required: true
      - name: serviceAccountName
      steps:
      - args:
        - sas.com/route-permissions
        - "true"
        cmd: set_variable
        when: |-
          (and
            $serviceAccountName
            (.ManifestResources $manifest ((((.NewManifestResourcesIterationSpec).WithGroup "route.openshift.io").WithVersion "v1").WithKind "Route")))
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - role
        - sas-predeploy-openshift-route
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
      - args:
        - create
        - --namespace
        - $namespace
        - role
        - sas-predeploy-openshift-route
        - --verb
        - get,create,update,patch
        - --resource
        - route.route.openshift.io/custom-host
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - rolebinding
        - sas-predeploy-openshift-route
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
      - args:
        - create
        - --namespace
        - $namespace
        - rolebinding
        - sas-predeploy-openshift-route
        - --role
        - sas-predeploy-openshift-route
        - --serviceaccount
        - (print $namespace ":" $serviceAccountName)
        cmd: kubectl
        when: (.GetVariable "sas.com/route-permissions")
  - |
    deploy-pre-pyconfig=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
        participate.lifecycle.sas.com/deploy-pre: "true"
      name: deploy-pre-pyconfig
    spec:
      args:
      - name: namespace
      - name: timeout
      steps:
      - args:
        - deploy-pre-pyconfig-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        when: |-
          (eq
            "true"
            (.Annotation "sas.com/sas-pyconfig-update" (.ClusterResource ((((((.NewClusterResourcesIterationSpec).WithNamespace $namespace).WithGroup "").WithVersion "v1").WithResource "configmap").WithName "sas-deploy-lifecycle-operation-variables")))
          )
  - |
    deploy-pre-pyconfig-execute=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
      name: deploy-pre-pyconfig-execute
    spec:
      args:
      - name: namespace
      - name: timeout
      steps:
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - job
        - sas-pyconfig-cjinitial
        cmd: kubectl
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - job
        - sas-pyconfig
        cmd: kubectl
      - args:
        - delete
        - --namespace
        - $namespace
        - --wait
        - --timeout
        - $timeout
        - --ignore-not-found
        - job
        - sas-pyconfig-job
        cmd: kubectl
  - |
    deploy-stage=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: deploy-stage
    spec:
      args:
      - name: namespace
      - name: manifest
      - name: timeout
      - name: serviceAccountName
      steps:
      - args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - --manifest
        - $manifest
        - --serviceAccountName
        - $serviceAccountName
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/deploy-stage=true
  - |
    kubernetes-kubectl-server-version-alignment-check=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-orchestration
        sas.com/component-version: 1.147.1-20251124.1764004273016
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/assess: "true"
      name: kubernetes-kubectl-server-version-alignment-check
    spec:
      steps:
      - args:
        - kubectl and server version combination exceed the supported skew window
        cmd: fail
        when: (not (.KubernetesClientServerVersionsAreValid))
  - |
    prepull-during-update=apiVersion: orchestration.sas.com/v3beta1
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-prepull
        sas.com/component-version: 2.9.3-20250904.1757004219406
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-prepull
        participate.lifecycle.sas.com/deploy-stage: "true"
      name: prepull-during-update
    spec:
      args:
      - name: namespace
        required: true
      - name: manifest
        required: true
      - default: 1800s
        name: timeout
      source: "package main\nimport (\n  \"encoding/json\"\n  \"regexp\"\n  \"fmt\"\n  \"time\"\n  \"sas/orchestration/lifecycle\"\n  m \"sas/orchestration/lifecycle/manifest\"\n  c \"sas/orchestration/lifecycle/cluster\"\n)\nfunc main() {\n  manifest := lifecycle.Arg(\"manifest\")\n  namespace := lifecycle.Arg(\"namespace\")\n  timeout := lifecycle.Arg(\"timeout\")\n  if prepullPresent(manifest) == false {\n    // handle orders without prepull\n    return\n  }\n  if isWorkbench(manifest) == true {\n    // Handle orders related to Workbench. Workbench\n    // cannot use Viya 4 lifecycle op.\n    return\n  }\n  deleteExistingPrepull(namespace, timeout)\n  deployPrepullcm(manifest, namespace, timeout)\n  deployInputcm(manifest, namespace, timeout)\n  deployGocm(manifest, namespace, timeout)\n  deploySCcm(manifest, namespace, timeout)\n  deployPrepullpt(manifest, namespace, timeout)\n  deployCSpt(manifest, namespace, timeout)\n  deployPrepullrl(manifest, namespace, timeout)\n  deployPrepullsa(manifest, namespace, timeout)\n  deployPrepullrb(manifest, namespace, timeout)\n  deployImagesecs(manifest, namespace, timeout)\n  deployConfigMap(manifest, namespace, timeout)\n  waitForConfigMapCreate(namespace, timeout)\n  deployPrepull(manifest, namespace, timeout)\n  waitForConfigMapDelete(namespace, timeout)\n}\nfunc deleteExistingPrepull(namespace, timeout string) {\n  matches, err := c.Resources(c.Namespace(namespace), c.Resource(\"Deployment\"), c.Name(\"sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(matches) > 0 {\n    _, err = lifecycle.Kubectl(\"delete\", \"deployment,pods\", \"--selector\", \"app.kubernetes.io/name=sas-prepull\", \"--namespace\", namespace, \"--timeout\", timeout, \"--wait\")\n    if err != nil {\n      panic(err)\n    }\n  }\n  return\n}\nfunc deployConfigMap(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"ConfigMap\"), m.LabelSelector(\"orchestration.sas.com/lifecycle=components\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Needed configmap not found\")\n  }\n  componentsConfigMap := resources[0]\n  renameResource(componentsConfigMap, \"sas-prepull-components\")\n  componentsConfigMapJson, err := json.Marshal(componentsConfigMap.Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(componentsConfigMapJson), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployInputcm(manifest, namespace, timeout string) {\n  inputCm := \"\"\n  sName := \"\"\n  inputRegEx, _ := regexp.Compile(\"^input-[a-zA-Z0-9]{10}$\")\n  resources, err := m.Resources(manifest, m.Kind(\"ConfigMap\"))\n  if err != nil {\n    panic(err)\n  }\n  for _, resource := range resources {\n    rName := resource.F(\"metadata\").F(\"name\").Value()\n    sName, _ = rName.(string)\n    if inputRegEx.MatchString(sName) {\n      inputCm = sName\n      break \n    }\n  }\n  inCm, err := m.Resources(manifest, m.Kind(\"ConfigMap\"), m.Name(inputCm))\n  if err != nil {\n    panic(err)\n  }\n  if len(inCm) != 1 {\n    panic(\"Unable to get input config map\")\n  }\n  injson, err := json.Marshal(inCm[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(injson), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }  \n}\nfunc deploySCcm(manifest, namespace, timeout string) {\n  inputCm := \"\"\n  sName := \"\"\n  inputRegEx, _ := regexp.Compile(\"^sas-shared-config-[a-zA-Z0-9]{10}$\")\n  resources, err := m.Resources(manifest, m.Kind(\"ConfigMap\"))\n  if err != nil {\n    panic(err)\n  }\n  for _, resource := range resources {\n    rName := resource.F(\"metadata\").F(\"name\").Value()\n    sName, _ = rName.(string)\n    if inputRegEx.MatchString(sName) {\n      inputCm = sName\n      break \n    }\n  }\n  inCm, err := m.Resources(manifest, m.Kind(\"ConfigMap\"), m.Name(inputCm))\n  if err != nil {\n    panic(err)\n  }\n  if len(inCm) != 1 {\n    panic(\"Unable to get input config map\")\n  }\n  injson, err := json.Marshal(inCm[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(injson), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }  \n}\nfunc deployGocm(manifest, namespace, timeout string) {\n  inputCm := \"\"\n  sName := \"\"\n  inputRegEx, _ := regexp.Compile(\"^sas-go-config-[a-zA-Z0-9]{10}$\")\n  resources, err := m.Resources(manifest, m.Kind(\"ConfigMap\"))\n  if err != nil {\n    panic(err)\n  }\n  for _, resource := range resources {\n    rName := resource.F(\"metadata\").F(\"name\").Value()\n    sName, _ = rName.(string)\n    if inputRegEx.MatchString(sName) {\n      inputCm = sName\n      break \n    }\n  }\n  inCm, err := m.Resources(manifest, m.Kind(\"ConfigMap\"), m.Name(inputCm))\n  if err != nil {\n    panic(err)\n  }\n  if len(inCm) != 1 {\n    panic(\"Unable to get input config map\")\n  }\n  injson, err := json.Marshal(inCm[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(injson), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }  \n}\nfunc deployCSpt(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"PodTemplate\"), m.Name(\"sas-compute-job-config\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Compute job config podtemplate not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepullpt(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"PodTemplate\"), m.Name(\"sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Prepull podtemplate not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepullrb(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"RoleBinding\"), m.Name(\"sas-prepull-v2-namespace\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Prepull role binding not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepullrl(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"Role\"), m.Name(\"sas-prepull-v2-namespace\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Prepull role not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepullsa(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"ServiceAccount\"), m.Name(\"sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Prepull service account config not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepullcm(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"ConfigMap\"), m.LabelSelector(\"app.kubernetes.io/name=sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Prepull parameters config map not found\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployImagesecs(manifest, namespace, timeout string) {\n  imageSec := \"\"\n  sName := \"\"\n  inputRegEx, _ := regexp.Compile(\"^sas-image-pull-secrets-[a-zA-Z0-9]{10}$\")\n  resources, err := m.Resources(manifest, m.Kind(\"Secret\"))\n  if err != nil {\n    panic(err)\n  }\n  for _, resource := range resources {\n    rName := resource.F(\"metadata\").F(\"name\").Value()\n    sName, _ = rName.(string)\n    if inputRegEx.MatchString(sName) {\n      imageSec = sName\n      break\n    }\n  }\n  inSe, err := m.Resources(manifest, m.Kind(\"Secret\"), m.Name(imageSec))\n  if err != nil {\n    panic(err)\n  }\n  if len(inSe) != 1 {\n    panic(\"Unable to get input config map\")\n  }\n  injson, err := json.Marshal(inSe[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(injson), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc deployPrepull(manifest, namespace, timeout string) {\n  resources, err := m.Resources(manifest, m.Kind(\"Deployment\"), m.Name(\"sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  if len(resources) != 1 {\n    panic(\"Unable to find sas-prepull deployment\")\n  }\n  json, err := json.Marshal(resources[0].Value())\n  if err != nil {\n    panic(err)\n  }\n  _, err = lifecycle.KubectlWithStdin(string(json), \"apply\", \"--namespace\", namespace, \"-f\", \"-\", \"--timeout\", timeout)\n  if err != nil {\n    panic(err)\n  }\n}\nfunc waitForConfigMapCreate(namespace, timeout string) {\n  tooLong, err := time.ParseDuration(timeout)\n  if err != nil {\n    panic(err)\n  }\n  stopAt := time.Now().Add(tooLong)\n  sleepDuration := 100 * time.Millisecond\n  for {\n    matches, err := c.Resources(c.Namespace(namespace), c.Resource(\"ConfigMap\"), c.Name(\"sas-prepull-components\"))\n    if err != nil {\n      panic(err)\n    }\n    if len(matches) == 1 {\n      return\n    }\n    if time.Now().After(stopAt) {\n      panic(\"Timed out waiting for creation of sas-prepull-components\")\n    }\n    time.Sleep(sleepDuration)\n  }\n}\nfunc waitForConfigMapDelete(namespace, timeout string) {\n  tooLong, err := time.ParseDuration(timeout)\n  if err != nil {\n    panic(err)\n  }\n  stopAt := time.Now().Add(tooLong)\n  sleepDuration := 100 * time.Millisecond\n  for {\n    matches, err := c.Resources(c.Namespace(namespace), c.Resource(\"ConfigMap\"), c.Name(\"sas-prepull-components\"))\n    if err != nil {\n      panic(err)\n    }\n    if len(matches) == 0 {\n      return\n    }\n    if time.Now().After(stopAt) {\n      panic(\"Timed out waiting for deletion of sas-prepull-components\")\n    }\n    time.Sleep(sleepDuration)\n  }\n}\nfunc renameResource(resource *lifecycle.Resource, name string) {\n  resourceAsMap, ok := resource.Value().(map[string]interface{})\n  if !ok {\n    panic(\"not the right type\")\n  }\n  resourceMetadataAsMap, ok := resourceAsMap[\"metadata\"].(map[string]interface{})\n  if !ok {\n    panic(\"not the right type\")\n  }\n  resourceMetadataAsMap[\"name\"] = name\n}\nfunc isWorkbench(manifest string) bool {\n  resources, err := m.Resources(manifest, m.Kind(\"PodTemplate\"), m.LabelSelector(\"app.kubernetes.io/name=sas-pup\"))\n  if err != nil {\n    panic(err)\n  }\n  return len(resources) > 0\n}\nfunc prepullPresent(manifest string) bool {\n  resources, err := m.Resources(manifest, m.Kind(\"Deployment\"), m.Name(\"sas-prepull\"))\n  if err != nil {\n    panic(err)\n  }\n  return len(resources) > 0\n}"
  - |
    pyconfig-runonce-execute=apiVersion: orchestration.sas.com/v2beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-pyconfig
        sas.com/component-version: 1.30.56-20251014.1760453664787
      creationTimestamp: null
      labels:
        app.kubernetes.io/name: sas-pyconfig
      name: pyconfig-runonce-execute
    spec:
      args:
      - name: namespace
        require: true
      steps:
      - args:
        - create
        - job
        - --namespace
        - $namespace
        - --from
        - cronjob/sas-pyconfig
        - sas-pyconfig-cjinitial
        cmd: kubectl
  - |
    reconcile-once.deploy=apiVersion: orchestration.sas.com/v2beta3
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-orchestration
        sas.com/component-version: 1.147.1-20251124.1764004273016
      creationTimestamp: null
      name: reconcile-once.deploy
    spec:
      args:
      - name: clusterApiManifest
      - name: clusterApiNamespace
      - name: deploymentDir
      - name: manifest
      - name: namespace
      - name: permissionsManifest
      - name: serviceAccountName
      - default: 7200s
        name: timeout
      steps:
      - args:
        - apply
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - -f
        - $permissionsManifest
        cmd: kubectl
        when: $permissionsManifest
      - args:
        - patch
        - --namespace
        - $namespace
        - secrets
        - $resource.Name
        - --type
        - json
        - --patch
        - '[{"op":"replace","path":"/metadata/ownerReferences","value":[]}]'
        cmd: kubectl
        withClusterResources:
          name: sas-crunchy-data-postgres-tls-secret
          namespace: $namespace
          resource: secrets
          version: v1
      - args:
        - deploy
        - --namespace
        - $namespace
        - --manifest
        - $manifest
        - --deploymentDir
        - $deploymentDir
        - --serviceAccountName
        - $serviceAccountName
        - --timeout
        - $timeout
        - --clusterApiNamespace
        - $clusterApiNamespace
        - --clusterApiManifest
        - $clusterApiManifest
        cmd: run
      - always: true
        args:
        - delete
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        - -f
        - $permissionsManifest
        cmd: kubectl
        when: $permissionsManifest
  - |
    scale-to-zero=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: scale-to-zero
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - 'DEPRECATED: Replaced by stop-all'
        cmd: log
      - args:
        - stop-all
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
  - |
    scale-up=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: scale-up
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - 'DEPRECATED: Replaced by start-all'
        cmd: log
      - args:
        - start-all
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
  - |
    start-all=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        lifecycle.orchestration.sas.com/publish: "true"
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: start-all
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/start-all-assess=true
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/start-all-pre=true
      - args:
        - start-all-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/start-all-post=true
  - |
    start-all-execute=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: start-all-execute
    spec:
      args:
      - name: namespace
      - name: timeout
      steps:
      - args:
        - start-all-scale
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
      - args:
        - patch
        - --namespace
        - $namespace
        - cronjobs
        - $resource.Name
        - --patch
        - (print "{\"spec\":{\"suspend\":" (.LastAppliedConfigurationValue $resource "{.spec.suspend}" "false") "}}")
        cmd: kubectl
        withClusterResources:
          group: batch
          labelSelector: sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never
          namespace: $namespace
          resource: cronjobs
      - args:
        - patch
        - --namespace
        - $namespace
        - daemonsets
        - $resource.Name
        - --patch
        - (print "{\"spec\":{\"template\":{\"spec\":{\"nodeSelector\":{\"sas.com/scale-class\":\"" (.LastAppliedConfigurationValue $resource "{.spec.template.spec.nodeSelector.sas\\.com/scale-class}" "ignored") "\"}}}}}" )
        cmd: kubectl
        withClusterResources:
          group: apps
          labelSelector: sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never
          lastAppliedConfiguration:
            jsonPath: '{.spec.template.spec.nodeSelector.sas\\.com/scale-class}'
          namespace: $namespace
          resource: daemonsets
      - args:
        - patch
        - --namespace
        - $namespace
        - daemonsets
        - $resource.Name
        - --type
        - json
        - --patch
        - '[{"op":"remove", "path": "/spec/template/spec/nodeSelector/sas.com~1scale-class"}]'
        cmd: kubectl
        withClusterResources:
          currentConfiguration:
            isMissing: false
            jsonPath: '{.spec.template.spec.nodeSelector.sas\\.com/scale-class}'
          group: apps
          labelSelector: sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never
          lastAppliedConfiguration:
            isMissing: true
            jsonPath: '{.spec.template.spec.nodeSelector.sas\\.com/scale-class}'
          namespace: $namespace
          resource: daemonsets
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/start-all-execute-phase-0=true
  - |
    start-all-execute-cas=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-cas-operator
        sas.com/component-version: 3.59.10-20250902.1756846578310
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/start-all-execute-phase-0: "true"
      name: start-all-execute-cas
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - casdeployments
        - $resource.Name
        - --type
        - json
        - --patch
        - '(print "[{\"op\":\"replace\", \"path\": \"/spec/shutdown\", \"value\":" (.LastAppliedConfigurationValue $resource "{.spec.shutdown}" "false") "}]" )'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "viya.sas.com").WithResource "casdeployments"))
        withClusterResources:
          group: viya.sas.com
          labelSelector: sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never
          namespace: $namespace
          resource: casdeployments
  - |
    start-all-execute-crunchy=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/start-all-execute-phase-0: "true"
      name: start-all-execute-crunchy
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - postgresclusters.postgres-operator.crunchydata.com
        - $resource.Name
        - --type
        - json
        - --patch
        - '(print "[{\"op\":\"replace\", \"path\": \"/spec/shutdown\", \"value\":" (.LastAppliedConfigurationValue $resource "{.spec.shutdown}" "false") "}]" )'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "postgres-operator.crunchydata.com").WithResource "postgresclusters"))
        withClusterResources:
          group: postgres-operator.crunchydata.com
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: postgresclusters
          version: v1beta1
  - |
    start-all-execute-opensearch=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-opendistro-operator
        sas.com/component-version: 7.52.2-20250911.1757593776425
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/start-all-execute-phase-0: "true"
      name: start-all-execute-opensearch
    spec:
      args:
      - name: namespace
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - opendistroclusters
        - $resource.Name
        - --type
        - json
        - --patch
        - '(print "[{\"op\":\"replace\", \"path\": \"/spec/shutdown\", \"value\":" (.LastAppliedConfigurationValue $resource "{.spec.shutdown}" "false") "}]" )'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "opendistro.sas.com").WithResource "opendistroclusters"))
        withClusterResources:
          group: opendistro.sas.com
          labelSelector: sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never
          namespace: $namespace
          resource: opendistroclusters
  - |
    start-all-scale=apiVersion: orchestration.sas.com/v3beta2
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: start-all-scale
    spec:
      args:
      - name: namespace
      - name: timeout
      source: |-
        package main
        import (
          "fmt"
          "sas/orchestration/lifecycle"
          c "sas/orchestration/lifecycle/cluster"
        )
        func main() {
          namespace := lifecycle.Arg("namespace")
          scale(namespace)
        }
        func scale(namespace string){
          scaleReplicaMap := make(map[string][]string)
          scaleCommand := []string{"scale", "--namespace", namespace, "--replicas"}
  
          deployments, err := c.MetadataResources(c.Namespace(namespace), c.Resource("Deployment"), c.LabelSelector("sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never"))
          if err != nil {
            panic(err)
          }
          statefulsets, err := c.MetadataResources(c.Namespace(namespace), c.Resource("StatefulSets"), c.LabelSelector("sas.com/deployment=sas-viya,sas.com/zero-scale-phase!=never"))
          if err != nil {
            panic(err)
          }
          metaresources := append(deployments, statefulsets...)
  
          for _, metaresource := range metaresources {
            replicas := lifecycle.LastAppliedConfigurationValue(metaresource,"{.spec.replicas}","1")
            name := metaresource.Name
            kind := metaresource.Kind
            resource := fmt.Sprintf("%s/%s", kind, name)
            scaleReplicaMap[replicas] = append(scaleReplicaMap[replicas], resource)
          }
  
          for replicaKey, scaleList := range scaleReplicaMap {
              command := append(scaleCommand, replicaKey)
              command = append(command, scaleList...)
              _, err = lifecycle.Kubectl(command...)
          }
        }
  - |
    stop-all=apiVersion: orchestration.sas.com/v2beta10
    kind: LifecycleOperation
    metadata:
      annotations:
        lifecycle.orchestration.sas.com/publish: "true"
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: stop-all
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/stop-all-assess=true
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/stop-all-pre=true
      - args:
        - stop-all-execute
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/stop-all-post=true
  - |
    stop-all-execute=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      name: stop-all-execute
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - scale
        - --namespace
        - $namespace
        - deployments
        - --replicas
        - "0"
        - --selector
        - sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
        cmd: kubectl
      - args:
        - scale
        - --namespace
        - $namespace
        - statefulsets
        - --replicas
        - "0"
        - --selector
        - sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
        cmd: kubectl
      - args:
        - patch
        - --namespace
        - $namespace
        - cronjobs
        - $resource.Name
        - --patch
        - '{"spec":{"suspend":true}}'
        cmd: kubectl
        withClusterResources:
          group: batch
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: cronjobs
      - args:
        - patch
        - --namespace
        - $namespace
        - cronjobs
        - $resource.Name
        - --patch
        - '{"spec":{"suspend":true}}'
        cmd: kubectl
        withClusterResources:
          group: batch
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: cronjobs
      - args:
        - patch
        - --namespace
        - $namespace
        - daemonsets
        - $resource.Name
        - --patch
        - '{"spec":{"template":{"spec":{"nodeSelector":{"sas.com/scale-class":"zero"}}}}}'
        cmd: kubectl
        withClusterResources:
          group: apps
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: daemonsets
      - always: true
        args:
        - $operation
        - --namespace
        - $namespace
        - --timeout
        - $timeout
        cmd: run
        withOperations:
          labelSelector: participate.lifecycle.sas.com/stop-all-execute-phase-0=true
      - args:
        - scale
        - --namespace
        - $namespace
        - deployments
        - --replicas
        - "0"
        - --selector
        - sas.com/deployment=sas-viya,sas.com/zero-scale-phase=1
        cmd: kubectl
  - |
    stop-all-execute-cas=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-cas-operator
        sas.com/component-version: 3.59.10-20250902.1756846578310
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/stop-all-execute-phase-0: "true"
      name: stop-all-execute-cas
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - casdeployments
        - $resource.Name
        - --type
        - json
        - --patch
        - '[{"op":"replace", "path": "/spec/shutdown", "value":true}]'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "viya.sas.com").WithResource "casdeployments"))
        withClusterResources:
          group: viya.sas.com
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: casdeployments
      - args:
        - wait
        - --namespace
        - $namespace
        - --for
        - delete
        - pod
        - --selector
        - app.kubernetes.io/managed-by=sas-cas-operator
        - --timeout
        - $timeout
        cmd: kubectl
  - |
    stop-all-execute-crunchy=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-crunchy5-postgres-operator
        sas.com/component-version: 1.6.3-20250609.1749489660207
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/stop-all-execute-phase-0: "true"
      name: stop-all-execute-crunchy
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - postgresclusters.postgres-operator.crunchydata.com
        - $resource.Name
        - --type
        - json
        - --patch
        - '[{"op":"replace", "path": "/spec/shutdown", "value":true}]'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "postgres-operator.crunchydata.com").WithResource "postgresclusters"))
        withClusterResources:
          group: postgres-operator.crunchydata.com
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: postgresclusters
          version: v1beta1
      - args:
        - wait
        - --namespace
        - $namespace
        - --for
        - delete
        - pod
        - --selector
        - postgres-operator.crunchydata.com/cluster,!job-name
        - --timeout
        - $timeout
        cmd: kubectl
  - |
    stop-all-execute-opensearch=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-opendistro-operator
        sas.com/component-version: 7.52.2-20250911.1757593776425
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/stop-all-execute-phase-0: "true"
      name: stop-all-execute-opensearch
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - patch
        - --namespace
        - $namespace
        - opendistroclusters
        - $resource.Name
        - --type
        - json
        - --patch
        - '[{"op":"replace", "path": "/spec/shutdown", "value":true}]'
        cmd: kubectl
        when: (.ClusterDefinitions (((.NewClusterDefinitionsIterationSpec).WithGroup "opendistro.sas.com").WithResource "opendistroclusters"))
        withClusterResources:
          group: opendistro.sas.com
          labelSelector: sas.com/deployment=sas-viya,!sas.com/zero-scale-phase
          namespace: $namespace
          resource: opendistroclusters
  - |
    stop-all-execute-sas-launcher=apiVersion: orchestration.sas.com/v2beta15
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-launcher
        sas.com/component-version: 1.103.5-20251008.1759934479179
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/stop-all-execute-phase-0: "true"
      name: stop-all-execute-sas-launcher
    spec:
      args:
      - name: namespace
      - default: 7200s
        name: timeout
      steps:
      - args:
        - --namespace
        - $namespace
        - delete
        - job
        - --selector
        - sas.com/created-by=sas-launcher
        - --wait
        - --timeout
        - $timeout
        cmd: kubectl
      - args:
        - --namespace
        - $namespace
        - delete
        - pod
        - --selector
        - sas.com/created-by=sas-launcher
        - --wait
        - --timeout
        - $timeout
        cmd: kubectl
  - |
    version-check=apiVersion: orchestration.sas.com/v3beta6
    kind: LifecycleOperation
    metadata:
      annotations:
        sas.com/component-name: sas-k8s-common
        sas.com/component-version: 2.108.0-20250904.1756998319075
      creationTimestamp: null
      labels:
        participate.lifecycle.sas.com/assess: "true"
      name: version-check
    spec:
      args:
      - name: namespace
        required: true
      - name: manifest
        required: true
      source: |-
        package main
        import (
          "fmt"
          "sas/orchestration/lifecycle"
          ca "sas/orchestration/lifecycle/cadence"
          cls "sas/orchestration/lifecycle/cluster"
          man "sas/orchestration/lifecycle/manifest"
        )
        func main() {
          manifest := lifecycle.Arg("manifest")
          namespace := lifecycle.Arg("namespace")
  
          manifestInfo := getManifestInfo(manifest)
          if manifestInfo == nil {
            return // should this be a failure?
          }
  
          clusterInfo := getClusterInfo(namespace)
          err := ca.VerifyUpdateIsAllowed(clusterInfo, manifestInfo)
          if err != nil {
            lifecycle.Fail(err.Error())
          }
        }
        func getManifestInfo(manifest string) ca.CadenceInfo {
          manifestConfigMaps, err := man.Resources(manifest, man.Kind("ConfigMap"), man.LabelSelector("orchestration.sas.com/lifecycle=metadata"))
          if err != nil {
            panic(err)
          }
          switch len(manifestConfigMaps) {
          case 0:
            return nil
          case 1:
            return ca.NewCadenceInfoFromConfigMap(manifestConfigMaps[0])
          default:
            panic("Error: Failed to find a unique lifecycle metadata ConfigMap in the manifest")
          }
        }
        func getClusterInfo(namespace string) ca.CadenceInfo {
          clusterConfigMaps, err := cls.Resources(cls.Namespace(namespace), cls.Resource("ConfigMap"), cls.LabelSelector("orchestration.sas.com/lifecycle=metadata"))
          if err != nil {
            panic(err)
          }
          switch len(clusterConfigMaps) {
          case 0:
            return nil
          case 1:
            return ca.NewCadenceInfoFromConfigMap(clusterConfigMaps[0])
          default:
            panic("Error: Failed to find a unique lifecycle metadata ConfigMap in the cluster")
          }
        }
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-access-config
literals:
- COPLIB=/opt/sas/viya/home/lib64/accessclients/teradata/20.00/etc
- DB2=
- DB2_BIN=
- DELIMIDENT=
- DIRLAX=
- DSQUERY=
- GOMEMLIMIT=2147483647
- HANA=
- IMPALA=
- IMPALA_INTERNAL=/opt/sas/viya/home/lib64/accessclients/impala/lib
- IQDIR16=
- JDBCDRIVERS=/data-drivers/jdbc:/opt/sas/viya/home/lib64/accessclients/jdbc
- MARIADB_PLUGIN_DIR=/opt/sas/viya/home/lib64/accessclients/lib/mariadb_plugin
- MONGODB=
- MYSQL=
- NETEZZA=
- NZ_ODBC_INI_PATH=
- ODBCHOME=/opt/sas/viya/home/lib64/accessclients
- ODBCINI=/opt/sas/viya/home/lib64/accessclients/odbc.ini
- ODBCINST=/opt/sas/viya/home/lib64/accessclients/odbcinst.ini
- ODBCSYSINI=/opt/sas/viya/home/lib64/accessclients/
- ORACLE=/opt/sas/viya/home/lib64/accessclients/oracle/19.22/client64/lib
- ORACLE_BIN=/opt/sas/viya/home/lib64/accessclients/oracle/19.22/client64/bin
- POSTGRES=/opt/sas/viya/home/lib64
- R3=
- SAPCRYPTO_LIB=
- SAPIQ=
- SAPIQ_BIN=
- SASODBC=/opt/sas/viya/home/lib64/accessclients/lib
- SAS_EXT_CLSPTH_ACCESS=
- SAS_EXT_LLP_ACCESS=/opt/sas/viya/home/lib64/accessclients/lib:/opt/sas/viya/home/lib64:/opt/sas/viya/home/lib64/accessclients/oracle/19.22/client64/lib:/opt/sas/viya/home/lib64/accessclients/impala/lib:/opt/sas/viya/home/lib64/accessclients/teradata/20.00/lib64:/opt/sas/viya/home/lib64/accessclients/vertica/lib64
- SAS_EXT_PATH_ACCESS=/opt/sas/viya/home/lib64/accessclients/oracle/19.22/client64/bin
- SECUDIR=
- SIMBAIMPALAINI=/opt/sas/viya/home/lib64/accessclients/impala/setup/simba.impalaodbc.ini
- SYBASE=
- SYBASELIBS=
- SYBASE_BIN=
- SYB_SAS_BULK_NOTE=1
- TERADATA=/opt/sas/viya/home/lib64/accessclients/teradata/20.00/lib64
- THIRD_PARTY_BIN=
- THIRD_PARTY_LIB=
- TNS_ADMIN=
- UNIXODBC=
- VERTICA=/opt/sas/viya/home/lib64/accessclients/vertica/lib64
- VERTICAINI=/opt/sas/viya/home/lib64/accessclients/vertica/vertica.ini
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-activities-parameters
literals:
- SAS_CONTEXT_PATH=activities
- SAS_DU_NAME=sas-content
- SAS_SERVICE_NAME=sas-activities
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-admin-content-loader-parameters
literals:
- SAS_DU_NAME=sas-admin-content-loader
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-components-parameters
literals:
- SAS_CONTEXT_PATH=analyticsComponents
- SAS_PORT_NAME=aacomponents
- SAS_SERVICE_NAME=sas-analytics-components
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-data-segmentation-parameters
literals:
- SAS_CONTEXT_PATH=analyticsDataSegmentation
- SAS_PORT_NAME=aasegmentatn
- SAS_SERVICE_NAME=sas-analytics-data-segmentation
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-events-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=analyticsEvents
- SAS_DU_NAME=sas-analytics-events
- SAS_SERVICE_NAME=sas-analytics-events
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=analytics-events
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-execution-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=analyticsExecution
- SAS_DU_NAME=sas-analytics-execution
- SAS_SERVICE_NAME=sas-analytics-execution
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=analytics-execution
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-flows-parameters
literals:
- SAS_CONTEXT_PATH=analyticsFlows
- SAS_PORT_NAME=aaflows
- SAS_SERVICE_NAME=sas-analytics-flows
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-gateway-parameters
literals:
- SAS_CONTEXT_PATH=analyticsGateway
- SAS_DU_NAME=sas-analytics-gateway
- SAS_SERVICE_NAME=sas-analytics-gateway
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-localization-parameters
literals:
- SAS_CONTEXT_PATH=analyticsLocalization
- SAS_PORT_NAME=aacaploclztn
- SAS_SERVICE_NAME=sas-analytics-localization
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-pipelines-parameters
literals:
- SAS_CONTEXT_PATH=analyticsPipelines
- SAS_PORT_NAME=aapipelines
- SAS_SERVICE_NAME=sas-analytics-pipelines
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-resources-root-parameters
literals:
- ANALYTICS_RESOURCES_DB_MIGRATION_MAJOR_VERSION=22
- ANALYTICS_SERVICES_DB_MIGRATION_MAJOR_VERSION=2
- CNTR_REPO_PREFIX=convoy
- SAS_DU_NAME=sas-analytics-resources
- SAS_SERVICE_NAME=sas-analytics-resources
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=analytics-resources
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-analytics-validation-parameters
literals:
- SAS_CONTEXT_PATH=analyticsValidation
- SAS_PORT_NAME=aavalidation
- SAS_SERVICE_NAME=sas-analytics-validation
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-annotations-parameters
literals:
- SAS_CONTEXT_PATH=annotations
- SAS_DU_NAME=sas-annotations
- SAS_SERVICE_NAME=sas-annotations
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=annotations
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-app-registry-parameters
literals:
- SAS_CONTEXT_PATH=appRegistry
- SAS_DU_NAME=sas-app-registry
- SAS_SERVICE_NAME=sas-app-registry
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=app-registry
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-arke-parameters-5d8gh79f67
literals:
- SAS_DU_NAME=sas-arke
- SAS_SERVICE_NAME=sas-arke
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-audit-parameters
literals:
- SAS_CONTEXT_PATH=audit
- SAS_DU_NAME=sas-audit
- SAS_SERVICE_NAME=sas-audit
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=audit
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-authorization-parameters
literals:
- SAS_CONTEXT_PATH=authorization
- SAS_DU_NAME=sas-authorization
- SAS_SERVICE_NAME=sas-authorization
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-backup-agent-parameters
literals:
- SAS_CONTEXT_PATH=backupagent
- SAS_DU_NAME=sas-backup-agent
- SAS_SERVICE_NAME=sas-backup-agent
- SAS_TOOL_RETRY_LIMIT=100
- SAS_TOOL_RETRY_PERIOD=1m
- SG_PROJECT=backup-agent
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-backup-job-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- FILE_SYSTEM_BACKUP_FORMAT=tar
- JOB_TIME_OUT=1200
- RETENTION_PERIOD=30
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_DU_NAME=backup
- SAS_SERVICE_NAME=sas-backup-job
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=backup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-backup-purge-job-parameters-27t7c875g7
literals:
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_CRONJOB_NAME=sas-backup-purge-job
- SAS_DU_NAME=sas-backup-job
- SAS_SERVICE_NAME=sas-backup-job
options:
  labels:
    app.kubernetes.io/name: sas-backup-purge-job
    sas.com/admin: namespace
    sas.com/backup-job-type: purge-backup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-backup-pv-copy-cleanup-job-parameters-bbgkfgdht8
literals:
- OAUTH2_CLIENT_ACCESSTOKENVALIDITY=72000
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_CRONJOB_NAME=sas-backup-pv-copy-cleanup-job
- SAS_DU_NAME=sas-backup-job
- SAS_SERVICE_NAME=sas-backup-pv-copy-cleanup-job
options:
  labels:
    app.kubernetes.io/name: sas-backup-pv-copy-cleanup-job
    sas.com/admin: namespace
    sas.com/backup-job-type: sas-backup-pv-copy-cleanup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-batch-cmd-pod-template-parameters
literals:
- SAS_CONTAINER_NAME=sas-batch-cmd
- SAS_SERVICE_NAME=sas-batch-cmd-pod-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-batch-parameters
literals:
- SAS_CONTEXT_PATH=batch
- SAS_DU_NAME=sas-batch
- SAS_SERVICE_NAME=sas-batch
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=batch
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-batch-pod-template-parameters
literals:
- SAS_SERVICE_NAME=sas-batch-pod-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-batch-server-config
literals:
- BATCHSERVER_AUTOEXEC_USERMODS_FILE=autoexec_usermods.sas
- BATCHSERVER_CONFIG_USERMODS_FILE=sasv9_usermods.cfg
- BATCHSERVER_SCRIPT_USERMODS_FILE=batchserver_usermods.sh
- BATCHSERVER_USER_CONFIG=/config/
- CONNECTSERVER_AUTOEXEC_USERMODS_FILE=autoexec_usermods.sas
- CONNECTSERVER_CONFIG_USERMODS_FILE=sasv9_usermods.cfg
- CONNECTSERVER_LOGCFG_USERMODS_FILE=logconfig.xml
- CONNECTSERVER_SCRIPT_USERMODS_FILE=connectserver_usermods.sh
- CONNECTSERVER_USER_CONFIG=/config/connectserver/
- SAS_INIT_CONFIG_FILE1=batchserver_usermods.sh
- SAS_INIT_CONFIG_FILE2=sasv9_usermods.cfg
- SAS_INIT_CONFIG_FILE3=autoexec_usermods.sas
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_AUTOEXEC=connectserver/autoexec_usermods.sas
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_LOG_CFG=connectserver/logconfig.xml
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_USERMODS=connectserver/connectserver_usermods.sh
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_V9USERMODS=connectserver/sasv9_usermods.cfg
- SAS_INIT_CONFIG_FILE_RESTROPTS=rsasv9.cfg
- SAS_INIT_CONFIG_KEY1=config/batch/sas.batch.server/startup_commands/contents
- SAS_INIT_CONFIG_KEY2=config/batch/sas.batch.server/configuration_options/contents
- SAS_INIT_CONFIG_KEY3=config/batch/sas.batch.server/autoexec_code/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_AUTOEXEC=config/connect-spawner-viya/sas.connect.server/autoexec_code/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_LOG_CFG=config/connect-spawner-viya/sas.connect.server/logconfig/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_USERMODS=config/connect-spawner-viya/sas.connect.server/startup_commands/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_V9USERMODS=config/connect-spawner-viya/sas.connect.server/configuration_options/contents
- SAS_INIT_CONFIG_KEY_RESTROPTS=config/batch/sas.batch.server/restricted_options/contents
- SAS_LANG_FILE_IN=/config/batchserver_usermods.sh
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-business-rules-parameters
literals:
- SAS_CONTEXT_PATH=businessRules
- SAS_SERVICE_NAME=sas-business-rules
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-access-management-parameters
literals:
- SAS_CONTEXT_PATH=casAccessManagement
- SAS_PORT_NAME=casacl
- SAS_SERVICE_NAME=sas-cas-access-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-control-parameters
literals:
- SAS_CONTEXT_PATH=sas-cas-control
- SAS_DU_NAME=sas-cas-control
- SAS_PORT_NAME=cas-control
- SAS_SERVICE_NAME=sas-cas-control
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=cas-control
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-formats-parameters
literals:
- SAS_CONTEXT_PATH=casFormats
- SAS_PORT_NAME=cas-formats
- SAS_SERVICE_NAME=sas-cas-formats
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-management-parameters
literals:
- SAS_CONTEXT_PATH=casManagement
- SAS_PORT_NAME=casmanagement
- SAS_SERVICE_NAME=sas-cas-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-operator-parameters
literals:
- SAS_DU_NAME=sas-cas-operator
- SAS_SERVICE_NAME=sas-cas-operator
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-pod-template-parameters
literals:
- SAS_SERVICE_NAME=sas-cas-pod-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-proxy-parameters
literals:
- SAS_CONTEXT_PATH=casProxy
- SAS_PORT_NAME=casproxy
- SAS_SERVICE_NAME=sas-cas-proxy
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-cas-row-sets-parameters
literals:
- SAS_CONTEXT_PATH=casRowSets
- SAS_PORT_NAME=cas-row-sets
- SAS_SERVICE_NAME=sas-cas-row-sets
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-database-config
literals:
- SAS_CATALOG_PERSISTENCE=postgres
- SAS_DATABASE_MAXACTIVE=22
- SAS_STORAGE_SQL_ERRORS_AT_DEBUG=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-job-config
literals:
- CATALOG_EXECUTION_MODE=job
- SAS_CATALOG_JOB_NAME=sas-catalog-job
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-parameters
literals:
- SAS_CONTEXT_PATH=catalog
- SAS_PORT_NAME=catalog
- SAS_SERVICE_NAME=sas-catalog
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-security-config
literals:
- SAS_CATALOG_ENHANCED_SECURITY=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-services-config
literals:
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-services-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_DU_NAME=sas-catalog-services
- SAS_PORT_NAME=catalog-services
- SAS_SERVICE_NAME=sas-catalog-services
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_GO_TEST_TIMEOUT=20m
- SG_PROJECT=catalog
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-catalog-table-bot-parameters
literals:
- SAS_CONTEXT_PATH=catalogTableBot
- SAS_PORT_NAME=catalogtablebot
- SAS_SERVICE_NAME=sas-catalog-table-bot
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-category-taxonomy-parameters
literals:
- SAS_CONTEXT_PATH=categoryTaxonomy
- SAS_DU_NAME=sas-text-analytics-taxonomies
- SAS_SERVICE_NAME=sas-category-taxonomy
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-certframe-config
literals:
- SAS_CERTIFICATE_CA_CERTIFICATE_FILE=/security/ca.crt
- SAS_CERTIFICATE_FILE=/security/tls.crt
- SAS_CERTIFICATE_PRIVATE_KEY_FILE=/security/tls.key
- SAS_TRUSTED_CA_CERTIFICATES_JKS_FILE=/security/trustedcerts.jks
- SAS_TRUSTED_CA_CERTIFICATES_PEM_FILE=/security/trustedcerts.pem
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-certframe-ingress-certificate-config
literals:
- SAS_INGRESS_CERTIFICATE_SECRET_NAME=
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-certframe-java-config
literals:
- SAS_CERTIFICATE_FILE=/security/cert.jks
- SAS_TRUSTED_CA_CERTIFICATES_JKS_FILE=/security/trustedcerts.jks
- SAS_TRUSTED_CA_CERTIFICATES_PEM_FILE=/security/trustedcerts.pem
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-certframe-truststore-config
literals:
- CAS_CLIENT_SSL_CA_LIST=/security/trustedcerts.pem
- JAVA_GLOBAL_OPTION_TRUSTSTORE=-Djavax.net.ssl.trustStore=/security/trustedcerts.jks
- JAVA_GLOBAL_OPTION_TRUSTSTORE_PASSWORD=-Djavax.net.ssl.trustStorePassword=changeit
- JAVA_GLOBAL_OPTION_TRUSTSTORE_TYPE=-Djavax.net.ssl.trustStoreType=jks
- REQUESTS_CA_BUNDLE=/security/trustedcerts.pem
- SAS_TRUSTED_CA_CERTIFICATES_JKS_FILE=/security/trustedcerts.jks
- SAS_TRUSTED_CA_CERTIFICATES_PEM_FILE=/security/trustedcerts.pem
- SSL_CERT_FILE=/security/trustedcerts.pem
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-certframe-user-config
literals:
- SAS_CA_CERTIFICATE_SECRET_NAME=sas-viya-ca-certificate-secret
- SAS_CERTIFICATE_GENERATOR=openssl
- SAS_CERTIFICATE_INGRESS_SAN_DNS=$(INGRESS_HOST)
- SAS_CERTIFICATE_ISSUER=sas-viya-issuer
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-code-debugger-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASCodeDebugger
- SAS_DU_NAME=sas-code-debugger-app
- SAS_SERVICE_NAME=sas-code-debugger-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=code-debugger-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-code-debugger-parameters
literals:
- SAS_CONTEXT_PATH=codeDebugger
- SAS_DU_NAME=sas-code-debugger
- SAS_SERVICE_NAME=sas-code-debugger
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=code-debugger
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-collaboration-parameters
literals:
- SAS_CONTEXT_PATH=collaboration
- SAS_DU_NAME=sas-collaboration
- SAS_ENTITY_REAPER_ENABLED=true
- SAS_ENTITY_REAPER_INTERVAL=24h
- SAS_ENTITY_REAPER_RETENTION=720h
- SAS_SERVICE_NAME=sas-collaboration
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=collaboration
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-comments-parameters
literals:
- SAS_CONTEXT_PATH=comments
- SAS_SERVICE_NAME=sas-comments
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-commonfiles-parameters
literals:
- SAS_CONTEXT_PATH=commonfiles
- SAS_DU_NAME=sas-commonfiles
- SAS_JOB_NAME=sas-commonfiles
- SAS_SERVICE_NAME=sas-commonfiles
options:
  labels:
    app.kubernetes.io/name: sas-commonfiles
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-compute-config
literals:
- SAS_HTTP_CLIENT_TIMEOUT_REQUEST=600s
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-compute-job-config-parameters
literals:
- SAS_SERVICE_NAME=sas-compute-job-config
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-compute-parameters
literals:
- SAS_CONTEXT_PATH=compute
- SAS_DU_NAME=sas-compute
- SAS_SERVICE_NAME=sas-compute
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=compute
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-compute-server-config
literals:
- AUTOEXEC_USERMODS_FILE=autoexec.sas
- COMPUTESERVER_USER_CONFIG=/config/
- COMPUTESERVER_VAR_PATH=/viya/
- CONFIG_USERMODS_FILE=sasv9.cfg
- CONNECTSERVER_AUTOEXEC_USERMODS_FILE=autoexec_usermods.sas
- CONNECTSERVER_CONFIG_USERMODS_FILE=sasv9_usermods.cfg
- CONNECTSERVER_LOGCFG_USERMODS_FILE=logconfig.xml
- CONNECTSERVER_SCRIPT_USERMODS_FILE=connectserver_usermods.sh
- CONNECTSERVER_USER_CONFIG=/config/connectserver/
- SAS_INIT_CONFIG_FILE1=autoexec.sas
- SAS_INIT_CONFIG_FILE2=sasv9.cfg
- SAS_INIT_CONFIG_FILE3=startscript.sh
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_AUTOEXEC=connectserver/autoexec_usermods.sas
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_LOG_CFG=connectserver/logconfig.xml
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_USERMODS=connectserver/connectserver_usermods.sh
- SAS_INIT_CONFIG_FILE_CONNECTSERVER_V9USERMODS=connectserver/sasv9_usermods.cfg
- SAS_INIT_CONFIG_FILE_LOGCONFIG=logconfig.xml
- SAS_INIT_CONFIG_FILE_RESTROPTS=rsasv9.cfg
- SAS_INIT_CONFIG_KEY1=config/compute/sas.compute.server/autoexec_code/contents
- SAS_INIT_CONFIG_KEY2=config/compute/sas.compute.server/configuration_options/contents
- SAS_INIT_CONFIG_KEY3=config/compute/sas.compute.server/startup_commands/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_AUTOEXEC=config/connect-spawner-viya/sas.connect.server/autoexec_code/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_LOG_CFG=config/connect-spawner-viya/sas.connect.server/logconfig/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_USERMODS=config/connect-spawner-viya/sas.connect.server/startup_commands/contents
- SAS_INIT_CONFIG_KEY_CONNECTSERVER_V9USERMODS=config/connect-spawner-viya/sas.connect.server/configuration_options/contents
- SAS_INIT_CONFIG_KEY_LOGCONFIG=config/compute/sas.compute.server/logconfig/contents
- SAS_INIT_CONFIG_KEY_RESTROPTS=config/compute/sas.compute.server/restricted_options/contents
- SAS_LANG_FILE_IN=/config/startscript.sh
- SCRIPT_USERMODS_FILE=startscript.sh
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-concept-taxonomy-parameters
literals:
- SAS_CONTEXT_PATH=conceptTaxonomy
- SAS_DU_NAME=sas-text-analytics-taxonomies
- SAS_SERVICE_NAME=sas-concept-taxonomy
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-config-reconciler-parameters
literals:
- SAS_CONTEXT_PATH=configReconciler
- SAS_DU_NAME=sas-configuration
- SAS_SERVICE_NAME=sas-config-reconciler
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-configuration-child-parameters
literals:
- SAS_CONTEXT_PATH=configuration
- SAS_DU_NAME=sas-configuration
- SAS_SERVICE_NAME=sas-configuration
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-configuration-parameters
literals:
- SAS_CONTEXT_PATH=configuration
- SAS_DU_NAME=sas-configuration
- SAS_SERVICE_NAME=sas-configuration
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=configuration
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-connect-parameters
literals:
- SAS_CONTEXT_PATH=connect
- SAS_DU_NAME=sas-connect
- SAS_SERVICE_NAME=sas-connect
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=connect
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-connect-pod-template-parameters
literals:
- SAS_SERVICE_NAME=sas-connect-pod-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-connect-spawner-config
literals:
- CONNECTSERVER_AUTOEXEC_USERMODS_FILE=autoexec_usermods.sas
- CONNECTSERVER_CONFIG_USERMODS_FILE=sasv9_usermods.cfg
- CONNECTSERVER_LOGCFG_USERMODS_FILE=logconfig.xml
- CONNECTSERVER_SCRIPT_USERMODS_FILE=connectserver_usermods.sh
- CONNECTSERVER_USER_CONFIG=/config/connectserver/
- CONNECTSPAWNER_SCRIPT_USERMODS_FILE=connect_usermods.sh
- CONNECTSPAWNER_USER_CONFIG=/config/
- SASCLOUDNATIVE=1
- SAS_INIT_CONFIG_FILE1=connect_usermods.sh
- SAS_INIT_CONFIG_FILE2=connectserver/connectserver_usermods.sh
- SAS_INIT_CONFIG_FILE3=connectserver/sasv9_usermods.cfg
- SAS_INIT_CONFIG_FILE4=connectserver/autoexec_usermods.sas
- SAS_INIT_CONFIG_FILE5=connectserver/rsasv9.cfg
- SAS_INIT_CONFIG_FILE6=customlogconfig-spawner.xml
- SAS_INIT_CONFIG_FILE7=connectserver/logconfig.xml
- SAS_INIT_CONFIG_KEY1=config/connect-spawner-viya/sas.connect.spawner/startup_commands/contents
- SAS_INIT_CONFIG_KEY2=config/connect-spawner-viya/sas.connect.server/startup_commands/contents
- SAS_INIT_CONFIG_KEY3=config/connect-spawner-viya/sas.connect.server/configuration_options/contents
- SAS_INIT_CONFIG_KEY4=config/connect-spawner-viya/sas.connect.server/autoexec_code/contents
- SAS_INIT_CONFIG_KEY5=config/connect-spawner-viya/sas.connect.server/restricted_options/contents
- SAS_INIT_CONFIG_KEY6=config/connect-spawner-viya/sas.connect.spawner/logconfig/contents
- SAS_INIT_CONFIG_KEY7=config/connect-spawner-viya/sas.connect.server/logconfig/contents
- SAS_LANG_FILE_IN=/config/connectserver/connectserver_usermods.sh
- USERMODS=-NOSCRIPT
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-connect-spawner-parameters
literals:
- SAS_DU_NAME=sas-connect-spawner
- SAS_SERVICE_NAME=sas-connect-spawner
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-consul-config
literals:
- SITEDEFAULT_CONF=
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-consul-server-parameters
literals:
- SAS_DU_NAME=sas-consul-server
- SAS_SERVICE_NAME=sas-consul-server
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-content-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=content
- SAS_DU_NAME=sas-content
- SAS_SERVICE_NAME=sas-content
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=content
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-credentials-parameters
literals:
- SAS_CONTEXT_PATH=credentials
- SAS_DU_NAME=sas-credentials
- SAS_SERVICE_NAME=sas-credentials
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-crossdomainproxy-parameters
literals:
- SAS_CONTEXT_PATH=crossdomainproxy
- SAS_DU_NAME=sas-geography
- SAS_SERVICE_NAME=sas-crossdomainproxy
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-customer-provided-ca-certificates
literals:
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-agent-content-parameters
literals:
- SAS_CONTEXT_PATH=dataAgentContent
- SAS_PORT_NAME=dagentcont
- SAS_SERVICE_NAME=sas-data-agent-content
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-agent-management-parameters
literals:
- SAS_CONTEXT_PATH=dataAgentManagement
- SAS_PORT_NAME=dagentmgmt
- SAS_SERVICE_NAME=sas-data-agent-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-agent-server-colocated-config
literals:
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-agent-server-colocated-parameters
literals:
- SAS_CONTEXT_PATH=dataAgentServerColocated
- SAS_DU_NAME=sas-data-agent-server-colocated
- SAS_SERVICE_NAME=sas-data-agent-server-colocated
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-agent-services-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_DU_NAME=sas-data-agent-services
- SAS_PORT_NAME=da-services
- SAS_SERVICE_NAME=sas-data-agent-services
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-agent
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-connections-parameters
literals:
- SAS_CONTEXT_PATH=dataConnections
- SAS_PORT_NAME=dataconnections
- SAS_SERVICE_NAME=sas-data-connections
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-explorer-app-parameters
literals:
- JAVA_OPTION_FJPCP=java.util.concurrent.ForkJoinPool.common.parallelism=16
- SAS_CONTEXT_PATH=SASDataExplorer
- SAS_DU_NAME=sas-data-explorer-app
- SAS_SERVICE_NAME=sas-data-explorer-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-flows-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- GO_LINT_CONTINUE_ON_ERROR=true
- SAS_CONTEXT_PATH=dataFlows
- SAS_DU_NAME=sas-data-flows
- SAS_SERVICE_NAME=sas-data-flows
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-flows
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-models-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningModels
- SAS_SERVICE_NAME=sas-data-mining-models
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-parameters
literals:
- SAS_CONTEXT_PATH=dataMining
- SAS_SERVICE_NAME=sas-data-mining
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-project-resources-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningProjectResources
- SAS_SERVICE_NAME=sas-data-mining-project-resources
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-project-resources-root-parameters
literals:
- AACS_L10N_EN_FILE_SUFFIX=/*NLG.properties
- AACS_L10N_PATH=_resources/nlg/nls
- AACS_L10N_TAG=NLG
- NLG_LOCALIZER_VERSION=v0.8.0
- NLG_TESTER_IMAGE=pulp.unx.sas.com/viya-4-x64_oci_linux_2-docker/nlg-tester:0.8.0-20241024.1729782792607
- SAS_CONTEXT_PATH=sas-data-mining-project-resources
- SAS_DU_NAME=sas-data-mining-project-resources
- SAS_PORT_NAME=data-mining-project-resources
- SAS_SERVICE_NAME=sas-data-mining-project-resources
- SG_CODEGEN_IMAGE=registry.unx.sas.com/aiml-common-components/go-server-codegen:0.0.5
- SG_CODEGEN_YAML=codegen/openapi-codegen.yaml
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-mining-project-resources
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-project-settings-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningProjectSettings
- SAS_SERVICE_NAME=sas-data-mining-project-settings
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-results-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningResults
- SAS_SERVICE_NAME=sas-data-mining-results
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-results-root-parameters
literals:
- SAS_CONTEXT_PATH=sas-data-mining-results
- SAS_DU_NAME=sas-data-mining-results
- SAS_SERVICE_NAME=sas-data-mining-results
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_HOOK_IMAGE=registry.unx.sas.com/convoy-devops/pre-commit:1.8.2
- SG_PROJECT=data-mining-results
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-risk-models-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningRiskModels
- SAS_DU_NAME=sas-data-mining-risk-models
- SAS_SERVICE_NAME=sas-data-mining-risk-models
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-mining-risk-models
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-mining-warehouse-parameters
literals:
- SAS_CONTEXT_PATH=dataMiningWarehouse
- SAS_SERVICE_NAME=sas-data-mining-warehouse
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-quality-monitoring-parameters
literals:
- SAS_CONTEXT_PATH=dataQualityMonitoring
- SAS_PORT_NAME=dqmonitoring
- SAS_SERVICE_NAME=sas-data-quality-monitoring
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-quality-parameters
literals:
- SAS_CONTEXT_PATH=dataQuality
- SAS_PORT_NAME=dataquality
- SAS_SERVICE_NAME=sas-data-quality
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-quality-services-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_DU_NAME=sas-data-quality-services
- SAS_PORT_NAME=dq-services
- SAS_SERVICE_NAME=sas-data-quality-services
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-quality
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-server-operator-parameters
literals:
- SAS_CUSTOM_RESOURCE_API_GROUP=webinfdsvr.sas.com
- SAS_CUSTOM_RESOURCE_NAME=dataserver
- SAS_CUSTOM_RESOURCE_NAME_PLURAL=dataservers
- SAS_DU_NAME=sas-data-server-operator
- SAS_SERVICE_NAME=sas-data-server-operator
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-server
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-sources-parameters
literals:
- SAS_CONTEXT_PATH=dataSources
- SAS_PORT_NAME=datasources
- SAS_SERVICE_NAME=sas-data-sources
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-sources-root-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_DU_NAME=sas-data-sources
- SAS_PORT_NAME=data-sources
- SAS_SERVICE_NAME=sas-data-sources
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=data-sources
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-data-tables-parameters
literals:
- SAS_CONTEXT_PATH=dataTables
- SAS_PORT_NAME=datatables
- SAS_SERVICE_NAME=sas-data-tables
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-decision-manager-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASDecisionManager
- SAS_DU_NAME=sas-decision-manager-app
- SAS_SERVICE_NAME=sas-decision-manager-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=decision-manager
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-decisions-framework-parameters
literals:
- SAS_DU_NAME=sas-decisions-framework
- SAS_SERVICE_NAME=sas-decisions-framework
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-decisions-parameters
literals:
- SAS_CONTEXT_PATH=decisions
- SAS_SERVICE_NAME=sas-decisions
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-decisions-runtime-builder-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=decisionsRuntimeBuilder
- SAS_DU_NAME=sas-decisions-runtime-builder
- SAS_SERVICE_NAME=sas-decisions-runtime-builder
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=decisions-runtime-builder
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-deployment-data-parameters
literals:
- SAS_CONTEXT_PATH=deploymentData
- SAS_DU_NAME=sas-deployment-data
- SAS_SERVICE_NAME=sas-deployment-data
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_PROJECT=deployment-data
- SG_TEST_TAGS=testca
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-deployment-metadata
literals:
- SAS_BASE_CADENCE_NAME=stable
- SAS_BASE_CADENCE_VERSION=2025.09
- SAS_BUILD_TYPE=x64_oci_linux_2-docker
- SAS_CADENCE_DISPLAY_NAME=Long-Term Support 2025.09
- SAS_CADENCE_DISPLAY_SHORT_NAME=Long-Term Support
- SAS_CADENCE_DISPLAY_VERSION=2025.09
- SAS_CADENCE_NAME=lts
- SAS_CADENCE_RELEASE=20251127.1764249807241
- SAS_CADENCE_UPDATABLE_FROMS=lts-2025.03,stable-2025.09,stable-2025.06,stable-2025.07,stable-2025.08
- SAS_CADENCE_VERSION=2025.09
- SAS_DEPLOYMENT_TYPE=default
- SAS_REPOSITORY_WAREHOUSE_URL=https://ses.sas.com/ses/
options:
  labels:
    orchestration.sas.com/lifecycle: metadata
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-device-management-parameters
literals:
- SAS_CONTEXT_PATH=deviceManagement
- SAS_DU_NAME=sas-device-management
- SAS_SERVICE_NAME=sas-device-management
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=device-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-documents-parameters
literals:
- SAS_CONTEXT_PATH=documents
- SAS_DU_NAME=sas-text-analytics-data
- SAS_SERVICE_NAME=sas-documents
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-drive-app-parameters
literals:
- SAS_CONTEXT_PATH=SASDrive
- SAS_DU_NAME=sas-drive-app
- SAS_SERVICE_NAME=sas-drive-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=drive-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-drive-parameters
literals:
- SAS_CONTEXT_PATH=drive
- SAS_DU_NAME=sas-content
- SAS_SERVICE_NAME=sas-drive
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-environment-manager-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASEnvironmentManager
- SAS_DU_NAME=sas-environment-manager-app
- SAS_SERVICE_NAME=sas-environment-manager-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=sas-environment-manager-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-feature-flags-parameters
literals:
- SAS_CONTEXT_PATH=featureFlags
- SAS_DU_NAME=sas-configuration
- SAS_SERVICE_NAME=sas-feature-flags
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-file-store-parameters
literals:
- SAS_CONTEXT_PATH=file-store
- SAS_DU_NAME=sas-file-store
- SAS_SERVICE_NAME=sas-file-store
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=file-store
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-files-parameters
literals:
- SAS_CONTEXT_PATH=files
- SAS_DU_NAME=sas-files
- SAS_SERVICE_NAME=sas-files
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-folders-parameters
literals:
- SAS_CONTEXT_PATH=folders
- SAS_SERVICE_NAME=sas-folders
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-fonts-parameters
literals:
- SAS_CONTEXT_PATH=fonts
- SAS_DU_NAME=sas-web-assets
- SAS_SERVICE_NAME=sas-fonts
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-formats-parameters
literals:
- SAS_CONTEXT_PATH=formats
- SAS_DU_NAME=sas-formats
- SAS_FMTSRV_PAYLOAD_SIZE_LIMIT=280000
- SAS_FMTSRV_PORT=9080
- SAS_FMT_VALIDATE_JSON=true
- SAS_SERVICE_NAME=sas-formats
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=formats
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-gen-ai-gateway-parameters
literals:
- SAS_CONTEXT_PATH=genAiGateway
- SAS_DU_NAME=sas-gen-ai-gateway
- SAS_SERVICE_NAME=sas-gen-ai-gateway
- SG_FAIL_SEVERITY=warn
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=gen-ai-gateway
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-geo-enrichment-parameters
literals:
- SAS_CONTEXT_PATH=geoEnrichment
- SAS_DU_NAME=sas-geography
- SAS_SERVICE_NAME=sas-geo-enrichment
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-geography-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=geography
- SAS_DU_NAME=sas-geography
- SAS_SERVICE_NAME=sas-geography
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=geography
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-glossary-parameters
literals:
- SAS_CONTEXT_PATH=glossary
- SAS_PORT_NAME=glossary
- SAS_SERVICE_NAME=sas-glossary
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-go-config
literals:
- CONSUL_HTTP_ADDR=http://sas-consul-server:8500
- SAS_AUTH_KUBERNETES_SERVICE_ACCOUNT_ENABLED=true
- SAS_BOOTSTRAP_HTTP_CLIENT_TIMEOUT_REQUEST=5m
- SAS_RECONCILER_SERVICES_ENABLED=true
- SAS_REGISTRY_REGISTER_ENABLED=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-graph-builder-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASGraphBuilder
- SAS_DU_NAME=sas-graph-builder-app
- SAS_SERVICE_NAME=sas-graph-builder-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=graph-builder
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-graph-templates-parameters
literals:
- SAS_CONTEXT_PATH=graphTemplates
- SAS_DU_NAME=sas-graph-templates
- SAS_SERVICE_NAME=sas-graph-templates
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=graph-templates
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-identities-parameters
literals:
- SAS_CONTEXT_PATH=identities
- SAS_DU_NAME=sas-identities
- SAS_SERVICE_NAME=sas-identities
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-import-9-parameters
literals:
- SAS_CONTEXT_PATH=import9
- SAS_DU_NAME=sas-import-9
- SAS_SERVICE_NAME=sas-import-9
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-import-data-loader-parameters
literals:
- SAS_DU_NAME=sas-import-data-loader
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-information-catalog-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASInformationCatalog
- SAS_DU_NAME=sas-information-catalog-app
- SAS_SERVICE_NAME=sas-information-catalog-app
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=catalog-app
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-insights-parameters
literals:
- SAS_CONTEXT_PATH=insights
- SAS_DU_NAME=sas-insights
- SAS_FMTSRV_PORT=9080
- SAS_SERVICE_NAME=sas-insights
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=insights
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-inventory-collector-parameters
literals:
- SAS_DU_NAME=sas-inventory-collector
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-java-config
literals:
- CONSUL_HTTP_ADDR=http://sas-consul-server:8500
- JAVA_GLOBAL_OPTION_ADDOPENS1=--add-opens=java.base/java.lang=ALL-UNNAMED
- JAVA_GLOBAL_OPTION_ADDOPENS2=
- JAVA_GLOBAL_OPTION_CHECK_CRITICAL_TIMEOUT=-Dspring.cloud.consul.discovery.healthCheckCriticalTimeout=2h
- JAVA_GLOBAL_OPTION_CICOMPILERCOUNT=-XX:CICompilerCount=2
- JAVA_GLOBAL_OPTION_CONSUL_HOST=-Dspring.cloud.consul.host=sas-consul-server
- JAVA_GLOBAL_OPTION_CONSUL_SCHEME=-Dspring.cloud.consul.scheme=http
- JAVA_GLOBAL_OPTION_DISABLEENDPOINTS=-Dendpoints.enabled=false
- JAVA_GLOBAL_OPTION_ENABLEHEALTH=-Dendpoints.health.enabled=true
- JAVA_GLOBAL_OPTION_ENABLEMETRICS=-Dendpoints.metrics.enabled=true
- JAVA_GLOBAL_OPTION_EXPORTS=--add-exports=java.base/sun.security.internal.spec=ALL-UNNAMED
- JAVA_GLOBAL_OPTION_FORWARD_STRATEGY=-Dserver.forward-headers-strategy=NATIVE
- JAVA_GLOBAL_OPTION_GC_1=-XX:+UseParallelGC
- JAVA_GLOBAL_OPTION_GC_MAXFREEHEAP_RATIO=-XX:MaxHeapFreeRatio=40
- JAVA_GLOBAL_OPTION_GC_MINFREEHEAP_RATIO=-XX:MinHeapFreeRatio=15
- JAVA_GLOBAL_OPTION_INTERNAL_PROXIES=-Dserver.tomcat.remoteip.internal-proxies=(fe80|fd[0-9a-fA-F]{2})(:{1,2}[0-9a-fA-F]{0,4}){0,7}(%[0-9a-zA-Z]+)?$|::1|0:0:0:0:0:0:0:1|10\.\d{1,3}\.\d{1,3}\.\d{1,3}|192\.168\.\d{1,3}\.\d{1,3}|169\.254\.\d{1,3}\.\d{1,3}|127\.\d{1,3}\.\d{1,3}\.\d{1,3}|172\.1[6-9]{1}\.\d{1,3}\.\d{1,3}|172\.2[0-9]{1}\.\d{1,3}\.\d{1,3}|172\.3[0-1]{1}\.\d{1,3}\.\d{1,3}
- JAVA_GLOBAL_OPTION_JAVAAGENT1=-javaagent:/opt/sas/viya/home/libexec/filesystem-init-agent.jar
- JAVA_GLOBAL_OPTION_JAVAAGENT2=-javaagent:/opt/sas/viya/home/libexec/aspectjweaver.jar
- JAVA_GLOBAL_OPTION_LIMIT_NIO_BUFF=-Djdk.nio.maxCachedBufferSize=256000
- JAVA_GLOBAL_OPTION_MAXRAMPERCENTAGE=-XX:MaxRAMPercentage=75.0
- JAVA_GLOBAL_OPTION_MAX_DIRECT_MEM=-XX:MaxDirectMemorySize=64m
- JAVA_GLOBAL_OPTION_MSINTEROP=-Dsun.security.krb5.msinterop.kstring=true
- JAVA_GLOBAL_OPTION_NEWSIZE=-XX:NewSize=20m
- JAVA_GLOBAL_OPTION_REMOTEIP_HEADER=-Dserver.tomcat.remoteip.remote-ip-header=X-Forwarded-For
- JAVA_GLOBAL_OPTION_SASVAULTPKI_REUSEVALIDCERTIFICATE=-Dsas.vault.pki.reuseValidCertificate=false
- JAVA_GLOBAL_OPTION_SECURITY_EGD=-Djava.security.egd=file:/dev/urandom
- JAVA_GLOBAL_OPTION_SERVERSSLCIPHERS=-Dserver.ssl.ciphers=TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_AES_128_CCM_SHA256,TLS_AES_128_CCM_8_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
- JAVA_GLOBAL_OPTION_TRUSTSTORE=-Djavax.net.ssl.trustStore=/opt/sas/viya/config/etc/SASSecurityCertificateFramework/cacerts/trustedcerts.jks
- JAVA_GLOBAL_OPTION_TRUSTSTORETYPE=-Djavax.net.ssl.trustStoreType=jks
- JAVA_GLOBAL_OPTION_USESERVERCIPHERSUITESORDER=-Dserver.ssl.use-server-cipher-suites-order=true
- JAVA_GLOBAL_OPTION_XMLSECUREPROCESSING=-Djavax.xml.XMLConstants.FEATURE_SECURE_PROCESSING=true
- JAVA_GLOBAL_OPTION_XSS=-Xss320k
- JAVA_OPTION_GEODE_LOG=-Dlogging.level.org.apache.geode.internal.net.SocketCreator=ERROR
- JAVA_OPTION_SERVER_PORT=-Dserver.port=8080
- MALLOC_ARENA_MAX=1
- SASLOGROOT=
- SAS_AUTH_KUBERNETES_SERVICE_ACCOUNT_ENABLED=true
- SAS_CATALOG_SERVICE_ENABLED=true
- SAS_EVENT_CONFIGURATION_ARKE_ENABLED=true
- SAS_FEATURE_FLAGS_ENABLED=true
- SAS_GUEST_BOOTSTRAPPING_ENABLED=true
- SAS_LOG_FORMAT=json
- SAS_REGISTRY_REGISTER_ENABLED=false
- SAS_SERVICES_METRICS_SECURED=false
- SPRING_CLOUD_CONSUL_DISCOVERY_PREFERIPADDRESS=true
- SPRING_CLOUD_CONSUL_DISCOVERY_REGISTER=false
- SPRING_CLOUD_CONSUL_ENABLED=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-java-tls-config
literals:
- CONSUL_CACERT=/security/trustedcerts.pem
- JAVA_GLOBAL_OPTION_JAVA_SERVER_KEYSTORE=-Dserver.ssl.key-store=/security/cert.jks
- JAVA_GLOBAL_OPTION_JAVA_SERVER_KEYSTORE_PASSWORD=-Dserver.ssl.key-store-password=changeit
- JAVA_GLOBAL_OPTION_JAVA_SERVER_KEYSTORE_TYPE=-Dserver.ssl.key-store-type=jks
- JAVA_GLOBAL_OPTION_KEYSTORE=-Djavax.net.ssl.keyStore=/security/cert.jks
- JAVA_GLOBAL_OPTION_KEYSTORE_PASSWORD=-Djavax.net.ssl.keyStorePassword=changeit
- JAVA_GLOBAL_OPTION_KEYSTORE_TYPE=-Djavax.net.ssl.keyStoreType=jks
- JAVA_GLOBAL_OPTION_SSLENABLED=-Dsas.security.network.web.enabled=true
- JAVA_GLOBAL_OPTION_TRUSTSTORE=-Djavax.net.ssl.trustStore=/security/trustedcerts.jks
- JAVA_GLOBAL_OPTION_TRUSTSTORE_PASSWORD=-Djavax.net.ssl.trustStorePassword=changeit
- JAVA_GLOBAL_OPTION_TRUSTSTORE_TYPE=-Djavax.net.ssl.trustStoreType=jks
- JAVA_GLOBAL_OPTION_VAULTENABLED=-Dspring.cloud.vault.enabled=false
- SAS_CERTIFICATE_FILE=/security/cert.jks
- SAS_TRUSTED_CA_CERTIFICATES_JKS_FILE=/security/trustedcerts.jks
- SAS_TRUSTED_CA_CERTIFICATES_PEM_FILE=/security/trustedcerts.pem
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-definitions-parameters
literals:
- SAS_CONTEXT_PATH=jobDefinitions
- SAS_SERVICE_NAME=sas-job-definitions
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-execution-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASJobExecution
- SAS_DU_NAME=sas-job-execution-app
- SAS_SERVICE_NAME=sas-job-execution-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_K8S_KUSTOMIZE_VERSION=5
- SG_PROJECT=jobexecapp
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-execution-parameters
literals:
- SAS_CONTEXT_PATH=jobExecution
- SAS_SERVICE_NAME=sas-job-execution
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-execution-root-parameters
literals:
- SAS_DU_NAME=sas-job-execution
- SAS_SERVICE_NAME=sas-job-execution
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-flow-scheduling-flow-orchestrator-pod-template-parameters
literals:
- SAS_SERVICE_NAME=sas-job-flow-scheduling-flow-orchestrator-pod-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-job-flow-scheduling-parameters
literals:
- SAS_CONTEXT_PATH=jobFlowScheduling
- SAS_DU_NAME=sas-job-flow-scheduling
- SAS_SERVICE_NAME=sas-job-flow-scheduling
- SG_PROJECT=jobflow-scheduling
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-landing-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASLanding
- SAS_DU_NAME=sas-landing-app
- SAS_SERVICE_NAME=sas-landing-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=sas-landing-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-launcher-init-nls-config
literals:
- SAS_LAUNCHER_INIT_ENCODING_DEFAULT=utf8
- SAS_LAUNCHER_INIT_LOCALE_DEFAULT=en_US
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-launcher-job-config-parameters
literals:
- SAS_SERVICE_NAME=sas-launcher-job-config
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-launcher-lockdown-config
literals:
- VIYA_LOCKDOWN_DEFAULT_METHODS=http email git ftp hadoop java
- VIYA_LOCKDOWN_ENABLE=1
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-launcher-parameters
literals:
- SAS_CONTEXT_PATH=launcher
- SAS_DU_NAME=sas-launcher
- SAS_SERVICE_NAME=sas-launcher
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-licenses-parameters
literals:
- SAS_CONTEXT_PATH=licenses
- SAS_DU_NAME=sas-deployment-data
- SAS_SERVICE_NAME=sas-licenses
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-lineage-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASLineage
- SAS_DU_NAME=sas-lineage-app
- SAS_SERVICE_NAME=sas-lineage-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=sas-lineage-app
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-links-parameters
literals:
- SAS_CONTEXT_PATH=links
- SAS_DU_NAME=sas-visual-analytics-app
- SAS_SERVICE_NAME=sas-links
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-list-data-parameters
literals:
- SAS_CONTEXT_PATH=listData
- SAS_DU_NAME=sas-list-data
- SAS_SERVICE_NAME=sas-list-data
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=list-data
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-localization-parameters
literals:
- SAS_CONTEXT_PATH=localization
- SAS_DU_NAME=sas-localization
- SAS_SERVICE_NAME=sas-localization
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_HOOK_IMAGE=registry.unx.sas.com/convoy-devops/pre-commit:1.8.1
- SG_PROJECT=localization
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-logon-app-parameters
literals:
- SAS_CONTEXT_PATH=SASLogon
- SAS_DU_NAME=sas-logon-app
- SAS_SERVICE_NAME=sas-logon-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-mail-parameters
literals:
- SAS_CONTEXT_PATH=mail
- SAS_SERVICE_NAME=sas-mail
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-maps-parameters
literals:
- SAS_CONTEXT_PATH=maps
- SAS_DU_NAME=sas-geography
- SAS_SERVICE_NAME=sas-maps
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-metering-parameters
literals:
- SAS_CONTEXT_PATH=metering
- SAS_DU_NAME=sas-deployment-data
- SAS_SERVICE_NAME=sas-metering
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-microanalytic-score-db-config
literals:
- MAS_INT_LLP_ACCESS=/opt/sas/viya/home/lib64:/usr/lib/oracle/19.13/client64/lib:/opt/sas/viya/home/lib64/accessclients/lib
- MAS_INT_LLP_POSTGRES=/opt/sas/viya/home/postgresql16/lib64
- ODBCHOME=/opt/sas/viya/home/lib64/accessclients
- ODBCINI=/opt/sas/viya/home/lib64/accessclients/odbc.ini
- ODBCINSTINI=/opt/sas/viya/home/lib64/accessclients/odbcinst.ini
- ORACLE_HOME=/usr/lib/oracle/19.13/client64
- ORAENV_ASK=NO
- PGCLIENTENCODING=UTF-8
- SASORA=V9
- TWO_TASK=ORACLE_SID
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-microanalytic-score-parameters
literals:
- SAS_CONTEXT_PATH=microanalyticScore
- SAS_DU_NAME=sas-microanalytic-score
- SAS_SERVICE_NAME=sas-microanalytic-score
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-migration-manager-parameters
literals:
- SAS_CONTEXT_PATH=migrationManager
- SAS_DU_NAME=sas-migration-manager
- SAS_PORT_NAME=migration-manager
- SAS_SERVICE_NAME=sas-migration-manager
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=migration-manager
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-ml-pipeline-automation-parameters
literals:
- SAS_CONTEXT_PATH=mlPipelineAutomation
- SAS_DU_NAME=sas-ml-pipeline-automation
- SAS_SERVICE_NAME=sas-ml-pipeline-automation
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=ml-pipeline-automation
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-builder-job-parameters-dt44tfdh6k
literals:
- SAS_DU_NAME=sas-model-builder-job
- SAS_SERVICE_NAME=sas-model-builder-job
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-management-parameters
literals:
- SAS_CONTEXT_PATH=modelManagement
- SAS_DU_NAME=sas-model-manager
- SAS_SERVICE_NAME=sas-model-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-manager-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASModelManager
- SAS_DU_NAME=sas-model-manager-app
- SAS_SERVICE_NAME=sas-model-manager-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=model-manager-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-manager-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=modelManager
- SAS_DU_NAME=sas-model-manager
- SAS_SERVICE_NAME=sas-model-manager
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=model-manager
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-publish-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=modelPublish
- SAS_DU_NAME=sas-model-publish
- SAS_SERVICE_NAME=sas-model-publish
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_HOOK_IMAGE=registry.unx.sas.com/convoy-devops/pre-commit:1.8.1
- SG_PROJECT=model-publish
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-repository-parameters
literals:
- SAS_CONTEXT_PATH=modelRepository
- SAS_DU_NAME=sas-model-manager
- SAS_SERVICE_NAME=sas-model-repository
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-studio-app-ms-parameters-m45cb942hb
literals:
- SAS_CONTEXT_PATH=SASModelStudio
- SAS_SERVICE_NAME=sas-model-studio-app-ms
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-model-studio-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASModelStudio
- SAS_DU_NAME=sas-model-studio-app
- SAS_SERVICE_NAME=sas-model-studio-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=model-studio
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-natural-language-generation-parameters
literals:
- SAS_CONTEXT_PATH=naturalLanguageGeneration
- SAS_DU_NAME=sas-natural-language-generation
- SAS_SERVICE_NAME=sas-natural-language-generation
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-notifications-parameters
literals:
- SAS_CONTEXT_PATH=notifications
- SAS_SERVICE_NAME=sas-notifications
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-office-addin-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASOfficeAddin
- SAS_DU_NAME=sas-office-addin-app
- SAS_SERVICE_NAME=sas-office-addin-app
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=sas-office-addin-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-preferences-parameters
literals:
- SAS_CONTEXT_PATH=preferences
- SAS_DU_NAME=sas-preferences
- SAS_SERVICE_NAME=sas-preferences
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=preferences
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-prepull-parameters
literals:
- SAS_DU_NAME=sas-prepull
- SAS_PREPULL_CRCRB_INT=30
- SAS_PREPULL_DAEMON_INT=3600
- SAS_PREPULL_IMAGE_LIST=sas-programming-environment,sas-certframe,sas-config-init
- SAS_PREPULL_NODE_LABEL="workload.sas.com/class=compute"
- SAS_SERVICE_NAME=sas-prepull
options:
  labels:
    app.kubernetes.io/name: sas-prepull
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-process-exporter-template-parameters
literals:
- SAS_DU_NAME=sas-process-exporter
- SAS_SERVICE_NAME=sas-process-exporter-template
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-programming-environment-java-policy-config
literals:
- SAS_INIT_JRE_POLICY_AUTH=permission javax.security.auth.AuthPermission "*";
- SAS_INIT_JRE_POLICY_FILE=permission java.io.FilePermission "<<ALL FILES>>", "read, write, delete";
- SAS_INIT_JRE_POLICY_HADOOPPCP=permission javax.security.auth.PrivateCredentialPermission "org.apache.hadoop.security.Credentials * \"*\"", "read";
- SAS_INIT_JRE_POLICY_HADOOPPCP_2=permission javax.security.auth.PrivateCredentialPermission "javax.security.auth.kerberos.KerberosTicket * \"*\"", "read";
- SAS_INIT_JRE_POLICY_KERBEROS=permission javax.security.auth.kerberos.ServicePermission "*", "initiate";
- SAS_INIT_JRE_POLICY_NETPROXY=permission java.net.NetPermission "*";
- SAS_INIT_JRE_POLICY_PROPERTY=permission java.util.PropertyPermission "*", "read, write";
- SAS_INIT_JRE_POLICY_REFLECT=permission java.lang.reflect.ReflectPermission "suppressAccessChecks";
- SAS_INIT_JRE_POLICY_RUNTIME=permission java.lang.RuntimePermission "*";
- SAS_INIT_JRE_POLICY_SECURITY=permission java.security.SecurityPermission "*";
- SAS_INIT_JRE_POLICY_SERIALIZABLE=permission java.io.SerializablePermission "*";
- SAS_INIT_JRE_POLICY_SOCKET=permission java.net.SocketPermission "*", "connect,accept,listen";
- SAS_INIT_JRE_POLICY_SQL=permission java.sql.SQLPermission "*";
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-programming-environment-path-config
literals:
- SAS_SPRE_APP_BATCH=batch
- SAS_SPRE_APP_COMPUTE=compsrv
- SAS_SPRE_APP_CONNECT=connectserver
- SAS_SPRE_VAR_PATH=/opt/sas/viya/config/var
- SAS_SPRE_VAR_PATH_LOG=log
- SAS_SPRE_VAR_PATH_RUN=run
- SAS_SPRE_VAR_PATH_SPOOL=spool
- SAS_SPRE_VAR_PATH_TMP=tmp
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-pv-backup-parameters-mff5gb6fcc
literals:
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_DU_NAME=sas-backup-job
- SAS_PV_POD_NAME=sas-pv-backup-pod
- SAS_SERVICE_NAME=sas-pv-backup
options:
  labels:
    app.kubernetes.io/name: sas-pv-backup-pod
    sas.com/admin: namespace
    sas.com/backup-pod-type: pv-backup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-pv-restore-parameters-2g47gh792g
literals:
- SAS_SERVICE_NAME=sas-pv-restore
options:
  labels:
    app.kubernetes.io/name: sas-restore-job
    sas.com/admin: namespace
    sas.com/backup-job-type: restore
    sas.com/restore-pod-type: pv-restore
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-pyconfig-parameters
literals:
- SAS_CONTEXT_PATH=pyconfig
- SAS_CRONJOB_NAME=sas-pyconfig
- SAS_DU_NAME=sas-pyconfig
- SAS_SERVICE_NAME=sas-pyconfig
- default_py.cflags="-fPIC"
- default_py.configure_opts="--enable-optimizations"
- default_py.pip_extra_url="none"
- default_py.pip_index_url="none"
- default_py.pip_install_opts="--upgrade"
- default_py.pip_install_packages="Prophet sas_kernel matplotlib sasoptpy sas-esppy NeuralProphet scipy Flask XGBoost TensorFlow pybase64 scikit-learn statsmodels sympy mlxtend Skl2onnx nbeats-pytorch ESRNN onnxruntime opencv-python zipfile38 json2 pyenchant nltk spacy gensim pyarrow great-expectations numpy==1.26.4"
- default_py.pip_local_packages="false"
- default_py.pip_r_packages="rpy2"
- default_py.pip_r_profile="default_r"
- default_py.python_signature="https://www.python.org/ftp/python/3.11.10/Python-3.11.10.tgz.asc"
- default_py.python_signer="https://keybase.io/pablogsal/pgp_keys.asc"
- default_py.python_tarball="https://www.python.org/ftp/python/3.11.10/Python-3.11.10.tgz"
- default_r.cflags="-fPIC"
- default_r.configure_opts="--enable-memory-profiling --enable-R-shlib --with-blas --with-lapack --with-readline=no --with-x=no --enable-BLAS-shlib"
- default_r.packages="dplyr jsonlite httr tidyverse randomForest xgboost forecast arrow logger"
- default_r.pkg_repos="https://cran.rstudio.com/ http://cran.rstudio.com/ https://cloud.r-project.org/ http://cloud.r-project.org/"
- default_r.r_tarball="https://cloud.r-project.org/src/base/R-4/R-4.3.3.tar.gz"
- global.dry_run="false"
- global.enabled="false"
- global.http_proxy="none"
- global.https_proxy="none"
- global.pvc=/opt/sas/viya/home/sas-pyconfig
- global.python_enabled="false"
- global.python_profiles=default_py
- global.r_enabled="false"
- global.r_profiles=default_r
- global.status=uninitialized
options:
  labels:
    app.kubernetes.io/name: sas-pyconfig
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-qkb-bootstrap-parameters
literals:
- SAS_DU_NAME=sas-quality-knowledge-base
- SAS_SERVICE_NAME=sas-qkb-bootstrap
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-qkb-management-parameters
literals:
- SAS_CONTEXT_PATH=qkbManagement
- SAS_PORT_NAME=qkbmanagement
- SAS_SERVICE_NAME=sas-qkb-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-qkb-management-pvc-config
literals:
- qkbStorageSize=8Gi
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-rabbitmq-server-parameters-d85588dcbd
literals:
- SAS_DU_NAME=sas-rabbitmq-server
- SAS_SERVICE_NAME=sas-rabbitmq-server
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-readiness-parameters
literals:
- SAS_CONTEXT_PATH=readiness
- SAS_DU_NAME=sas-readiness
- SAS_SERVICE_NAME=sas-readiness
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=readiness
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-redis-server-parameters-48ccg72tt4
literals:
- SAS_DU_NAME=sas-redis-server
- SAS_SERVICE_NAME=sas-redis-server
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-reference-data-parameters
literals:
- SAS_CONTEXT_PATH=referenceData
- SAS_SERVICE_NAME=sas-reference-data
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-relationships-parameters
literals:
- SAS_CONTEXT_PATH=relationships
- SAS_PORT_NAME=relationships
- SAS_SERVICE_NAME=sas-relationships
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-alerts-parameters
literals:
- SAS_CONTEXT_PATH=reportAlerts
- SAS_DU_NAME=sas-report-alerts
- SAS_SERVICE_NAME=sas-report-alerts
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=report-alerts
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-data-parameters
literals:
- SAS_CONTEXT_PATH=reportData
- SAS_PORT_NAME=reportdata
- SAS_SERVICE_NAME=sas-report-data
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-distribution-parameters
literals:
- SAS_CONTEXT_PATH=reportDistribution
- SAS_DU_NAME=sas-report-distribution
- SAS_SERVICE_NAME=sas-report-distribution
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=report-distribution
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-execution-parameters
literals:
- SAS_DU_NAME=sas-report-execution
- SAS_SERVICE_NAME=sas-report-execution
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-images-parameters
literals:
- SAS_CONTEXT_PATH=reportImages
- SAS_DU_NAME=sas-report-renderers
- SAS_SERVICE_NAME=sas-report-images
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-operations-parameters
literals:
- SAS_CONTEXT_PATH=reportOperations
- SAS_DU_NAME=sas-visual-analytics
- SAS_SERVICE_NAME=sas-report-operations
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-packages-parameters
literals:
- SAS_CONTEXT_PATH=reportPackages
- SAS_PORT_NAME=reportpackages
- SAS_SERVICE_NAME=sas-report-packages
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-renderer-parameters
literals:
- SAS_CONTEXT_PATH=reportRenderer
- SAS_DU_NAME=sas-report-renderers
- SAS_SERVICE_NAME=sas-report-renderer
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-renderers-parameters
literals:
- SAS_CONTEXT_PATH=report-renderers
- SAS_DU_NAME=sas-report-renderers
- SAS_SERVICE_NAME=sas-report-renderers
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=report-renderers
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-services-group-parameters
literals:
- SAS_DU_NAME=sas-report-services-group
- SAS_SERVICE_NAME=sas-report-services-group
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-templates-parameters
literals:
- SAS_CONTEXT_PATH=reportTemplates
- SAS_PORT_NAME=reporttemplates
- SAS_SERVICE_NAME=sas-report-templates
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-report-transforms-parameters
literals:
- SAS_CONTEXT_PATH=reportTransforms
- SAS_PORT_NAME=reporttransform
- SAS_SERVICE_NAME=sas-report-transforms
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-reports-parameters
literals:
- SAS_CONTEXT_PATH=reports
- SAS_PORT_NAME=reports
- SAS_SERVICE_NAME=sas-reports
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-restore-job-parameters
literals:
- OAUTH2_CLIENT_ACCESSTOKENVALIDITY=72000
- SAS_CONTEXT_PATH=restore
- SAS_CRONJOB_NAME=sas-restore-job
- SAS_DU_NAME=sas-restore-job
- SAS_RESTORE_JOB_DU_NAME=sas-restore-job
- SAS_SERVICE_NAME=sas-restore-job
- SG_PROJECT=backup
options:
  labels:
    app.kubernetes.io/name: sas-restore-job
    sas.com/admin: namespace
    sas.com/backup-job-type: restore
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASRiskCirrus
- SAS_DU_NAME=sas-risk-cirrus-app
- SAS_SERVICE_NAME=sas-risk-cirrus-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_HOOK_IMAGE=registry.unx.sas.com/convoy-devops/pre-commit:1.8.5
- SG_PROJECT=sas-risk-cirrus-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-builder-parameters
literals:
- RISK_CIRRUS_UI_SAVE_ENABLED=true
- SAS_CONTEXT_PATH=riskCirrusBuilder
- SAS_DU_NAME=sas-risk-cirrus-builder
- SAS_LOG_LEVEL_RISKCIRRUSBUILDER=INFO
- SAS_LOG_LEVEL_RISKCIRRUSCOMMONS=INFO
- SAS_SERVICE_NAME=sas-risk-cirrus-builder
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_GO_TEST_TIMEOUT=30m
- SG_PROJECT=risk-cirrus-builder
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-core-parameters
literals:
- SAS_CONTEXT_PATH=riskCirrusCore
- SAS_CORE_SERVICE=sas-risk-cirrus-core
- SAS_DU_NAME=sas-risk-cirrus-rcc
- SAS_LOG_LEVEL_RISKCIRRUSDEPLOYER=INFO
- SAS_RISK_CIRRUS_BATCH_PYTHON_BIN_PATH=python
- SAS_RISK_CIRRUS_CADENCE=2025.09
- SAS_RISK_CIRRUS_CODE_LIB_LOCAL=Y
- SAS_RISK_CIRRUS_CODE_LIB_SHARED_DIR=/riskcirruscore
- SAS_RISK_CIRRUS_CODE_LIB_SSC=RCC
- SAS_RISK_CIRRUS_DEPLOYER_INSTALL_STEPS_FILE=../content/install_steps.json
- SAS_RISK_CIRRUS_DEPLOYER_RUN_SPECIFIC_INSTALL_STEPS=
- SAS_RISK_CIRRUS_DEPLOYER_SKIP_SPECIFIC_INSTALL_STEPS=
- SAS_RISK_CIRRUS_DEPLOYER_SLEEP_AFTER_DEPLOY=N
- SAS_RISK_CIRRUS_OBJECTS_REQUIRED=Y
- SAS_RISK_CIRRUS_SOLUTION_BUILDER_REPO_TYPE=database
- SAS_RISK_CIRRUS_SOLUTION_IS_CORE=Y
- SAS_RISK_CIRRUS_SOLUTION_REPLACE_PREV_SOLUTION=N
- SAS_SERVICE_NAME=sas-risk-cirrus-rcc
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-core-service-parameters
literals:
- SAS_CONTEXT_PATH=riskCirrusCore
- SAS_DU_NAME=sas-risk-cirrus-core
- SAS_RISK_CIRRUS_BATCH_PYTHON_BIN_PATH=python
- SAS_SERVICE_NAME=sas-risk-cirrus-core
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=risk-cirrus-core
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-objects-config
literals:
- JAVA_OPTION_JAVA_LOCALE_USEOLDISOCODES=-Djava.locale.useOldISOCodes=true
- JAVA_OPTION_MHS=-Djdk.tls.maxHandshakeMessageSize=65536
- JAVA_OPTION_XMX=-Xmx512m
- JAVA_OPTION_XPREFETCH=-Dsas.event.consumer.prefetchCount=8
- JAVA_OPTION_XSS=-Xss1048576
- SEARCH_ENABLED=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-objects-parameters
literals:
- SAS_CONTEXT_PATH=riskCirrusObjects
- SAS_DU_NAME=sas-risk-cirrus-objects
- SAS_SERVICE_NAME=sas-risk-cirrus-objects
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-cirrus-rm-parameters
literals:
- SAS_CONTEXT_PATH=/SASRiskCirrus/Solutions/RM
- SAS_DU_NAME=sas-risk-cirrus-rm
- SAS_LOG_LEVEL_RISKCIRRUSDEPLOYER=INFO
- SAS_RISK_CIRRUS_DEPLOYER_INCLUDE_SAMPLES=N
- SAS_RISK_CIRRUS_DEPLOYER_INSTALL_STEPS_FILE=../content/install_steps.json
- SAS_RISK_CIRRUS_DEPLOYER_RUN_SPECIFIC_INSTALL_STEPS=
- SAS_RISK_CIRRUS_DEPLOYER_SKIP_SPECIFIC_INSTALL_STEPS=
- SAS_RISK_CIRRUS_DEPLOYER_SLEEP_AFTER_DEPLOY=N
- SAS_RISK_CIRRUS_OBJECTS_REQUIRED=Y
- SAS_RISK_CIRRUS_SOLUTION_BUILDER_REPO_TYPE=database
- SAS_RISK_CIRRUS_SOLUTION_REPLACE_PREV_SOLUTION=N
- SAS_SERVICE_NAME=sas-risk-cirrus-rm
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-data-config
literals:
- SAS_DATABASE_ALTERNATIVE_DATABASESERVERNAME=sas-cdspostgres
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-data-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=riskData
- SAS_DU_NAME=sas-risk-data
- SAS_SERVICE_NAME=sas-risk-data
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=risk-data
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-modeling-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASRiskModeling
- SAS_DU_NAME=sas-risk-modeling-app
- SAS_SERVICE_NAME=sas-risk-modeling-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_GRADLE_CMD_OPTIONS='--info'
- SG_PROJECT=riskmodeling
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-risk-modeling-core-parameters
literals:
- SAS_CONTEXT_PATH=riskModelingCore
- SAS_DU_NAME=sas-risk-modeling-core
- SAS_SERVICE_NAME=sas-risk-modeling-core
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-row-sets-parameters
literals:
- SAS_CONTEXT_PATH=rowSets
- SAS_PORT_NAME=rowsets
- SAS_SERVICE_NAME=sas-row-sets
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-scheduled-backup-all-sources-parameters-k5f7ctc924
literals:
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_CRONJOB_NAME=sas-scheduled-backup-all-sources
- SAS_DU_NAME=sas-backup-job
- SAS_SERVICE_NAME=sas-backup-job
options:
  labels:
    app.kubernetes.io/name: sas-scheduled-backup-all-sources
    sas.com/admin: namespace
    sas.com/backup-job-type: scheduled-backup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-scheduled-backup-incr-job-parameters-t4gmgthkgh
literals:
- FILE_SYSTEM_BACKUP_FORMAT=tar
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_CRONJOB_NAME=sas-scheduled-backup-incr-job
- SAS_DU_NAME=sas-backup-job
- SAS_SERVICE_NAME=sas-backup-job
options:
  labels:
    app.kubernetes.io/name: sas-scheduled-backup-incr-job
    sas.com/admin: namespace
    sas.com/backup-job-type: scheduled-backup-incremental
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-scheduled-backup-job-parameters-tkdg4cb5g9
literals:
- SAS_BACKUP_JOB_DU_NAME=sas-backup-job
- SAS_CONTEXT_PATH=backup
- SAS_CRONJOB_NAME=sas-scheduled-backup-job
- SAS_DU_NAME=sas-backup-job
- SAS_SERVICE_NAME=sas-backup-job
options:
  labels:
    app.kubernetes.io/name: sas-scheduled-backup-job
    sas.com/admin: namespace
    sas.com/backup-job-type: scheduled-backup
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-scheduler-parameters
literals:
- SAS_CONTEXT_PATH=scheduler
- SAS_DU_NAME=sas-scheduler
- SAS_SERVICE_NAME=sas-scheduler
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-score-definitions-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=scoreDefinitions
- SAS_DU_NAME=sas-score-definitions
- SAS_SERVICE_NAME=sas-score-definitions
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=score-definitions
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-score-execution-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=scoreExecution
- SAS_DU_NAME=sas-score-execution
- SAS_SERVICE_NAME=sas-score-execution
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=score-execution
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-search-index-parameters
literals:
- SAS_CONTEXT_PATH=searchIndex
- SAS_PORT_NAME=searchindex
- SAS_SERVICE_NAME=sas-search-index
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-search-parameters
literals:
- SAS_CONTEXT_PATH=search
- SAS_PORT_NAME=search
- SAS_SERVICE_NAME=sas-search
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-search-root-parameters
literals:
- SAS_CONTEXT_PATH=sas-search
- SAS_DU_NAME=sas-search
- SAS_SERVICE_NAME=sas-search
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=search
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-shared-config
literals:
- SAS_ALLOW_ADMIN_SCRIPTS=false
- SAS_MULTI_TENANCY_ENABLED=false
- SAS_URL_SERVICE_SCHEME=http
- SAS_URL_SERVICE_TEMPLATE=http://@k8s.service.name@
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-spring-23-management-config
literals:
- MANAGEMENT_ENDPOINTS_WEB_BASEPATH=/
- MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE=live, health, metrics, prometheus, ready
- MANAGEMENT_ENDPOINTS_WEB_PATHMAPPING_ENV=/internal/env
- MANAGEMENT_ENDPOINTS_WEB_PATHMAPPING_HEALTH=/internal
- MANAGEMENT_ENDPOINTS_WEB_PATHMAPPING_PROMETHEUS=/internal/metrics
- MANAGEMENT_ENDPOINT_HEALTH_GROUP_LIVE_INCLUDE=livenessState
- MANAGEMENT_ENDPOINT_HEALTH_GROUP_READY_INCLUDE=readinessState, bootstrap
- MANAGEMENT_ENDPOINT_HEALTH_PROBES_ENABLED=true
- MANAGEMENT_ENDPOINT_METRICS_ENABLED=false
- MANAGEMENT_ENDPOINT_PROMETHEUS_ENABLED=true
- MANAGEMENT_SERVER_PORT=10445
- MANAGEMENT_SERVER_SERVLET_CONTEXTPATH=/
- SAS_MANAGEMENT_INDICATOR_BOOTSTRAP_ENABLED=true
- SAS_MANAGEMENT_INDICATOR_COMMONS_ENABLED=true
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-spring-management-config
literals:
- MANAGEMENT_ENDPOINTS_WEB_BASEPATH=/internal
- MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE=live, health, prometheus, ready
- MANAGEMENT_ENDPOINTS_WEB_PATHMAPPING_PROMETHEUS=metrics
- MANAGEMENT_ENDPOINT_LIVE_ENABLED=true
- MANAGEMENT_ENDPOINT_METRICS_ENABLED=false
- MANAGEMENT_ENDPOINT_PROMETHEUS_ENABLED=true
- MANAGEMENT_ENDPOINT_READY_ENABLED=true
- MANAGEMENT_SERVER_PORT=10445
- MANAGEMENT_SERVER_SERVLET_CONTEXTPATH=/
- SAS_MANAGEMENT_INDICATOR_BOOTSTRAP_ENABLED=true
- SAS_MANAGEMENT_INDICATOR_COMMONS_ENABLED=true
- SAS_MANAGEMENT_INDICATOR_LIVE_ENABLED=true
- SAS_MANAGEMENT_INDICATOR_READY_ENABLED=true
- SPRING_CLOUD_CONSUL_DISCOVERY_HEALTHCHECKPATH=/internal/health
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-start-all-parameters-mf4bhtcd5g
literals:
- SAS_CRONJOB_NAME=sas-start-all
- SAS_DU_NAME=sas-k8s-common
- SAS_SERVICE_NAME=sas-start-all
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-stop-all-parameters-24g47b7k28
literals:
- SAS_CRONJOB_NAME=sas-stop-all
- SAS_DU_NAME=sas-k8s-common
- SAS_SERVICE_NAME=sas-stop-all
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-studio-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASStudio
- SAS_DU_NAME=sas-studio-app
- SAS_SERVICE_NAME=sas-studio-app
- SG_PROJECT=sas-studio-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-studio-development-parameters
literals:
- SAS_CONTEXT_PATH=studioDevelopment
- SAS_DU_NAME=sas-studio-development
- SAS_SERVICE_NAME=sas-studio-development
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=studio-development
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-studio-parameters
literals:
- SAS_CONTEXT_PATH=studio
- SAS_DU_NAME=sas-studio
- SAS_INIT_CODE_PATH=meta/sasinit
- SAS_SERVICE_NAME=sas-studio
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=studio
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-studio-steps-parameters
literals:
- SAS_DU_NAME=sas-studio-steps
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-subject-contacts-parameters
literals:
- SAS_CONTEXT_PATH=subjectContacts
- SAS_DU_NAME=sas-subject-contacts
- SAS_SERVICE_NAME=sas-subject-contacts
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-templates-parameters
literals:
- SAS_CONTEXT_PATH=templates
- SAS_SERVICE_NAME=sas-templates
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-terms-management-parameters
literals:
- SAS_CONTEXT_PATH=termsManagement
- SAS_DU_NAME=sas-text-analytics-data
- SAS_SERVICE_NAME=sas-terms-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-text-analytics-data-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- GOEXPERIMENT=nocoverageredesign
- SAS_CONTEXT_PATH=textAnalyticsData
- SAS_DU_NAME=sas-text-analytics-data
- SAS_SERVICE_NAME=sas-text-analytics-data
- SG_FIPS=true
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=text-analytics-data
- SG_STATIC=false
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-text-analytics-taxonomies-parameters
literals:
- GOEXPERIMENT=nocoverageredesign
- SAS_CONTEXT_PATH=textAnalyticsTaxonomies
- SAS_DU_NAME=sas-text-analytics-taxonomies
- SAS_SERVICE_NAME=sas-text-analytics-taxonomies
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=text-analytics-taxonomies
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-theme-content-parameters
literals:
- SAS_CONTEXT_PATH=themeContent
- SAS_DU_NAME=sas-web-assets
- SAS_SERVICE_NAME=sas-theme-content
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-theme-designer-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASThemeDesigner
- SAS_DU_NAME=sas-theme-designer-app
- SAS_SERVICE_NAME=sas-theme-designer-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=theme-designer-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-themes-parameters
literals:
- SAS_CONTEXT_PATH=themes
- SAS_DU_NAME=sas-web-assets
- SAS_SERVICE_NAME=sas-themes
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-thumbnails-parameters
literals:
- SAS_CONTEXT_PATH=thumbnails
- SAS_DU_NAME=sas-content
- SAS_SERVICE_NAME=sas-thumbnails
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-tls-config
literals:
- CAS_CLIENT_SSL_CA_LIST=/security/trustedcerts.pem
- SAS_CERTIFICATE_CA_CERTIFICATE_FILE=/security/ca.crt
- SAS_CERTIFICATE_FILE=/security/tls.crt
- SAS_CERTIFICATE_PRIVATE_KEY_FILE=/security/tls.key
- SAS_TLS_LISTENER_ENABLED=true
- SAS_TRUSTED_CA_CERTIFICATES_JKS_FILE=/security/trustedcerts.jks
- SAS_TRUSTED_CA_CERTIFICATES_PEM_FILE=/security/trustedcerts.pem
- SSL_CERT_FILE=/security/trustedcerts.pem
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-topic-management-parameters
literals:
- SAS_CONTEXT_PATH=topicManagement
- SAS_DU_NAME=sas-text-analytics-data
- SAS_SERVICE_NAME=sas-topic-management
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-transfer-parameters
literals:
- SAS_CONTEXT_PATH=transfer
- SAS_DU_NAME=sas-transfer
- SAS_SERVICE_NAME=sas-transfer
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-treatment-definitions-parameters
literals:
- SAS_CONTEXT_PATH=treatmentDefinitions
- SAS_DU_NAME=sas-treatment-definitions
- SAS_SERVICE_NAME=sas-treatment-definitions
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-types-parameters
literals:
- SAS_CONTEXT_PATH=types
- SAS_SERVICE_NAME=sas-types
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-visual-analytics-administration-parameters
literals:
- SAS_CONTEXT_PATH=visualAnalyticsAdministration
- SAS_DU_NAME=sas-visual-analytics-app
- SAS_SERVICE_NAME=sas-visual-analytics-administration
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-visual-analytics-app-parameters
literals:
- SAS_CONTEXT_PATH=SASVisualAnalytics
- SAS_DU_NAME=sas-visual-analytics-app
- SAS_SERVICE_NAME=sas-visual-analytics-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-visual-analytics-app-root-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=sas-visual-analytics-app
- SAS_DU_NAME=sas-visual-analytics-app
- SAS_SERVICE_NAME=sas-visual-analytics-app
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=visual-analytics-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-visual-analytics-parameters
literals:
- SAS_CONTEXT_PATH=visualAnalytics
- SAS_DU_NAME=sas-visual-analytics
- SAS_SERVICE_NAME=sas-visual-analytics
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-visual-analytics-root-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=sas-visual-analytics
- SAS_DU_NAME=sas-visual-analytics
- SAS_SERVICE_NAME=sas-visual-analytics
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=visual-analytics
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-viya-context-root-parameters
literals:
- SAS_CONTEXT_PATH=appRegistry/initialPage
- SAS_DU_NAME=sas-app-registry
- SAS_SERVICE_NAME=sas-viya-context-root
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-web-assets-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=sas-web-assets
- SAS_DU_NAME=sas-web-assets
- SAS_SERVICE_NAME=sas-web-assets
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=web-assets
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-web-data-access-parameters
literals:
- SAS_CONTEXT_PATH=webDataAccess
- SAS_DU_NAME=sas-geography
- SAS_SERVICE_NAME=sas-web-data-access
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-webhooks-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=webhooks
- SAS_DU_NAME=sas-webhooks
- SAS_SERVICE_NAME=sas-webhooks
- SG_GO_COVERPKGS=./...
- SG_GO_MODULES_ENABLED=true
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=webhooks
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workflow-definition-parameters
literals:
- SAS_CONTEXT_PATH=workflowDefinition
- SAS_SERVICE_NAME=sas-workflow-definition
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workflow-engine-parameters
literals:
- SAS_DU_NAME=sas-workflow-engine
- SAS_SERVICE_NAME=sas-workflow-engine
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workflow-history-parameters
literals:
- SAS_CONTEXT_PATH=workflowHistory
- SAS_DU_NAME=sas-workflow-history
- SAS_SERVICE_NAME=sas-workflow-history
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workflow-manager-app-parameters
literals:
- CNTR_REPO_PREFIX=convoy
- SAS_CONTEXT_PATH=SASWorkflowManager
- SAS_DU_NAME=sas-workflow-manager-app
- SAS_SERVICE_NAME=sas-workflow-manager-app
- SG_GO_MODULES_ENABLED=false
- SG_GO_MULTI_MODULES=true
- SG_PROJECT=workflow-manager-app
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workflow-parameters
literals:
- SAS_CONTEXT_PATH=workflow
- SAS_SERVICE_NAME=sas-workflow
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workload-orchestrator-external-parameters
literals:
- SAS_SERVICE_NAME=sas-workload-orchestrator
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workload-orchestrator-initial-configuration
literals:
- |
  SGMG_CONFIG_JSON={
    "version" : 1,
    "admins"  : ["SASAdministrators"],
    "hostTypes":
    [
        {
          "name"           : "default",
          "description"    : "SAS Workload Orchestrator Server Hosts on Kubernetes Nodes",
          "role"           : "server"
        }
    ]
  }
---
apiVersion: builtin
kind: ConfigMapGenerator
metadata:
  name: sas-workload-orchestrator-parameters
literals:
- SAS_CONTEXT_PATH=workloadOrchestrator
- SAS_DU_NAME=sas-workload-orchestrator
- SAS_SERVICE_NAME=sas-workload-orchestrator
- SGMG_MANAGER_SERVICE_PREFIX=sas-workload-orchestrator
- SGMG_PORT=8080
